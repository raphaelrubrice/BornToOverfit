{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f6f78c42",
      "metadata": {
        "id": "f6f78c42"
      },
      "source": [
        "# **Running the baseline**\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/raphaelrubrice/BornToOverfit/blob/raph/baseline.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a>  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d44c459",
      "metadata": {
        "id": "8d44c459"
      },
      "source": [
        "## **Colab setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a3c77b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9a3c77b",
        "outputId": "d26f65c9-8434-4210-b2fc-9a8bd36cf995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# to avoid having the data on your drive\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/raphaelrubrice/BornToOverfit.git\n",
        "%cd BornToOverfit\n",
        "!git checkout Camille"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yFJ-AUT6w5g",
        "outputId": "c4ad67d8-73b9-418e-f123-bbc6bb3280e4"
      },
      "id": "9yFJ-AUT6w5g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BornToOverfit'...\n",
            "remote: Enumerating objects: 691, done.\u001b[K\n",
            "remote: Counting objects: 100% (272/272), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 691 (delta 183), reused 161 (delta 90), pack-reused 419 (from 1)\u001b[K\n",
            "Receiving objects: 100% (691/691), 1.04 MiB | 4.11 MiB/s, done.\n",
            "Resolving deltas: 100% (462/462), done.\n",
            "/content/BornToOverfit\n",
            "Branch 'Camille' set up to track remote branch 'Camille' from 'origin'.\n",
            "Switched to a new branch 'Camille'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3346ea9",
      "metadata": {
        "id": "b3346ea9"
      },
      "source": [
        "Installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d067adf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d067adf",
        "outputId": "defc7db3-767a-4ebb-bd56-65becea52300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r data_baseline/requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Collecting torch-geometric>=2.3.0 (from -r data_baseline/requirements.txt (line 2))\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r data_baseline/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from -r data_baseline/requirements.txt (line 4)) (4.57.3)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r data_baseline/requirements.txt (line 5)) (4.67.1)\n",
            "Collecting rdkit>=2023.3.1 (from -r data_baseline/requirements.txt (line 6))\n",
            "  Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: nltk>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from -r data_baseline/requirements.txt (line 7)) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (3.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->-r data_baseline/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->-r data_baseline/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->-r data_baseline/requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit>=2023.3.1->-r data_baseline/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8.0->-r data_baseline/requirements.txt (line 7)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8.0->-r data_baseline/requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r data_baseline/requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r data_baseline/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r data_baseline/requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.3.0->-r data_baseline/requirements.txt (line 2)) (2025.11.12)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit, torch-geometric\n",
            "Successfully installed rdkit-2025.9.3 torch-geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r data_baseline/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ad188a",
      "metadata": {
        "id": "b8ad188a"
      },
      "source": [
        "Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc9c409a",
      "metadata": {
        "id": "bc9c409a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a6b484-c9b0-4c72-8367-ba9b62f84ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot open '/content/drive/MyDrive/Kaggle_ALTEGRAD/data/results/baseline.gsheet' for reading: Operation not supported\n"
          ]
        }
      ],
      "source": [
        "!cp -r /content/drive/MyDrive/Kaggle_ALTEGRAD/data /content/BornToOverfit/data_baseline/."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Configuration des chemins\n",
        "DATA_DIR = Path(\"data_baseline/data\")\n",
        "\n",
        "TRAIN_FILE = DATA_DIR / \"train_embeddings_RealChemBERT.pt\"\n",
        "VAL_FILE = DATA_DIR / \"validation_embeddings_RealChemBERT.pt\"\n",
        "\n",
        "# Fonction pour charger le .pt\n",
        "def load_embeddings_pt(filepath):\n",
        "    print(f\"üì• Chargement de {filepath}...\")\n",
        "\n",
        "    # On charge le dictionnaire binaire directement\n",
        "    # map_location='cpu' √©vite les erreurs si le fichier a √©t√© sauv√© sur GPU et qu'on charge sur CPU\n",
        "    data = torch.load(filepath, map_location='cpu')\n",
        "\n",
        "    # On r√©cup√®re les cl√©s qu'on a d√©finies lors de la g√©n√©ration\n",
        "    ids = data['ids']\n",
        "    embeddings_tensor = data['embeddings']\n",
        "\n",
        "    print(f\"‚úÖ Charg√© ! Shape: {embeddings_tensor.shape}\")\n",
        "    return ids, embeddings_tensor\n",
        "\n",
        "# 2. Logique Principale\n",
        "if TRAIN_FILE.exists() and VAL_FILE.exists():\n",
        "    print(\"üöÄ Fichiers .pt trouv√©s ! Chargement direct...\")\n",
        "\n",
        "    train_ids, train_embeddings = load_embeddings_pt(TRAIN_FILE)\n",
        "    val_ids, val_embeddings = load_embeddings_pt(VAL_FILE)\n",
        "\n",
        "    # Exemple d'acc√®s pour v√©rifier\n",
        "    print(f\"Premier ID train : {train_ids[0]}\")\n",
        "    print(f\"Norme du premier vecteur : {train_embeddings[0].norm().item():.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Fichiers non trouv√©s : {TRAIN_FILE}\")\n",
        "    print(\"‚öôÔ∏è Lancement du script de g√©n√©ration...\")\n",
        "\n",
        "    cmd = [\n",
        "        \"python\", \"data_baseline/generate_description_embeddings_automatic.py\",\n",
        "        \"--data_dir\", \"data_baseline/data\",\n",
        "        \"--model_name\", \"recobo/chemical-bert-uncased\",\n",
        "        \"--pooling\", \"cls\",\n",
        "        \"--splits\", \"train\", \"validation\"\n",
        "    ]\n",
        "\n",
        "    process = subprocess.run(cmd, capture_output=False)\n",
        "\n",
        "    if process.returncode == 0:\n",
        "        print(\"\\n‚úÖ G√©n√©ration termin√©e avec succ√®s !\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå Erreur lors de la g√©n√©ration.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt0-2wnPiRLO",
        "outputId": "e7868851-e71c-4462-c420-f29980211de4"
      },
      "id": "yt0-2wnPiRLO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Fichiers .pt trouv√©s ! Chargement direct...\n",
            "üì• Chargement de data_baseline/data/train_embeddings_RealChemBERT.pt...\n",
            "‚úÖ Charg√© ! Shape: torch.Size([31008, 768])\n",
            "üì• Chargement de data_baseline/data/validation_embeddings_RealChemBERT.pt...\n",
            "‚úÖ Charg√© ! Shape: torch.Size([1000, 768])\n",
            "Premier ID train : 0\n",
            "Norme du premier vecteur : 24.6847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dual Encoder**"
      ],
      "metadata": {
        "id": "E9zVABzjuO5J"
      },
      "id": "E9zVABzjuO5J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code qui va tourner pour train le dual encoder\n"
      ],
      "metadata": {
        "id": "_oethq9hDYZC"
      },
      "id": "_oethq9hDYZC"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_baseline/train_dual_encoder_optimized.py\n",
        "import os\n",
        "import argparse\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.nn import GPSConv, GINEConv, global_add_pool\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# --- DATASET ---\n",
        "class RawTextGraphDataset(Dataset):\n",
        "    def __init__(self, pkl_path):\n",
        "        self.pkl_path = Path(pkl_path)\n",
        "        with open(self.pkl_path, 'rb') as f:\n",
        "            self.data_list = pickle.load(f)\n",
        "    def __len__(self): return len(self.data_list)\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        text = data.description if hasattr(data, 'description') else \"\"\n",
        "        return data, text\n",
        "\n",
        "class DualCollate:\n",
        "    def __init__(self, tokenizer, max_len=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __call__(self, batch):\n",
        "        graphs, texts = zip(*batch)\n",
        "        batched_graphs = Batch.from_data_list(graphs)\n",
        "        text_inputs = self.tokenizer(list(texts), padding=True, truncation=True,\n",
        "                                     max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return batched_graphs, text_inputs\n",
        "\n",
        "# --- MODELS ---\n",
        "ATOM_DIMS = [119, 4, 11, 12, 9, 5, 8, 2, 2]\n",
        "BOND_DIMS = [22, 6, 2]\n",
        "\n",
        "class AtomEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in ATOM_DIMS])\n",
        "    def forward(self, x):\n",
        "        return sum(emb(x[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class BondEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in BOND_DIMS])\n",
        "    def forward(self, edge_attr):\n",
        "        return sum(emb(edge_attr[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class MolGNN(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, out_dim=768, num_layers=4, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.atom_encoder = AtomEncoder(hidden_dim)\n",
        "        self.bond_encoder = BondEncoder(hidden_dim)\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            local_nn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, 2 * hidden_dim),\n",
        "                nn.BatchNorm1d(2 * hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GPSConv(\n",
        "                hidden_dim,\n",
        "                GINEConv(local_nn, train_eps=True, edge_dim=hidden_dim),\n",
        "                heads=num_heads,\n",
        "                dropout=dropout,\n",
        "                attn_type='multihead'\n",
        "            ))\n",
        "        self.pool = global_add_pool\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        h = self.atom_encoder(batch.x)\n",
        "        edge_attr = self.bond_encoder(batch.edge_attr)\n",
        "        for conv in self.convs:\n",
        "            h = conv(h, batch.edge_index, batch.batch, edge_attr=edge_attr)\n",
        "        return self.proj(self.pool(h, batch.batch))\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, model_name, gnn_args, freeze_layers=0):\n",
        "        super().__init__()\n",
        "        self.graph_encoder = MolGNN(**gnn_args)\n",
        "        self.text_encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        if freeze_layers > 0:\n",
        "            print(f\"‚ùÑÔ∏è Gel des {freeze_layers} premi√®res couches de BERT\")\n",
        "            for param in self.text_encoder.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "            for i in range(freeze_layers):\n",
        "                if i < len(self.text_encoder.encoder.layer):\n",
        "                    for param in self.text_encoder.encoder.layer[i].parameters():\n",
        "                        param.requires_grad = False\n",
        "\n",
        "        bert_dim = self.text_encoder.config.hidden_size\n",
        "        out_dim = gnn_args['out_dim']\n",
        "        self.text_proj = nn.Linear(bert_dim, out_dim) if bert_dim != out_dim else nn.Identity()\n",
        "\n",
        "    def forward(self, batch_graphs, text_inputs):\n",
        "        g_emb = self.graph_encoder(batch_graphs)\n",
        "        t_out = self.text_encoder(**text_inputs)\n",
        "        t_emb = self.text_proj(t_out.last_hidden_state[:, 0, :])\n",
        "        return F.normalize(g_emb, dim=-1), F.normalize(t_emb, dim=-1)\n",
        "\n",
        "# --- LOSS CORRIG√âE POUR FP16 ---\n",
        "def triplet_loss(mol_vec, txt_vec, margin=0.2):\n",
        "    sims = mol_vec @ txt_vec.t()\n",
        "    mask = torch.eye(sims.size(0), device=sims.device).bool()\n",
        "\n",
        "    # CORRECTION : On utilise la plus petite valeur support√©e par le type de donn√©es actuel\n",
        "    # En Float16 (AMP), min_value sera ~ -65000, ce qui ne plante pas.\n",
        "    min_value = torch.finfo(sims.dtype).min\n",
        "    neg_sims = sims.masked_fill(mask, min_value)\n",
        "\n",
        "    hard_neg_m2t = neg_sims.max(dim=1, keepdim=True)[0]\n",
        "    hard_neg_t2m = neg_sims.max(dim=0, keepdim=True)[0].t()\n",
        "    pos_sims = sims.diag().unsqueeze(1)\n",
        "\n",
        "    loss = (F.relu(margin + hard_neg_m2t - pos_sims).mean() +\n",
        "            F.relu(margin + hard_neg_t2m - pos_sims).mean())\n",
        "    return loss / 2\n",
        "\n",
        "# --- EVALUATION ---\n",
        "@torch.no_grad()\n",
        "def evaluate_retrieval(model, val_loader, device):\n",
        "    \"\"\"√âvalue le MRR sur le validation set.\"\"\"\n",
        "    model.eval()\n",
        "    all_g_emb, all_t_emb = [], []\n",
        "\n",
        "    for graphs, text_inputs in val_loader:\n",
        "        graphs = graphs.to(device)\n",
        "        text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
        "\n",
        "        # En eval, on peut d√©sactiver autocast ou le laisser, mais ici on le garde\n",
        "        # pour √™tre coh√©rent, m√™me si moins critique.\n",
        "        with autocast():\n",
        "             g_emb, t_emb = model(graphs, text_inputs)\n",
        "\n",
        "        all_g_emb.append(g_emb.float()) # On repasse en float32 pour le calcul de similarit√© pr√©cis\n",
        "        all_t_emb.append(t_emb.float())\n",
        "\n",
        "    all_g_emb = torch.cat(all_g_emb, dim=0)\n",
        "    all_t_emb = torch.cat(all_t_emb, dim=0)\n",
        "\n",
        "    # Text-to-Molecule retrieval\n",
        "    sims = all_t_emb @ all_g_emb.t()  # [N, N]\n",
        "    ranks = sims.argsort(dim=-1, descending=True)\n",
        "\n",
        "    N = sims.size(0)\n",
        "    correct = torch.arange(N, device=sims.device)\n",
        "    positions = (ranks == correct.unsqueeze(1)).nonzero()[:, 1] + 1\n",
        "\n",
        "    mrr = (1.0 / positions.float()).mean().item()\n",
        "    r1 = (positions <= 1).float().mean().item()\n",
        "    r5 = (positions <= 5).float().mean().item()\n",
        "    r10 = (positions <= 10).float().mean().item()\n",
        "\n",
        "    return {'MRR': mrr, 'R@1': r1, 'R@5': r5, 'R@10': r10}\n",
        "\n",
        "# --- MAIN ---\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--data_dir', type=str, default='data_baseline/data')\n",
        "    parser.add_argument('--model_name', type=str, default='recobo/chemical-bert-uncased')\n",
        "\n",
        "    # Param√®tres √† varier\n",
        "    parser.add_argument('--lr_gnn', type=float, default=8e-4)\n",
        "    parser.add_argument('--lr_bert', type=float, default=3e-5)\n",
        "    parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
        "    parser.add_argument('--freeze_layers', type=int, default=0)\n",
        "    parser.add_argument('--margin', type=float, default=0.2)\n",
        "\n",
        "    # Training\n",
        "    parser.add_argument('--batch_size', type=int, default=16)\n",
        "    parser.add_argument('--grad_accum', type=int, default=8)\n",
        "    parser.add_argument('--epochs', type=int, default=150)\n",
        "    parser.add_argument('--patience', type=int, default=15)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"LR GNN      : {args.lr_gnn}\")\n",
        "    print(f\"LR BERT     : {args.lr_bert}\")\n",
        "    print(f\"Weight Decay: {args.weight_decay}\")\n",
        "    print(f\"Freeze Layers: {args.freeze_layers}\")\n",
        "    print(f\"Margin      : {args.margin}\")\n",
        "    print(f\"Batch Size  : {args.batch_size} √ó {args.grad_accum} = {args.batch_size * args.grad_accum} (effective)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
        "\n",
        "    # Train loader\n",
        "    train_loader = DataLoader(\n",
        "        RawTextGraphDataset(Path(args.data_dir) / \"train_graphs.pkl\"),\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=DualCollate(tokenizer),\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Validation loader\n",
        "    val_loader = DataLoader(\n",
        "        RawTextGraphDataset(Path(args.data_dir) / \"validation_graphs.pkl\"),\n",
        "        batch_size=64,  # Plus gros batch pour eval\n",
        "        shuffle=False,\n",
        "        collate_fn=DualCollate(tokenizer),\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    gnn_config = {\n",
        "        'hidden_dim': 256,\n",
        "        'out_dim': 768,\n",
        "        'num_layers': 4,\n",
        "        'num_heads': 4,\n",
        "        'dropout': 0.1\n",
        "    }\n",
        "    model = DualEncoder(args.model_name, gnn_config, freeze_layers=args.freeze_layers).to(DEVICE)\n",
        "\n",
        "    # Optimizer avec weight decay diff√©renci√©\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': model.graph_encoder.parameters(),\n",
        "         'lr': args.lr_gnn,\n",
        "         'weight_decay': args.weight_decay},\n",
        "        {'params': model.text_encoder.parameters(),\n",
        "         'lr': args.lr_bert,\n",
        "         'weight_decay': args.weight_decay / 10},\n",
        "        {'params': model.text_proj.parameters(),\n",
        "         'lr': args.lr_bert,\n",
        "         'weight_decay': args.weight_decay}\n",
        "    ])\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=[args.lr_gnn, args.lr_bert, args.lr_bert],\n",
        "        steps_per_epoch=len(train_loader) // args.grad_accum,\n",
        "        epochs=args.epochs,\n",
        "        pct_start=0.1\n",
        "    )\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    best_mrr = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # === TRAINING ===\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for step, (graphs, text_inputs) in enumerate(train_loader):\n",
        "            graphs = graphs.to(DEVICE)\n",
        "            text_inputs = {k: v.to(DEVICE) for k, v in text_inputs.items()}\n",
        "\n",
        "            with autocast():\n",
        "                g_emb, t_emb = model(graphs, text_inputs)\n",
        "                loss = triplet_loss(g_emb, t_emb, margin=args.margin) / args.grad_accum\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (step + 1) % args.grad_accum == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                scheduler.step()\n",
        "\n",
        "            total_loss += loss.item() * args.grad_accum\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # === VALIDATION ===\n",
        "        val_metrics = evaluate_retrieval(model, val_loader, DEVICE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{args.epochs} | \"\n",
        "              f\"Train Loss: {avg_loss:.4f} | \"\n",
        "              f\"Val MRR: {val_metrics['MRR']:.4f} | \"\n",
        "              f\"R@1: {val_metrics['R@1']:.4f}\")\n",
        "\n",
        "        # === EARLY STOPPING ===\n",
        "        if val_metrics['MRR'] > best_mrr:\n",
        "            best_mrr = val_metrics['MRR']\n",
        "            patience_counter = 0\n",
        "\n",
        "            effective_bs = args.batch_size * args.grad_accum\n",
        "            save_name = (f\"dual_lrGNN{args.lr_gnn}_lrBERT{args.lr_bert}_\"\n",
        "                        f\"wd{args.weight_decay}_frz{args.freeze_layers}_\"\n",
        "                        f\"margin{args.margin}_bs{effective_bs}.pt\")\n",
        "\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'args': vars(args),\n",
        "                'best_mrr': best_mrr\n",
        "            }, Path(args.data_dir) / save_name)\n",
        "\n",
        "            print(f\"  üíæ New Best MRR: {best_mrr:.4f} | Saved: {save_name}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= args.patience:\n",
        "                print(\"üõë Early stopping\")\n",
        "                break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIIoHoAKLw7K",
        "outputId": "42a6c7d0-06bd-4102-c2cf-a4c792e1b01f"
      },
      "id": "RIIoHoAKLw7K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_baseline/train_dual_encoder_optimized.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import time\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# =========================================================\n",
        "# 0. CONFIGURATION DRIVE & DOSSIERS\n",
        "# =========================================================\n",
        "print(\"üîÑ Connexion au Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# D√©finissez ici le dossier de VOTRE Drive o√π vous voulez stocker les r√©sultats\n",
        "# (Le script cr√©era le dossier s'il n'existe pas)\n",
        "DRIVE_OUTPUT_DIR = Path(\"/content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder\")\n",
        "DRIVE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Dossier de sauvegarde s√©curis√© : {DRIVE_OUTPUT_DIR}\")\n",
        "\n",
        "# Le CSV de r√©sultats sera mis √† jour en direct sur le Drive\n",
        "RESULTS_CSV = DRIVE_OUTPUT_DIR / \"dual_encoder_results.csv\"\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION DES EXP√âRIENCES\n",
        "# =========================================================\n",
        "EXPERIMENTS = [\n",
        "    # === GROUP 1 : LR BERT SWEEP (ROI ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    ## d√©j√† fait #{\"lr_gnn\": 8e-4, \"lr_bert\": 1e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Low LR BERT\"},\n",
        "    ## d√©j√† fait #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Baseline BERT\"},\n",
        "    ##√† run ##{\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"High LR BERT\"},\n",
        "\n",
        "    # === GROUP 2 : FREEZE STRATEGIES (ROI ‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 6, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Freeze 6 Layers\"},\n",
        "    #{\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 6, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Freeze 6 + High LR\"},\n",
        "    #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 9, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Freeze 9 Layers\"},\n",
        "\n",
        "    # === GROUP 3 : WEIGHT DECAY (ROI ‚≠ê‚≠ê‚≠ê) ===\n",
        "    #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-5, \"margin\": 0.2, \"name\": \"Low WD\"},\n",
        "    #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 5e-4, \"margin\": 0.2, \"name\": \"Medium WD\"},\n",
        "    #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-3, \"margin\": 0.2, \"name\": \"High WD\"},\n",
        "\n",
        "    # === GROUP 4 : MARGIN (ROI ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.15, \"name\": \"Low Margin\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.25, \"name\": \"High Margin\"},\n",
        "\n",
        "    # === GROUP 5 : LR GNN (ROI ‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 5e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Low LR GNN\"},\n",
        "    {\"lr_gnn\": 1e-3, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"High LR GNN\"},\n",
        "\n",
        "    # === GROUP 6 : COMBINATIONS (ROI ‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 0, \"wd\": 5e-4, \"margin\": 0.25, \"name\": \"Aggressive Full\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 6, \"wd\": 1e-4, \"margin\": 0.25, \"name\": \"Aggressive Freeze\"},\n",
        "    {\"lr_gnn\": 5e-4, \"lr_bert\": 1e-5, \"freeze\": 0, \"wd\": 1e-5, \"margin\": 0.15, \"name\": \"Conservative Full\"},\n",
        "\n",
        "    # === BATCH SIZE VARIATIONS (ROI ‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"batch_size\": 32, \"grad_accum\": 4, \"name\": \"Batch 128 (32x4)\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"batch_size\": 8, \"grad_accum\": 16, \"name\": \"Batch 128 (8x16)\"},\n",
        "]\n",
        "\n",
        "# Param√®tres fixes\n",
        "FIXED_PARAMS = {\n",
        "    \"data_dir\": \"data_baseline/data\",\n",
        "    \"model_name\": \"recobo/chemical-bert-uncased\",\n",
        "    \"batch_size\": 16,\n",
        "    \"grad_accum\": 8,\n",
        "    \"epochs\": 100,\n",
        "    \"patience\": 10,\n",
        "}\n",
        "\n",
        "# Chemin du script d'entra√Ænement (local)\n",
        "SCRIPT_PATH = \"data_baseline/train_dual_encoder_optimized.py\"\n",
        "\n",
        "# =========================================================\n",
        "# AFFICHAGE R√âCAPITULATIF\n",
        "# =========================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"üöÄ DUAL ENCODER - GRID SEARCH AUTOMATIQUE (DRIVE SAVE MODE)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Dossier de sortie    : {DRIVE_OUTPUT_DIR}\")\n",
        "print(f\"Fichier de r√©sultats : {RESULTS_CSV}\")\n",
        "print(f\"Nombre d'exp√©riences : {len(EXPERIMENTS)}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "input(\"\\n‚ö†Ô∏è  Appuie sur ENTER pour lancer (ou Ctrl+C pour annuler)...\\n\")\n",
        "\n",
        "# Charge les r√©sultats existants si on reprend le run\n",
        "results = []\n",
        "if RESULTS_CSV.exists():\n",
        "    print(f\"üîÑ Reprise du fichier existant : {RESULTS_CSV}\")\n",
        "    try:\n",
        "        existing_df = pd.read_csv(RESULTS_CSV)\n",
        "        results = existing_df.to_dict('records')\n",
        "        # On saute les runs d√©j√† faits ? (Optionnel, ici on refait tout par s√©curit√© ou on peut filtrer)\n",
        "        # runs_done = [r['Name'] for r in results]\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Impossible de lire le fichier existant, on repart √† z√©ro.\")\n",
        "\n",
        "total_start = datetime.now()\n",
        "\n",
        "for i, exp in enumerate(EXPERIMENTS, 1):\n",
        "\n",
        "    # V√©rifie si l'exp√©rience a d√©j√† √©t√© faite (Optionnel)\n",
        "    # if exp['name'] in [r.get('Name') for r in results]:\n",
        "    #     print(f\"‚è© Run {i} ({exp['name']}) d√©j√† fait. Skipping...\")\n",
        "    #     continue\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"RUN {i}/{len(EXPERIMENTS)} : {exp['name']}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"LR GNN      : {exp['lr_gnn']}\")\n",
        "    print(f\"LR BERT     : {exp['lr_bert']}\")\n",
        "    print(f\"Freeze      : {exp['freeze']} layers\")\n",
        "    print(f\"Weight Decay: {exp['wd']}\")\n",
        "    print(f\"Margin      : {exp['margin']}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Commande d'entra√Ænement (Les fichiers temp sont cr√©√©s en local d'abord pour la vitesse)\n",
        "    cmd = [\n",
        "        'python', '-u', SCRIPT_PATH,\n",
        "        '--data_dir', FIXED_PARAMS['data_dir'],\n",
        "        '--model_name', FIXED_PARAMS['model_name'],\n",
        "        '--lr_gnn', str(exp['lr_gnn']),\n",
        "        '--lr_bert', str(exp['lr_bert']),\n",
        "        '--freeze_layers', str(exp['freeze']),\n",
        "        '--weight_decay', str(exp['wd']),\n",
        "        '--margin', str(exp['margin']),\n",
        "        '--batch_size', str(exp.get('batch_size', FIXED_PARAMS['batch_size'])),\n",
        "        '--grad_accum', str(exp.get('grad_accum', FIXED_PARAMS['grad_accum'])),\n",
        "        '--epochs', str(FIXED_PARAMS['epochs']),\n",
        "        '--patience', str(FIXED_PARAMS['patience']),\n",
        "    ]\n",
        "\n",
        "    run_start = datetime.now()\n",
        "    generated_model_file = None # Pour stocker le nom du fichier cr√©√©\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1\n",
        "        )\n",
        "\n",
        "        output_lines = []\n",
        "        for line in process.stdout:\n",
        "            print(line, end='')\n",
        "            output_lines.append(line)\n",
        "            # On guette le nom du fichier sauvegard√© en local\n",
        "            if \"Saved: \" in line:\n",
        "                # Ex: \"Saved: dual_lrGNN...pt\"\n",
        "                try:\n",
        "                    generated_model_file = line.split(\"Saved: \")[1].strip()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        return_code = process.returncode\n",
        "\n",
        "        # Parsing des r√©sultats (MRR, etc.)\n",
        "        best_mrr = 0.0\n",
        "        best_r1 = 0.0\n",
        "        best_r5 = 0.0\n",
        "\n",
        "        for line in output_lines:\n",
        "            if \"New Best MRR:\" in line:\n",
        "                try:\n",
        "                    mrr_str = line.split(\"New Best MRR:\")[1].split(\"|\")[0].strip()\n",
        "                    best_mrr = float(mrr_str)\n",
        "                except: pass\n",
        "            elif \"Val MRR:\" in line and \"R@1:\" in line:\n",
        "                try:\n",
        "                    parts = line.split(\"|\")\n",
        "                    for part in parts:\n",
        "                        if \"Val MRR:\" in part: best_mrr = max(best_mrr, float(part.split(\":\")[1].strip()))\n",
        "                        elif \"R@1:\" in part: best_r1 = max(best_r1, float(part.split(\":\")[1].strip()))\n",
        "                        elif \"R@5:\" in part: best_r5 = max(best_r5, float(part.split(\":\")[1].strip()))\n",
        "                except: pass\n",
        "\n",
        "        elapsed = (datetime.now() - run_start).total_seconds() / 60\n",
        "        status = \"‚úÖ SUCCESS\" if return_code == 0 else \"‚ùå FAILED\"\n",
        "\n",
        "        # === SAUVEGARDE SUR DRIVE ===\n",
        "        # Si un fichier .pt a √©t√© cr√©√©, on le d√©place sur le Drive\n",
        "        if generated_model_file and return_code == 0:\n",
        "            local_path = Path(FIXED_PARAMS['data_dir']) / generated_model_file\n",
        "            if local_path.exists():\n",
        "                drive_path = DRIVE_OUTPUT_DIR / generated_model_file\n",
        "                print(f\"üì¶ Copie vers Drive : {drive_path} ...\")\n",
        "                shutil.copy2(local_path, drive_path)\n",
        "                print(\"‚úÖ Copie termin√©e.\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Fichier local introuvable : {local_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERREUR : {e}\")\n",
        "        elapsed = (datetime.now() - run_start).total_seconds() / 60\n",
        "        status = f\"‚ùå ERROR: {str(e)[:50]}\"\n",
        "        return_code = -1\n",
        "\n",
        "    # Enregistrement des r√©sultats\n",
        "    result = {\n",
        "        'Run': i,\n",
        "        'Name': exp['name'],\n",
        "        'LR_GNN': exp['lr_gnn'],\n",
        "        'LR_BERT': exp['lr_bert'],\n",
        "        'Freeze_Layers': exp['freeze'],\n",
        "        'Weight_Decay': exp['wd'],\n",
        "        'Margin': exp['margin'],\n",
        "        'MRR': best_mrr,\n",
        "        'R@1': best_r1,\n",
        "        'R@5': best_r5,\n",
        "        'Time_min': elapsed,\n",
        "        'Status': status,\n",
        "        'Model_File': generated_model_file if generated_model_file else \"N/A\"\n",
        "    }\n",
        "\n",
        "    # Mise √† jour de la liste et sauvegarde CSV imm√©diate sur le Drive\n",
        "    results.append(result)\n",
        "    df_temp = pd.DataFrame(results)\n",
        "    df_temp.to_csv(RESULTS_CSV, index=False)\n",
        "    print(f\"\\nüíæ CSV mis √† jour sur Drive : {RESULTS_CSV}\")\n",
        "\n",
        "    # Progression\n",
        "    total_elapsed = (datetime.now() - total_start).total_seconds() / 60\n",
        "    print(f\"\\n‚è±Ô∏è  Temps √©coul√© : {total_elapsed:.1f}min\")\n",
        "\n",
        "    if i < len(EXPERIMENTS):\n",
        "        print(\"\\n‚è∏Ô∏è  Pause de 30s...\")\n",
        "        time.sleep(30)\n",
        "\n",
        "print(\"\\nüéâ GRID SEARCH TERMIN√â - TOUT EST SUR LE DRIVE !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QduzxqnrIngK",
        "outputId": "9ec42d07-56aa-4fe8-fdae-130c162bb78c"
      },
      "id": "QduzxqnrIngK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Connexion au Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Dossier de sauvegarde s√©curis√© : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder\n",
            "================================================================================\n",
            "üöÄ DUAL ENCODER - GRID SEARCH AUTOMATIQUE (DRIVE SAVE MODE)\n",
            "================================================================================\n",
            "Dossier de sortie    : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder\n",
            "Fichier de r√©sultats : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "Nombre d'exp√©riences : 9\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Appuie sur ENTER pour lancer (ou Ctrl+C pour annuler)...\n",
            "\n",
            "üîÑ Reprise du fichier existant : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "================================================================================\n",
            "RUN 1/9 : Low Margin\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.15\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.15\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-11 17:39:59.140551: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-11 17:39:59.162111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768153199.187328    1241 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768153199.194580    1241 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768153199.212763    1241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768153199.212783    1241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768153199.212785    1241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768153199.212787    1241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 17:39:59.217802: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.1589 | Val MRR: 0.1610 | R@1: 0.0700\n",
            "  üíæ New Best MRR: 0.1610 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1185 | Val MRR: 0.3279 | R@1: 0.1770\n",
            "  üíæ New Best MRR: 0.3279 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.0668 | Val MRR: 0.4568 | R@1: 0.3000\n",
            "  üíæ New Best MRR: 0.4568 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0429 | Val MRR: 0.5425 | R@1: 0.3890\n",
            "  üíæ New Best MRR: 0.5425 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0321 | Val MRR: 0.5787 | R@1: 0.4170\n",
            "  üíæ New Best MRR: 0.5787 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0248 | Val MRR: 0.6083 | R@1: 0.4600\n",
            "  üíæ New Best MRR: 0.6083 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0213 | Val MRR: 0.6446 | R@1: 0.4830\n",
            "  üíæ New Best MRR: 0.6446 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0184 | Val MRR: 0.6271 | R@1: 0.4710\n",
            "Epoch 9/100 | Train Loss: 0.0165 | Val MRR: 0.6729 | R@1: 0.5170\n",
            "  üíæ New Best MRR: 0.6729 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0141 | Val MRR: 0.7146 | R@1: 0.5710\n",
            "  üíæ New Best MRR: 0.7146 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0129 | Val MRR: 0.7186 | R@1: 0.5790\n",
            "  üíæ New Best MRR: 0.7186 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0115 | Val MRR: 0.7166 | R@1: 0.5780\n",
            "Epoch 13/100 | Train Loss: 0.0101 | Val MRR: 0.7436 | R@1: 0.6240\n",
            "  üíæ New Best MRR: 0.7436 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0097 | Val MRR: 0.7502 | R@1: 0.6230\n",
            "  üíæ New Best MRR: 0.7502 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0092 | Val MRR: 0.7533 | R@1: 0.6330\n",
            "  üíæ New Best MRR: 0.7533 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0084 | Val MRR: 0.7853 | R@1: 0.6650\n",
            "  üíæ New Best MRR: 0.7853 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0078 | Val MRR: 0.7783 | R@1: 0.6610\n",
            "Epoch 18/100 | Train Loss: 0.0078 | Val MRR: 0.7948 | R@1: 0.6830\n",
            "  üíæ New Best MRR: 0.7948 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0077 | Val MRR: 0.7844 | R@1: 0.6680\n",
            "Epoch 20/100 | Train Loss: 0.0076 | Val MRR: 0.7888 | R@1: 0.6740\n",
            "Epoch 21/100 | Train Loss: 0.0072 | Val MRR: 0.7900 | R@1: 0.6760\n",
            "Epoch 22/100 | Train Loss: 0.0067 | Val MRR: 0.8090 | R@1: 0.7050\n",
            "  üíæ New Best MRR: 0.8090 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0067 | Val MRR: 0.8057 | R@1: 0.6950\n",
            "Epoch 24/100 | Train Loss: 0.0064 | Val MRR: 0.8115 | R@1: 0.7010\n",
            "  üíæ New Best MRR: 0.8115 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0059 | Val MRR: 0.8113 | R@1: 0.7060\n",
            "Epoch 26/100 | Train Loss: 0.0056 | Val MRR: 0.8120 | R@1: 0.7110\n",
            "  üíæ New Best MRR: 0.8120 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 27/100 | Train Loss: 0.0055 | Val MRR: 0.8170 | R@1: 0.7130\n",
            "  üíæ New Best MRR: 0.8170 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0060 | Val MRR: 0.8182 | R@1: 0.7130\n",
            "  üíæ New Best MRR: 0.8182 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 29/100 | Train Loss: 0.0058 | Val MRR: 0.8293 | R@1: 0.7290\n",
            "  üíæ New Best MRR: 0.8293 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 30/100 | Train Loss: 0.0063 | Val MRR: 0.8257 | R@1: 0.7300\n",
            "Epoch 31/100 | Train Loss: 0.0053 | Val MRR: 0.8202 | R@1: 0.7270\n",
            "Epoch 32/100 | Train Loss: 0.0053 | Val MRR: 0.8373 | R@1: 0.7410\n",
            "  üíæ New Best MRR: 0.8373 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 33/100 | Train Loss: 0.0047 | Val MRR: 0.8309 | R@1: 0.7370\n",
            "Epoch 34/100 | Train Loss: 0.0047 | Val MRR: 0.8532 | R@1: 0.7680\n",
            "  üíæ New Best MRR: 0.8532 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 35/100 | Train Loss: 0.0043 | Val MRR: 0.8492 | R@1: 0.7590\n",
            "Epoch 36/100 | Train Loss: 0.0041 | Val MRR: 0.8256 | R@1: 0.7260\n",
            "Epoch 37/100 | Train Loss: 0.0044 | Val MRR: 0.8431 | R@1: 0.7540\n",
            "Epoch 38/100 | Train Loss: 0.0042 | Val MRR: 0.8493 | R@1: 0.7630\n",
            "Epoch 39/100 | Train Loss: 0.0039 | Val MRR: 0.8463 | R@1: 0.7560\n",
            "Epoch 40/100 | Train Loss: 0.0038 | Val MRR: 0.8506 | R@1: 0.7590\n",
            "Epoch 41/100 | Train Loss: 0.0039 | Val MRR: 0.8513 | R@1: 0.7640\n",
            "Epoch 42/100 | Train Loss: 0.0037 | Val MRR: 0.8587 | R@1: 0.7760\n",
            "  üíæ New Best MRR: 0.8587 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0034 | Val MRR: 0.8611 | R@1: 0.7830\n",
            "  üíæ New Best MRR: 0.8611 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 44/100 | Train Loss: 0.0037 | Val MRR: 0.8513 | R@1: 0.7670\n",
            "Epoch 45/100 | Train Loss: 0.0036 | Val MRR: 0.8624 | R@1: 0.7830\n",
            "  üíæ New Best MRR: 0.8624 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 46/100 | Train Loss: 0.0034 | Val MRR: 0.8640 | R@1: 0.7800\n",
            "  üíæ New Best MRR: 0.8640 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 47/100 | Train Loss: 0.0035 | Val MRR: 0.8611 | R@1: 0.7810\n",
            "Epoch 48/100 | Train Loss: 0.0030 | Val MRR: 0.8587 | R@1: 0.7750\n",
            "Epoch 49/100 | Train Loss: 0.0030 | Val MRR: 0.8743 | R@1: 0.8010\n",
            "  üíæ New Best MRR: 0.8743 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 50/100 | Train Loss: 0.0032 | Val MRR: 0.8742 | R@1: 0.7980\n",
            "Epoch 51/100 | Train Loss: 0.0029 | Val MRR: 0.8735 | R@1: 0.7910\n",
            "Epoch 52/100 | Train Loss: 0.0031 | Val MRR: 0.8866 | R@1: 0.8160\n",
            "  üíæ New Best MRR: 0.8866 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 53/100 | Train Loss: 0.0027 | Val MRR: 0.8697 | R@1: 0.7900\n",
            "Epoch 54/100 | Train Loss: 0.0028 | Val MRR: 0.8756 | R@1: 0.7940\n",
            "Epoch 55/100 | Train Loss: 0.0027 | Val MRR: 0.8775 | R@1: 0.8020\n",
            "Epoch 56/100 | Train Loss: 0.0027 | Val MRR: 0.8792 | R@1: 0.8060\n",
            "Epoch 57/100 | Train Loss: 0.0023 | Val MRR: 0.8773 | R@1: 0.8000\n",
            "Epoch 58/100 | Train Loss: 0.0025 | Val MRR: 0.8926 | R@1: 0.8240\n",
            "  üíæ New Best MRR: 0.8926 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 59/100 | Train Loss: 0.0025 | Val MRR: 0.8953 | R@1: 0.8290\n",
            "  üíæ New Best MRR: 0.8953 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 60/100 | Train Loss: 0.0022 | Val MRR: 0.8929 | R@1: 0.8240\n",
            "Epoch 61/100 | Train Loss: 0.0023 | Val MRR: 0.8912 | R@1: 0.8200\n",
            "Epoch 62/100 | Train Loss: 0.0022 | Val MRR: 0.8940 | R@1: 0.8290\n",
            "Epoch 63/100 | Train Loss: 0.0022 | Val MRR: 0.8906 | R@1: 0.8210\n",
            "Epoch 64/100 | Train Loss: 0.0022 | Val MRR: 0.8989 | R@1: 0.8370\n",
            "  üíæ New Best MRR: 0.8989 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 65/100 | Train Loss: 0.0022 | Val MRR: 0.8976 | R@1: 0.8350\n",
            "Epoch 66/100 | Train Loss: 0.0022 | Val MRR: 0.8919 | R@1: 0.8250\n",
            "Epoch 67/100 | Train Loss: 0.0018 | Val MRR: 0.9033 | R@1: 0.8450\n",
            "  üíæ New Best MRR: 0.9033 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 68/100 | Train Loss: 0.0021 | Val MRR: 0.9023 | R@1: 0.8390\n",
            "Epoch 69/100 | Train Loss: 0.0020 | Val MRR: 0.9053 | R@1: 0.8460\n",
            "  üíæ New Best MRR: 0.9053 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 70/100 | Train Loss: 0.0018 | Val MRR: 0.9081 | R@1: 0.8500\n",
            "  üíæ New Best MRR: 0.9081 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 71/100 | Train Loss: 0.0018 | Val MRR: 0.9022 | R@1: 0.8400\n",
            "Epoch 72/100 | Train Loss: 0.0019 | Val MRR: 0.9012 | R@1: 0.8380\n",
            "Epoch 73/100 | Train Loss: 0.0016 | Val MRR: 0.9032 | R@1: 0.8400\n",
            "Epoch 74/100 | Train Loss: 0.0017 | Val MRR: 0.9084 | R@1: 0.8490\n",
            "  üíæ New Best MRR: 0.9084 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 75/100 | Train Loss: 0.0017 | Val MRR: 0.9043 | R@1: 0.8420\n",
            "Epoch 76/100 | Train Loss: 0.0017 | Val MRR: 0.9087 | R@1: 0.8480\n",
            "  üíæ New Best MRR: 0.9087 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 77/100 | Train Loss: 0.0017 | Val MRR: 0.9113 | R@1: 0.8540\n",
            "  üíæ New Best MRR: 0.9113 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 78/100 | Train Loss: 0.0016 | Val MRR: 0.9060 | R@1: 0.8460\n",
            "Epoch 79/100 | Train Loss: 0.0013 | Val MRR: 0.9163 | R@1: 0.8610\n",
            "  üíæ New Best MRR: 0.9163 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 80/100 | Train Loss: 0.0015 | Val MRR: 0.9080 | R@1: 0.8480\n",
            "Epoch 81/100 | Train Loss: 0.0015 | Val MRR: 0.9133 | R@1: 0.8560\n",
            "Epoch 82/100 | Train Loss: 0.0014 | Val MRR: 0.9102 | R@1: 0.8510\n",
            "Epoch 83/100 | Train Loss: 0.0013 | Val MRR: 0.9127 | R@1: 0.8550\n",
            "Epoch 84/100 | Train Loss: 0.0015 | Val MRR: 0.9119 | R@1: 0.8570\n",
            "Epoch 85/100 | Train Loss: 0.0015 | Val MRR: 0.9150 | R@1: 0.8630\n",
            "Epoch 86/100 | Train Loss: 0.0014 | Val MRR: 0.9118 | R@1: 0.8560\n",
            "Epoch 87/100 | Train Loss: 0.0013 | Val MRR: 0.9178 | R@1: 0.8660\n",
            "  üíæ New Best MRR: 0.9178 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 88/100 | Train Loss: 0.0013 | Val MRR: 0.9167 | R@1: 0.8630\n",
            "Epoch 89/100 | Train Loss: 0.0012 | Val MRR: 0.9164 | R@1: 0.8640\n",
            "Epoch 90/100 | Train Loss: 0.0014 | Val MRR: 0.9179 | R@1: 0.8650\n",
            "  üíæ New Best MRR: 0.9179 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 91/100 | Train Loss: 0.0013 | Val MRR: 0.9137 | R@1: 0.8570\n",
            "Epoch 92/100 | Train Loss: 0.0015 | Val MRR: 0.9163 | R@1: 0.8620\n",
            "Epoch 93/100 | Train Loss: 0.0014 | Val MRR: 0.9168 | R@1: 0.8630\n",
            "Epoch 94/100 | Train Loss: 0.0015 | Val MRR: 0.9176 | R@1: 0.8650\n",
            "Epoch 95/100 | Train Loss: 0.0014 | Val MRR: 0.9214 | R@1: 0.8710\n",
            "  üíæ New Best MRR: 0.9214 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 96/100 | Train Loss: 0.0014 | Val MRR: 0.9192 | R@1: 0.8670\n",
            "Epoch 97/100 | Train Loss: 0.0013 | Val MRR: 0.9179 | R@1: 0.8650\n",
            "Epoch 98/100 | Train Loss: 0.0014 | Val MRR: 0.9159 | R@1: 0.8620\n",
            "Epoch 99/100 | Train Loss: 0.0013 | Val MRR: 0.9195 | R@1: 0.8690\n",
            "Epoch 100/100 | Train Loss: 0.0011 | Val MRR: 0.9206 | R@1: 0.8700\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 265.0min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 2/9 : High Margin\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.25\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.25\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-11 22:05:20.027748: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-11 22:05:20.049118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768169120.074668   75815 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768169120.081771   75815 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768169120.100009   75815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768169120.100030   75815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768169120.100033   75815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768169120.100034   75815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 22:05:20.104960: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2591 | Val MRR: 0.1533 | R@1: 0.0640\n",
            "  üíæ New Best MRR: 0.1533 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.2123 | Val MRR: 0.3143 | R@1: 0.1700\n",
            "  üíæ New Best MRR: 0.3143 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.1301 | Val MRR: 0.4338 | R@1: 0.2760\n",
            "  üíæ New Best MRR: 0.4338 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0851 | Val MRR: 0.5312 | R@1: 0.3700\n",
            "  üíæ New Best MRR: 0.5312 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0639 | Val MRR: 0.5841 | R@1: 0.4310\n",
            "  üíæ New Best MRR: 0.5841 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0514 | Val MRR: 0.6211 | R@1: 0.4750\n",
            "  üíæ New Best MRR: 0.6211 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0420 | Val MRR: 0.6485 | R@1: 0.5020\n",
            "  üíæ New Best MRR: 0.6485 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0373 | Val MRR: 0.6880 | R@1: 0.5520\n",
            "  üíæ New Best MRR: 0.6880 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0328 | Val MRR: 0.7068 | R@1: 0.5660\n",
            "  üíæ New Best MRR: 0.7068 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0284 | Val MRR: 0.7070 | R@1: 0.5710\n",
            "  üíæ New Best MRR: 0.7070 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0257 | Val MRR: 0.7505 | R@1: 0.6310\n",
            "  üíæ New Best MRR: 0.7505 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0233 | Val MRR: 0.7495 | R@1: 0.6230\n",
            "Epoch 13/100 | Train Loss: 0.0207 | Val MRR: 0.7554 | R@1: 0.6460\n",
            "  üíæ New Best MRR: 0.7554 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0191 | Val MRR: 0.7700 | R@1: 0.6510\n",
            "  üíæ New Best MRR: 0.7700 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0176 | Val MRR: 0.7895 | R@1: 0.6740\n",
            "  üíæ New Best MRR: 0.7895 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0166 | Val MRR: 0.7911 | R@1: 0.6820\n",
            "  üíæ New Best MRR: 0.7911 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0162 | Val MRR: 0.7903 | R@1: 0.6790\n",
            "Epoch 18/100 | Train Loss: 0.0154 | Val MRR: 0.8012 | R@1: 0.6940\n",
            "  üíæ New Best MRR: 0.8012 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0141 | Val MRR: 0.8151 | R@1: 0.7180\n",
            "  üíæ New Best MRR: 0.8151 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0136 | Val MRR: 0.8159 | R@1: 0.7200\n",
            "  üíæ New Best MRR: 0.8159 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 21/100 | Train Loss: 0.0135 | Val MRR: 0.8243 | R@1: 0.7300\n",
            "  üíæ New Best MRR: 0.8243 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 22/100 | Train Loss: 0.0131 | Val MRR: 0.8253 | R@1: 0.7270\n",
            "  üíæ New Best MRR: 0.8253 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0127 | Val MRR: 0.8250 | R@1: 0.7300\n",
            "Epoch 24/100 | Train Loss: 0.0117 | Val MRR: 0.8218 | R@1: 0.7230\n",
            "Epoch 25/100 | Train Loss: 0.0115 | Val MRR: 0.8286 | R@1: 0.7340\n",
            "  üíæ New Best MRR: 0.8286 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 26/100 | Train Loss: 0.0112 | Val MRR: 0.8514 | R@1: 0.7620\n",
            "  üíæ New Best MRR: 0.8514 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 27/100 | Train Loss: 0.0108 | Val MRR: 0.8338 | R@1: 0.7430\n",
            "Epoch 28/100 | Train Loss: 0.0102 | Val MRR: 0.8432 | R@1: 0.7620\n",
            "Epoch 29/100 | Train Loss: 0.0098 | Val MRR: 0.8341 | R@1: 0.7510\n",
            "Epoch 30/100 | Train Loss: 0.0101 | Val MRR: 0.8420 | R@1: 0.7520\n",
            "Epoch 31/100 | Train Loss: 0.0097 | Val MRR: 0.8419 | R@1: 0.7490\n",
            "Epoch 32/100 | Train Loss: 0.0097 | Val MRR: 0.8470 | R@1: 0.7570\n",
            "Epoch 33/100 | Train Loss: 0.0089 | Val MRR: 0.8582 | R@1: 0.7770\n",
            "  üíæ New Best MRR: 0.8582 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 34/100 | Train Loss: 0.0091 | Val MRR: 0.8401 | R@1: 0.7520\n",
            "Epoch 35/100 | Train Loss: 0.0088 | Val MRR: 0.8499 | R@1: 0.7640\n",
            "Epoch 36/100 | Train Loss: 0.0082 | Val MRR: 0.8521 | R@1: 0.7690\n",
            "Epoch 37/100 | Train Loss: 0.0084 | Val MRR: 0.8516 | R@1: 0.7670\n",
            "Epoch 38/100 | Train Loss: 0.0081 | Val MRR: 0.8622 | R@1: 0.7790\n",
            "  üíæ New Best MRR: 0.8622 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 39/100 | Train Loss: 0.0082 | Val MRR: 0.8560 | R@1: 0.7760\n",
            "Epoch 40/100 | Train Loss: 0.0078 | Val MRR: 0.8598 | R@1: 0.7820\n",
            "Epoch 41/100 | Train Loss: 0.0077 | Val MRR: 0.8664 | R@1: 0.7910\n",
            "  üíæ New Best MRR: 0.8664 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 42/100 | Train Loss: 0.0073 | Val MRR: 0.8725 | R@1: 0.7950\n",
            "  üíæ New Best MRR: 0.8725 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0073 | Val MRR: 0.8676 | R@1: 0.7890\n",
            "Epoch 44/100 | Train Loss: 0.0073 | Val MRR: 0.8612 | R@1: 0.7860\n",
            "Epoch 45/100 | Train Loss: 0.0069 | Val MRR: 0.8745 | R@1: 0.8010\n",
            "  üíæ New Best MRR: 0.8745 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 46/100 | Train Loss: 0.0070 | Val MRR: 0.8795 | R@1: 0.8040\n",
            "  üíæ New Best MRR: 0.8795 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 47/100 | Train Loss: 0.0060 | Val MRR: 0.8745 | R@1: 0.7940\n",
            "Epoch 48/100 | Train Loss: 0.0062 | Val MRR: 0.8858 | R@1: 0.8130\n",
            "  üíæ New Best MRR: 0.8858 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 49/100 | Train Loss: 0.0059 | Val MRR: 0.8834 | R@1: 0.8120\n",
            "Epoch 50/100 | Train Loss: 0.0056 | Val MRR: 0.8764 | R@1: 0.7990\n",
            "Epoch 51/100 | Train Loss: 0.0055 | Val MRR: 0.8762 | R@1: 0.8010\n",
            "Epoch 52/100 | Train Loss: 0.0055 | Val MRR: 0.8906 | R@1: 0.8200\n",
            "  üíæ New Best MRR: 0.8906 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 53/100 | Train Loss: 0.0051 | Val MRR: 0.8853 | R@1: 0.8140\n",
            "Epoch 54/100 | Train Loss: 0.0050 | Val MRR: 0.8855 | R@1: 0.8150\n",
            "Epoch 55/100 | Train Loss: 0.0050 | Val MRR: 0.8941 | R@1: 0.8270\n",
            "  üíæ New Best MRR: 0.8941 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 56/100 | Train Loss: 0.0054 | Val MRR: 0.8938 | R@1: 0.8300\n",
            "Epoch 57/100 | Train Loss: 0.0049 | Val MRR: 0.8938 | R@1: 0.8270\n",
            "Epoch 58/100 | Train Loss: 0.0050 | Val MRR: 0.8939 | R@1: 0.8270\n",
            "Epoch 59/100 | Train Loss: 0.0046 | Val MRR: 0.8999 | R@1: 0.8370\n",
            "  üíæ New Best MRR: 0.8999 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 60/100 | Train Loss: 0.0047 | Val MRR: 0.8972 | R@1: 0.8340\n",
            "Epoch 61/100 | Train Loss: 0.0044 | Val MRR: 0.8992 | R@1: 0.8410\n",
            "Epoch 62/100 | Train Loss: 0.0044 | Val MRR: 0.9007 | R@1: 0.8430\n",
            "  üíæ New Best MRR: 0.9007 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 63/100 | Train Loss: 0.0044 | Val MRR: 0.8972 | R@1: 0.8340\n",
            "Epoch 64/100 | Train Loss: 0.0043 | Val MRR: 0.8967 | R@1: 0.8290\n",
            "Epoch 65/100 | Train Loss: 0.0042 | Val MRR: 0.8995 | R@1: 0.8340\n",
            "Epoch 66/100 | Train Loss: 0.0042 | Val MRR: 0.9005 | R@1: 0.8400\n",
            "Epoch 67/100 | Train Loss: 0.0043 | Val MRR: 0.9075 | R@1: 0.8500\n",
            "  üíæ New Best MRR: 0.9075 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 68/100 | Train Loss: 0.0038 | Val MRR: 0.9084 | R@1: 0.8530\n",
            "  üíæ New Best MRR: 0.9084 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 69/100 | Train Loss: 0.0035 | Val MRR: 0.9046 | R@1: 0.8450\n",
            "Epoch 70/100 | Train Loss: 0.0038 | Val MRR: 0.9073 | R@1: 0.8520\n",
            "Epoch 71/100 | Train Loss: 0.0041 | Val MRR: 0.9068 | R@1: 0.8500\n",
            "Epoch 72/100 | Train Loss: 0.0036 | Val MRR: 0.9012 | R@1: 0.8410\n",
            "Epoch 73/100 | Train Loss: 0.0035 | Val MRR: 0.9111 | R@1: 0.8570\n",
            "  üíæ New Best MRR: 0.9111 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 74/100 | Train Loss: 0.0036 | Val MRR: 0.9096 | R@1: 0.8530\n",
            "Epoch 75/100 | Train Loss: 0.0033 | Val MRR: 0.9086 | R@1: 0.8550\n",
            "Epoch 76/100 | Train Loss: 0.0037 | Val MRR: 0.9151 | R@1: 0.8650\n",
            "  üíæ New Best MRR: 0.9151 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 77/100 | Train Loss: 0.0036 | Val MRR: 0.9142 | R@1: 0.8640\n",
            "Epoch 78/100 | Train Loss: 0.0031 | Val MRR: 0.9123 | R@1: 0.8620\n",
            "Epoch 79/100 | Train Loss: 0.0032 | Val MRR: 0.9144 | R@1: 0.8640\n",
            "Epoch 80/100 | Train Loss: 0.0030 | Val MRR: 0.9163 | R@1: 0.8680\n",
            "  üíæ New Best MRR: 0.9163 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 81/100 | Train Loss: 0.0033 | Val MRR: 0.9130 | R@1: 0.8590\n",
            "Epoch 82/100 | Train Loss: 0.0030 | Val MRR: 0.9103 | R@1: 0.8570\n",
            "Epoch 83/100 | Train Loss: 0.0033 | Val MRR: 0.9159 | R@1: 0.8640\n",
            "Epoch 84/100 | Train Loss: 0.0030 | Val MRR: 0.9155 | R@1: 0.8640\n",
            "Epoch 85/100 | Train Loss: 0.0029 | Val MRR: 0.9195 | R@1: 0.8710\n",
            "  üíæ New Best MRR: 0.9195 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 86/100 | Train Loss: 0.0031 | Val MRR: 0.9179 | R@1: 0.8690\n",
            "Epoch 87/100 | Train Loss: 0.0032 | Val MRR: 0.9167 | R@1: 0.8660\n",
            "Epoch 88/100 | Train Loss: 0.0031 | Val MRR: 0.9198 | R@1: 0.8730\n",
            "  üíæ New Best MRR: 0.9198 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 89/100 | Train Loss: 0.0031 | Val MRR: 0.9148 | R@1: 0.8630\n",
            "Epoch 90/100 | Train Loss: 0.0031 | Val MRR: 0.9176 | R@1: 0.8670\n",
            "Epoch 91/100 | Train Loss: 0.0028 | Val MRR: 0.9169 | R@1: 0.8650\n",
            "Epoch 92/100 | Train Loss: 0.0028 | Val MRR: 0.9202 | R@1: 0.8730\n",
            "  üíæ New Best MRR: 0.9202 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 93/100 | Train Loss: 0.0030 | Val MRR: 0.9206 | R@1: 0.8740\n",
            "  üíæ New Best MRR: 0.9206 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 94/100 | Train Loss: 0.0030 | Val MRR: 0.9147 | R@1: 0.8620\n",
            "Epoch 95/100 | Train Loss: 0.0032 | Val MRR: 0.9244 | R@1: 0.8790\n",
            "  üíæ New Best MRR: 0.9244 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt\n",
            "Epoch 96/100 | Train Loss: 0.0029 | Val MRR: 0.9231 | R@1: 0.8770\n",
            "Epoch 97/100 | Train Loss: 0.0030 | Val MRR: 0.9166 | R@1: 0.8660\n",
            "Epoch 98/100 | Train Loss: 0.0029 | Val MRR: 0.9206 | R@1: 0.8720\n",
            "Epoch 99/100 | Train Loss: 0.0026 | Val MRR: 0.9181 | R@1: 0.8690\n",
            "Epoch 100/100 | Train Loss: 0.0029 | Val MRR: 0.9171 | R@1: 0.8650\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.25_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 538.6min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 3/9 : Low LR GNN\n",
            "================================================================================\n",
            "LR GNN      : 0.0005\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0005\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-12 02:38:55.436285: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-12 02:38:55.457167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768185535.483298  153101 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768185535.490630  153101 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768185535.509442  153101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768185535.509481  153101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768185535.509485  153101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768185535.509488  153101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-12 02:38:55.514507: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2126 | Val MRR: 0.1259 | R@1: 0.0460\n",
            "  üíæ New Best MRR: 0.1259 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1806 | Val MRR: 0.2724 | R@1: 0.1420\n",
            "  üíæ New Best MRR: 0.2724 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.1110 | Val MRR: 0.4236 | R@1: 0.2620\n",
            "  üíæ New Best MRR: 0.4236 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0673 | Val MRR: 0.5226 | R@1: 0.3600\n",
            "  üíæ New Best MRR: 0.5226 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0484 | Val MRR: 0.5949 | R@1: 0.4360\n",
            "  üíæ New Best MRR: 0.5949 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0374 | Val MRR: 0.6208 | R@1: 0.4630\n",
            "  üíæ New Best MRR: 0.6208 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0304 | Val MRR: 0.6595 | R@1: 0.5120\n",
            "  üíæ New Best MRR: 0.6595 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0257 | Val MRR: 0.6986 | R@1: 0.5630\n",
            "  üíæ New Best MRR: 0.6986 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0222 | Val MRR: 0.7020 | R@1: 0.5620\n",
            "  üíæ New Best MRR: 0.7020 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0194 | Val MRR: 0.7176 | R@1: 0.5830\n",
            "  üíæ New Best MRR: 0.7176 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0168 | Val MRR: 0.7219 | R@1: 0.5840\n",
            "  üíæ New Best MRR: 0.7219 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0151 | Val MRR: 0.7424 | R@1: 0.6150\n",
            "  üíæ New Best MRR: 0.7424 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0141 | Val MRR: 0.7775 | R@1: 0.6630\n",
            "  üíæ New Best MRR: 0.7775 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0123 | Val MRR: 0.7840 | R@1: 0.6710\n",
            "  üíæ New Best MRR: 0.7840 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0117 | Val MRR: 0.7944 | R@1: 0.6790\n",
            "  üíæ New Best MRR: 0.7944 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0115 | Val MRR: 0.7753 | R@1: 0.6650\n",
            "Epoch 17/100 | Train Loss: 0.0104 | Val MRR: 0.8101 | R@1: 0.7100\n",
            "  üíæ New Best MRR: 0.8101 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 18/100 | Train Loss: 0.0099 | Val MRR: 0.7854 | R@1: 0.6700\n",
            "Epoch 19/100 | Train Loss: 0.0101 | Val MRR: 0.8276 | R@1: 0.7320\n",
            "  üíæ New Best MRR: 0.8276 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0092 | Val MRR: 0.8127 | R@1: 0.7070\n",
            "Epoch 21/100 | Train Loss: 0.0083 | Val MRR: 0.8165 | R@1: 0.7130\n",
            "Epoch 22/100 | Train Loss: 0.0083 | Val MRR: 0.8225 | R@1: 0.7250\n",
            "Epoch 23/100 | Train Loss: 0.0081 | Val MRR: 0.8033 | R@1: 0.6970\n",
            "Epoch 24/100 | Train Loss: 0.0080 | Val MRR: 0.8459 | R@1: 0.7590\n",
            "  üíæ New Best MRR: 0.8459 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0074 | Val MRR: 0.8371 | R@1: 0.7460\n",
            "Epoch 26/100 | Train Loss: 0.0073 | Val MRR: 0.8419 | R@1: 0.7480\n",
            "Epoch 27/100 | Train Loss: 0.0072 | Val MRR: 0.8429 | R@1: 0.7480\n",
            "Epoch 28/100 | Train Loss: 0.0069 | Val MRR: 0.8460 | R@1: 0.7570\n",
            "  üíæ New Best MRR: 0.8460 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 29/100 | Train Loss: 0.0064 | Val MRR: 0.8402 | R@1: 0.7560\n",
            "Epoch 30/100 | Train Loss: 0.0064 | Val MRR: 0.8468 | R@1: 0.7570\n",
            "  üíæ New Best MRR: 0.8468 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 31/100 | Train Loss: 0.0061 | Val MRR: 0.8558 | R@1: 0.7760\n",
            "  üíæ New Best MRR: 0.8558 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 32/100 | Train Loss: 0.0058 | Val MRR: 0.8559 | R@1: 0.7750\n",
            "  üíæ New Best MRR: 0.8559 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 33/100 | Train Loss: 0.0060 | Val MRR: 0.8610 | R@1: 0.7780\n",
            "  üíæ New Best MRR: 0.8610 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 34/100 | Train Loss: 0.0055 | Val MRR: 0.8582 | R@1: 0.7750\n",
            "Epoch 35/100 | Train Loss: 0.0057 | Val MRR: 0.8555 | R@1: 0.7700\n",
            "Epoch 36/100 | Train Loss: 0.0052 | Val MRR: 0.8633 | R@1: 0.7780\n",
            "  üíæ New Best MRR: 0.8633 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 37/100 | Train Loss: 0.0053 | Val MRR: 0.8690 | R@1: 0.7860\n",
            "  üíæ New Best MRR: 0.8690 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 38/100 | Train Loss: 0.0049 | Val MRR: 0.8722 | R@1: 0.7930\n",
            "  üíæ New Best MRR: 0.8722 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 39/100 | Train Loss: 0.0052 | Val MRR: 0.8735 | R@1: 0.7980\n",
            "  üíæ New Best MRR: 0.8735 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 40/100 | Train Loss: 0.0048 | Val MRR: 0.8672 | R@1: 0.7870\n",
            "Epoch 41/100 | Train Loss: 0.0046 | Val MRR: 0.8750 | R@1: 0.8020\n",
            "  üíæ New Best MRR: 0.8750 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 42/100 | Train Loss: 0.0044 | Val MRR: 0.8772 | R@1: 0.8050\n",
            "  üíæ New Best MRR: 0.8772 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0045 | Val MRR: 0.8746 | R@1: 0.7990\n",
            "Epoch 44/100 | Train Loss: 0.0042 | Val MRR: 0.8750 | R@1: 0.8020\n",
            "Epoch 45/100 | Train Loss: 0.0040 | Val MRR: 0.8832 | R@1: 0.8100\n",
            "  üíæ New Best MRR: 0.8832 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 46/100 | Train Loss: 0.0040 | Val MRR: 0.8870 | R@1: 0.8140\n",
            "  üíæ New Best MRR: 0.8870 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 47/100 | Train Loss: 0.0040 | Val MRR: 0.8870 | R@1: 0.8180\n",
            "Epoch 48/100 | Train Loss: 0.0040 | Val MRR: 0.8837 | R@1: 0.8140\n",
            "Epoch 49/100 | Train Loss: 0.0039 | Val MRR: 0.8745 | R@1: 0.8010\n",
            "Epoch 50/100 | Train Loss: 0.0036 | Val MRR: 0.8928 | R@1: 0.8260\n",
            "  üíæ New Best MRR: 0.8928 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 51/100 | Train Loss: 0.0036 | Val MRR: 0.8863 | R@1: 0.8150\n",
            "Epoch 52/100 | Train Loss: 0.0036 | Val MRR: 0.8828 | R@1: 0.8080\n",
            "Epoch 53/100 | Train Loss: 0.0032 | Val MRR: 0.8975 | R@1: 0.8310\n",
            "  üíæ New Best MRR: 0.8975 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 54/100 | Train Loss: 0.0033 | Val MRR: 0.9036 | R@1: 0.8470\n",
            "  üíæ New Best MRR: 0.9036 | Saved: dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 55/100 | Train Loss: 0.0035 | Val MRR: 0.9011 | R@1: 0.8420\n",
            "Epoch 56/100 | Train Loss: 0.0032 | Val MRR: 0.8904 | R@1: 0.8240\n",
            "Epoch 57/100 | Train Loss: 0.0032 | Val MRR: 0.8973 | R@1: 0.8310\n",
            "Epoch 58/100 | Train Loss: 0.0030 | Val MRR: 0.8973 | R@1: 0.8330\n",
            "Epoch 59/100 | Train Loss: 0.0029 | Val MRR: 0.9009 | R@1: 0.8380\n",
            "Epoch 60/100 | Train Loss: 0.0029 | Val MRR: 0.8983 | R@1: 0.8350\n",
            "Epoch 61/100 | Train Loss: 0.0030 | Val MRR: 0.8925 | R@1: 0.8290\n",
            "Epoch 62/100 | Train Loss: 0.0026 | Val MRR: 0.9015 | R@1: 0.8410\n",
            "Epoch 63/100 | Train Loss: 0.0027 | Val MRR: 0.9021 | R@1: 0.8380\n",
            "Epoch 64/100 | Train Loss: 0.0027 | Val MRR: 0.9012 | R@1: 0.8380\n",
            "üõë Early stopping\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0005_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 717.0min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 4/9 : High LR GNN\n",
            "================================================================================\n",
            "LR GNN      : 0.001\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.001\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-12 05:37:24.017414: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-12 05:37:24.040556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768196244.067002  203461 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768196244.074210  203461 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768196244.093719  203461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768196244.093743  203461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768196244.093746  203461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768196244.093748  203461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-12 05:37:24.098970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2064 | Val MRR: 0.1935 | R@1: 0.0930\n",
            "  üíæ New Best MRR: 0.1935 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1550 | Val MRR: 0.3299 | R@1: 0.1840\n",
            "  üíæ New Best MRR: 0.3299 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.0912 | Val MRR: 0.4639 | R@1: 0.3040\n",
            "  üíæ New Best MRR: 0.4639 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0602 | Val MRR: 0.5280 | R@1: 0.3630\n",
            "  üíæ New Best MRR: 0.5280 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0459 | Val MRR: 0.6068 | R@1: 0.4600\n",
            "  üíæ New Best MRR: 0.6068 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0376 | Val MRR: 0.6328 | R@1: 0.4880\n",
            "  üíæ New Best MRR: 0.6328 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0325 | Val MRR: 0.6364 | R@1: 0.4940\n",
            "  üíæ New Best MRR: 0.6364 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0272 | Val MRR: 0.6661 | R@1: 0.5230\n",
            "  üíæ New Best MRR: 0.6661 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0239 | Val MRR: 0.6991 | R@1: 0.5700\n",
            "  üíæ New Best MRR: 0.6991 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0210 | Val MRR: 0.7125 | R@1: 0.5740\n",
            "  üíæ New Best MRR: 0.7125 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0187 | Val MRR: 0.7296 | R@1: 0.5990\n",
            "  üíæ New Best MRR: 0.7296 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0168 | Val MRR: 0.7423 | R@1: 0.6190\n",
            "  üíæ New Best MRR: 0.7423 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0152 | Val MRR: 0.7567 | R@1: 0.6390\n",
            "  üíæ New Best MRR: 0.7567 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0145 | Val MRR: 0.7391 | R@1: 0.6070\n",
            "Epoch 15/100 | Train Loss: 0.0140 | Val MRR: 0.7704 | R@1: 0.6520\n",
            "  üíæ New Best MRR: 0.7704 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0135 | Val MRR: 0.7748 | R@1: 0.6520\n",
            "  üíæ New Best MRR: 0.7748 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0131 | Val MRR: 0.7761 | R@1: 0.6600\n",
            "  üíæ New Best MRR: 0.7761 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 18/100 | Train Loss: 0.0123 | Val MRR: 0.7820 | R@1: 0.6650\n",
            "  üíæ New Best MRR: 0.7820 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0122 | Val MRR: 0.7856 | R@1: 0.6730\n",
            "  üíæ New Best MRR: 0.7856 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0120 | Val MRR: 0.7889 | R@1: 0.6720\n",
            "  üíæ New Best MRR: 0.7889 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 21/100 | Train Loss: 0.0116 | Val MRR: 0.7961 | R@1: 0.6850\n",
            "  üíæ New Best MRR: 0.7961 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 22/100 | Train Loss: 0.0107 | Val MRR: 0.8049 | R@1: 0.6990\n",
            "  üíæ New Best MRR: 0.8049 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0098 | Val MRR: 0.8075 | R@1: 0.7030\n",
            "  üíæ New Best MRR: 0.8075 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 24/100 | Train Loss: 0.0099 | Val MRR: 0.7739 | R@1: 0.6640\n",
            "Epoch 25/100 | Train Loss: 0.0096 | Val MRR: 0.8018 | R@1: 0.6930\n",
            "Epoch 26/100 | Train Loss: 0.0097 | Val MRR: 0.8234 | R@1: 0.7270\n",
            "  üíæ New Best MRR: 0.8234 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 27/100 | Train Loss: 0.0095 | Val MRR: 0.8318 | R@1: 0.7400\n",
            "  üíæ New Best MRR: 0.8318 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0081 | Val MRR: 0.8357 | R@1: 0.7410\n",
            "  üíæ New Best MRR: 0.8357 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 29/100 | Train Loss: 0.0082 | Val MRR: 0.8301 | R@1: 0.7360\n",
            "Epoch 30/100 | Train Loss: 0.0085 | Val MRR: 0.8373 | R@1: 0.7440\n",
            "  üíæ New Best MRR: 0.8373 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 31/100 | Train Loss: 0.0080 | Val MRR: 0.8390 | R@1: 0.7530\n",
            "  üíæ New Best MRR: 0.8390 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 32/100 | Train Loss: 0.0072 | Val MRR: 0.8427 | R@1: 0.7540\n",
            "  üíæ New Best MRR: 0.8427 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 33/100 | Train Loss: 0.0069 | Val MRR: 0.8474 | R@1: 0.7620\n",
            "  üíæ New Best MRR: 0.8474 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 34/100 | Train Loss: 0.0071 | Val MRR: 0.8579 | R@1: 0.7740\n",
            "  üíæ New Best MRR: 0.8579 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 35/100 | Train Loss: 0.0065 | Val MRR: 0.8577 | R@1: 0.7750\n",
            "Epoch 36/100 | Train Loss: 0.0063 | Val MRR: 0.8542 | R@1: 0.7710\n",
            "Epoch 37/100 | Train Loss: 0.0061 | Val MRR: 0.8510 | R@1: 0.7660\n",
            "Epoch 38/100 | Train Loss: 0.0063 | Val MRR: 0.8577 | R@1: 0.7720\n",
            "Epoch 39/100 | Train Loss: 0.0064 | Val MRR: 0.8449 | R@1: 0.7590\n",
            "Epoch 40/100 | Train Loss: 0.0070 | Val MRR: 0.8570 | R@1: 0.7730\n",
            "Epoch 41/100 | Train Loss: 0.0060 | Val MRR: 0.8430 | R@1: 0.7480\n",
            "Epoch 42/100 | Train Loss: 0.0058 | Val MRR: 0.8648 | R@1: 0.7830\n",
            "  üíæ New Best MRR: 0.8648 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0055 | Val MRR: 0.8651 | R@1: 0.7850\n",
            "  üíæ New Best MRR: 0.8651 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 44/100 | Train Loss: 0.0052 | Val MRR: 0.8637 | R@1: 0.7830\n",
            "Epoch 45/100 | Train Loss: 0.0049 | Val MRR: 0.8567 | R@1: 0.7730\n",
            "Epoch 46/100 | Train Loss: 0.0046 | Val MRR: 0.8660 | R@1: 0.7860\n",
            "  üíæ New Best MRR: 0.8660 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 47/100 | Train Loss: 0.0050 | Val MRR: 0.8692 | R@1: 0.7940\n",
            "  üíæ New Best MRR: 0.8692 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 48/100 | Train Loss: 0.0051 | Val MRR: 0.8725 | R@1: 0.7950\n",
            "  üíæ New Best MRR: 0.8725 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 49/100 | Train Loss: 0.0049 | Val MRR: 0.8770 | R@1: 0.8050\n",
            "  üíæ New Best MRR: 0.8770 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 50/100 | Train Loss: 0.0045 | Val MRR: 0.8667 | R@1: 0.7900\n",
            "Epoch 51/100 | Train Loss: 0.0045 | Val MRR: 0.8731 | R@1: 0.7980\n",
            "Epoch 52/100 | Train Loss: 0.0044 | Val MRR: 0.8919 | R@1: 0.8280\n",
            "  üíæ New Best MRR: 0.8919 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 53/100 | Train Loss: 0.0043 | Val MRR: 0.8807 | R@1: 0.8100\n",
            "Epoch 54/100 | Train Loss: 0.0042 | Val MRR: 0.8735 | R@1: 0.7980\n",
            "Epoch 55/100 | Train Loss: 0.0040 | Val MRR: 0.8834 | R@1: 0.8130\n",
            "Epoch 56/100 | Train Loss: 0.0038 | Val MRR: 0.8875 | R@1: 0.8210\n",
            "Epoch 57/100 | Train Loss: 0.0034 | Val MRR: 0.8825 | R@1: 0.8140\n",
            "Epoch 58/100 | Train Loss: 0.0039 | Val MRR: 0.8914 | R@1: 0.8220\n",
            "Epoch 59/100 | Train Loss: 0.0035 | Val MRR: 0.8897 | R@1: 0.8210\n",
            "Epoch 60/100 | Train Loss: 0.0039 | Val MRR: 0.8894 | R@1: 0.8210\n",
            "Epoch 61/100 | Train Loss: 0.0036 | Val MRR: 0.8906 | R@1: 0.8250\n",
            "Epoch 62/100 | Train Loss: 0.0036 | Val MRR: 0.8977 | R@1: 0.8380\n",
            "  üíæ New Best MRR: 0.8977 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 63/100 | Train Loss: 0.0033 | Val MRR: 0.8934 | R@1: 0.8310\n",
            "Epoch 64/100 | Train Loss: 0.0033 | Val MRR: 0.9058 | R@1: 0.8510\n",
            "  üíæ New Best MRR: 0.9058 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 65/100 | Train Loss: 0.0032 | Val MRR: 0.8937 | R@1: 0.8260\n",
            "Epoch 66/100 | Train Loss: 0.0031 | Val MRR: 0.8963 | R@1: 0.8320\n",
            "Epoch 67/100 | Train Loss: 0.0029 | Val MRR: 0.8970 | R@1: 0.8360\n",
            "Epoch 68/100 | Train Loss: 0.0033 | Val MRR: 0.9015 | R@1: 0.8420\n",
            "Epoch 69/100 | Train Loss: 0.0031 | Val MRR: 0.8986 | R@1: 0.8360\n",
            "Epoch 70/100 | Train Loss: 0.0028 | Val MRR: 0.9039 | R@1: 0.8490\n",
            "Epoch 71/100 | Train Loss: 0.0029 | Val MRR: 0.9046 | R@1: 0.8500\n",
            "Epoch 72/100 | Train Loss: 0.0025 | Val MRR: 0.9048 | R@1: 0.8440\n",
            "Epoch 73/100 | Train Loss: 0.0028 | Val MRR: 0.9068 | R@1: 0.8500\n",
            "  üíæ New Best MRR: 0.9068 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 74/100 | Train Loss: 0.0027 | Val MRR: 0.9078 | R@1: 0.8510\n",
            "  üíæ New Best MRR: 0.9078 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 75/100 | Train Loss: 0.0028 | Val MRR: 0.8984 | R@1: 0.8350\n",
            "Epoch 76/100 | Train Loss: 0.0028 | Val MRR: 0.9038 | R@1: 0.8430\n",
            "Epoch 77/100 | Train Loss: 0.0024 | Val MRR: 0.9058 | R@1: 0.8490\n",
            "Epoch 78/100 | Train Loss: 0.0027 | Val MRR: 0.9056 | R@1: 0.8440\n",
            "Epoch 79/100 | Train Loss: 0.0024 | Val MRR: 0.9088 | R@1: 0.8490\n",
            "  üíæ New Best MRR: 0.9088 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 80/100 | Train Loss: 0.0023 | Val MRR: 0.9084 | R@1: 0.8490\n",
            "Epoch 81/100 | Train Loss: 0.0024 | Val MRR: 0.9085 | R@1: 0.8520\n",
            "Epoch 82/100 | Train Loss: 0.0022 | Val MRR: 0.9111 | R@1: 0.8530\n",
            "  üíæ New Best MRR: 0.9111 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 83/100 | Train Loss: 0.0022 | Val MRR: 0.9119 | R@1: 0.8540\n",
            "  üíæ New Best MRR: 0.9119 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 84/100 | Train Loss: 0.0024 | Val MRR: 0.9122 | R@1: 0.8550\n",
            "  üíæ New Best MRR: 0.9122 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 85/100 | Train Loss: 0.0022 | Val MRR: 0.9103 | R@1: 0.8550\n",
            "Epoch 86/100 | Train Loss: 0.0023 | Val MRR: 0.9120 | R@1: 0.8570\n",
            "Epoch 87/100 | Train Loss: 0.0022 | Val MRR: 0.9162 | R@1: 0.8640\n",
            "  üíæ New Best MRR: 0.9162 | Saved: dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "Epoch 88/100 | Train Loss: 0.0021 | Val MRR: 0.9158 | R@1: 0.8650\n",
            "Epoch 89/100 | Train Loss: 0.0022 | Val MRR: 0.9122 | R@1: 0.8560\n",
            "Epoch 90/100 | Train Loss: 0.0021 | Val MRR: 0.9133 | R@1: 0.8580\n",
            "Epoch 91/100 | Train Loss: 0.0021 | Val MRR: 0.9124 | R@1: 0.8570\n",
            "Epoch 92/100 | Train Loss: 0.0021 | Val MRR: 0.9128 | R@1: 0.8600\n",
            "Epoch 93/100 | Train Loss: 0.0022 | Val MRR: 0.9144 | R@1: 0.8600\n",
            "Epoch 94/100 | Train Loss: 0.0022 | Val MRR: 0.9130 | R@1: 0.8590\n",
            "Epoch 95/100 | Train Loss: 0.0021 | Val MRR: 0.9121 | R@1: 0.8560\n",
            "Epoch 96/100 | Train Loss: 0.0022 | Val MRR: 0.9161 | R@1: 0.8630\n",
            "Epoch 97/100 | Train Loss: 0.0019 | Val MRR: 0.9157 | R@1: 0.8640\n",
            "üõë Early stopping\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.001_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 989.0min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 5/9 : Aggressive Full\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 5e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0005\n",
            "Margin      : 0.25\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 5e-05\n",
            "Weight Decay: 0.0005\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.25\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-627966316.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0moutput_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0moutput_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**‚ö†Ô∏èLancer en local ensuite le run de : *good_conversion_dual.py* pour que le fichier .pt g√©n√©r√© soit compatible avec le pipeline de RAPH**"
      ],
      "metadata": {
        "id": "b17_TPKGZkah"
      },
      "id": "b17_TPKGZkah"
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import time\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# =========================================================\n",
        "# 0. CONFIGURATION DRIVE & DOSSIERS\n",
        "# =========================================================\n",
        "print(\"üîÑ Connexion au Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# D√©finissez ici le dossier de VOTRE Drive o√π vous voulez stocker les r√©sultats\n",
        "# (Le script cr√©era le dossier s'il n'existe pas)\n",
        "DRIVE_OUTPUT_DIR = Path(\"/content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder\")\n",
        "DRIVE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Dossier de sauvegarde s√©curis√© : {DRIVE_OUTPUT_DIR}\")\n",
        "\n",
        "# Le CSV de r√©sultats sera mis √† jour en direct sur le Drive\n",
        "RESULTS_CSV = DRIVE_OUTPUT_DIR / \"dual_encoder_results.csv\"\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION DES EXP√âRIENCES\n",
        "# =========================================================\n",
        "EXPERIMENTS = [\n",
        "    # === GROUP 1 : LR BERT SWEEP (ROI ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    ## d√©j√† fait #{\"lr_gnn\": 8e-4, \"lr_bert\": 1e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Low LR BERT\"},\n",
        "    ## d√©j√† fait #{\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Baseline BERT\"},\n",
        "    ##√† run ##{\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"High LR BERT\"},\n",
        "\n",
        "    # === GROUP 2 : FREEZE STRATEGIES (ROI ‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 6, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Freeze 6 Layers\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 6, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Freeze 6 + High LR\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 9, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Freeze 9 Layers\"},\n",
        "\n",
        "    # === GROUP 3 : WEIGHT DECAY (ROI ‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-5, \"margin\": 0.2, \"name\": \"Low WD\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 5e-4, \"margin\": 0.2, \"name\": \"Medium WD\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-3, \"margin\": 0.2, \"name\": \"High WD\"},\n",
        "\n",
        "    # === GROUP 4 : MARGIN (ROI ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.15, \"name\": \"Low Margin\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.25, \"name\": \"High Margin\"},\n",
        "\n",
        "    # === GROUP 5 : LR GNN (ROI ‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 5e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"Low LR GNN\"},\n",
        "    {\"lr_gnn\": 1e-3, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"name\": \"High LR GNN\"},\n",
        "\n",
        "    # === GROUP 6 : COMBINATIONS (ROI ‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 0, \"wd\": 5e-4, \"margin\": 0.25, \"name\": \"Aggressive Full\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 5e-5, \"freeze\": 6, \"wd\": 1e-4, \"margin\": 0.25, \"name\": \"Aggressive Freeze\"},\n",
        "    {\"lr_gnn\": 5e-4, \"lr_bert\": 1e-5, \"freeze\": 0, \"wd\": 1e-5, \"margin\": 0.15, \"name\": \"Conservative Full\"},\n",
        "\n",
        "    # === BATCH SIZE VARIATIONS (ROI ‚≠ê‚≠ê‚≠ê‚≠ê) ===\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"batch_size\": 32, \"grad_accum\": 4, \"name\": \"Batch 128 (32x4)\"},\n",
        "    {\"lr_gnn\": 8e-4, \"lr_bert\": 3e-5, \"freeze\": 0, \"wd\": 1e-4, \"margin\": 0.2, \"batch_size\": 8, \"grad_accum\": 16, \"name\": \"Batch 128 (8x16)\"},\n",
        "]\n",
        "\n",
        "# Param√®tres fixes\n",
        "FIXED_PARAMS = {\n",
        "    \"data_dir\": \"data_baseline/data\",\n",
        "    \"model_name\": \"recobo/chemical-bert-uncased\",\n",
        "    \"batch_size\": 16,\n",
        "    \"grad_accum\": 8,\n",
        "    \"epochs\": 100,\n",
        "    \"patience\": 10,\n",
        "}\n",
        "\n",
        "# Chemin du script d'entra√Ænement (local)\n",
        "SCRIPT_PATH = \"data_baseline/train_dual_encoder_optimized.py\"\n",
        "\n",
        "# =========================================================\n",
        "# AFFICHAGE R√âCAPITULATIF\n",
        "# =========================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"üöÄ DUAL ENCODER - GRID SEARCH AUTOMATIQUE (DRIVE SAVE MODE)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Dossier de sortie    : {DRIVE_OUTPUT_DIR}\")\n",
        "print(f\"Fichier de r√©sultats : {RESULTS_CSV}\")\n",
        "print(f\"Nombre d'exp√©riences : {len(EXPERIMENTS)}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "input(\"\\n‚ö†Ô∏è  Appuie sur ENTER pour lancer (ou Ctrl+C pour annuler)...\\n\")\n",
        "\n",
        "# Charge les r√©sultats existants si on reprend le run\n",
        "results = []\n",
        "if RESULTS_CSV.exists():\n",
        "    print(f\"üîÑ Reprise du fichier existant : {RESULTS_CSV}\")\n",
        "    try:\n",
        "        existing_df = pd.read_csv(RESULTS_CSV)\n",
        "        results = existing_df.to_dict('records')\n",
        "        # On saute les runs d√©j√† faits ? (Optionnel, ici on refait tout par s√©curit√© ou on peut filtrer)\n",
        "        # runs_done = [r['Name'] for r in results]\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Impossible de lire le fichier existant, on repart √† z√©ro.\")\n",
        "\n",
        "total_start = datetime.now()\n",
        "\n",
        "for i, exp in enumerate(EXPERIMENTS, 1):\n",
        "\n",
        "    # V√©rifie si l'exp√©rience a d√©j√† √©t√© faite (Optionnel)\n",
        "    # if exp['name'] in [r.get('Name') for r in results]:\n",
        "    #     print(f\"‚è© Run {i} ({exp['name']}) d√©j√† fait. Skipping...\")\n",
        "    #     continue\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"RUN {i}/{len(EXPERIMENTS)} : {exp['name']}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"LR GNN      : {exp['lr_gnn']}\")\n",
        "    print(f\"LR BERT     : {exp['lr_bert']}\")\n",
        "    print(f\"Freeze      : {exp['freeze']} layers\")\n",
        "    print(f\"Weight Decay: {exp['wd']}\")\n",
        "    print(f\"Margin      : {exp['margin']}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Commande d'entra√Ænement (Les fichiers temp sont cr√©√©s en local d'abord pour la vitesse)\n",
        "    cmd = [\n",
        "        'python', '-u', SCRIPT_PATH,\n",
        "        '--data_dir', FIXED_PARAMS['data_dir'],\n",
        "        '--model_name', FIXED_PARAMS['model_name'],\n",
        "        '--lr_gnn', str(exp['lr_gnn']),\n",
        "        '--lr_bert', str(exp['lr_bert']),\n",
        "        '--freeze_layers', str(exp['freeze']),\n",
        "        '--weight_decay', str(exp['wd']),\n",
        "        '--margin', str(exp['margin']),\n",
        "        '--batch_size', str(exp.get('batch_size', FIXED_PARAMS['batch_size'])),\n",
        "        '--grad_accum', str(exp.get('grad_accum', FIXED_PARAMS['grad_accum'])),\n",
        "        '--epochs', str(FIXED_PARAMS['epochs']),\n",
        "        '--patience', str(FIXED_PARAMS['patience']),\n",
        "    ]\n",
        "\n",
        "    run_start = datetime.now()\n",
        "    generated_model_file = None # Pour stocker le nom du fichier cr√©√©\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1\n",
        "        )\n",
        "\n",
        "        output_lines = []\n",
        "        for line in process.stdout:\n",
        "            print(line, end='')\n",
        "            output_lines.append(line)\n",
        "            # On guette le nom du fichier sauvegard√© en local\n",
        "            if \"Saved: \" in line:\n",
        "                # Ex: \"Saved: dual_lrGNN...pt\"\n",
        "                try:\n",
        "                    generated_model_file = line.split(\"Saved: \")[1].strip()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        return_code = process.returncode\n",
        "\n",
        "        # Parsing des r√©sultats (MRR, etc.)\n",
        "        best_mrr = 0.0\n",
        "        best_r1 = 0.0\n",
        "        best_r5 = 0.0\n",
        "\n",
        "        for line in output_lines:\n",
        "            if \"New Best MRR:\" in line:\n",
        "                try:\n",
        "                    mrr_str = line.split(\"New Best MRR:\")[1].split(\"|\")[0].strip()\n",
        "                    best_mrr = float(mrr_str)\n",
        "                except: pass\n",
        "            elif \"Val MRR:\" in line and \"R@1:\" in line:\n",
        "                try:\n",
        "                    parts = line.split(\"|\")\n",
        "                    for part in parts:\n",
        "                        if \"Val MRR:\" in part: best_mrr = max(best_mrr, float(part.split(\":\")[1].strip()))\n",
        "                        elif \"R@1:\" in part: best_r1 = max(best_r1, float(part.split(\":\")[1].strip()))\n",
        "                        elif \"R@5:\" in part: best_r5 = max(best_r5, float(part.split(\":\")[1].strip()))\n",
        "                except: pass\n",
        "\n",
        "        elapsed = (datetime.now() - run_start).total_seconds() / 60\n",
        "        status = \"‚úÖ SUCCESS\" if return_code == 0 else \"‚ùå FAILED\"\n",
        "\n",
        "        # === SAUVEGARDE SUR DRIVE ===\n",
        "        # Si un fichier .pt a √©t√© cr√©√©, on le d√©place sur le Drive\n",
        "        if generated_model_file and return_code == 0:\n",
        "            local_path = Path(FIXED_PARAMS['data_dir']) / generated_model_file\n",
        "            if local_path.exists():\n",
        "                drive_path = DRIVE_OUTPUT_DIR / generated_model_file\n",
        "                print(f\"üì¶ Copie vers Drive : {drive_path} ...\")\n",
        "                shutil.copy2(local_path, drive_path)\n",
        "                print(\"‚úÖ Copie termin√©e.\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Fichier local introuvable : {local_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERREUR : {e}\")\n",
        "        elapsed = (datetime.now() - run_start).total_seconds() / 60\n",
        "        status = f\"‚ùå ERROR: {str(e)[:50]}\"\n",
        "        return_code = -1\n",
        "\n",
        "    # Enregistrement des r√©sultats\n",
        "    result = {\n",
        "        'Run': i,\n",
        "        'Name': exp['name'],\n",
        "        'LR_GNN': exp['lr_gnn'],\n",
        "        'LR_BERT': exp['lr_bert'],\n",
        "        'Freeze_Layers': exp['freeze'],\n",
        "        'Weight_Decay': exp['wd'],\n",
        "        'Margin': exp['margin'],\n",
        "        'MRR': best_mrr,\n",
        "        'R@1': best_r1,\n",
        "        'R@5': best_r5,\n",
        "        'Time_min': elapsed,\n",
        "        'Status': status,\n",
        "        'Model_File': generated_model_file if generated_model_file else \"N/A\"\n",
        "    }\n",
        "\n",
        "    # Mise √† jour de la liste et sauvegarde CSV imm√©diate sur le Drive\n",
        "    results.append(result)\n",
        "    df_temp = pd.DataFrame(results)\n",
        "    df_temp.to_csv(RESULTS_CSV, index=False)\n",
        "    print(f\"\\nüíæ CSV mis √† jour sur Drive : {RESULTS_CSV}\")\n",
        "\n",
        "    # Progression\n",
        "    total_elapsed = (datetime.now() - total_start).total_seconds() / 60\n",
        "    print(f\"\\n‚è±Ô∏è  Temps √©coul√© : {total_elapsed:.1f}min\")\n",
        "\n",
        "    if i < len(EXPERIMENTS):\n",
        "        print(\"\\n‚è∏Ô∏è  Pause de 30s...\")\n",
        "        time.sleep(30)\n",
        "\n",
        "print(\"\\nüéâ GRID SEARCH TERMIN√â - TOUT EST SUR LE DRIVE !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjEu7DFBIzsj",
        "outputId": "7a5f3f08-a416-446e-d2fb-9e95f05f1964"
      },
      "id": "sjEu7DFBIzsj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Connexion au Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Dossier de sauvegarde s√©curis√© : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder\n",
            "================================================================================\n",
            "üöÄ DUAL ENCODER - GRID SEARCH AUTOMATIQUE (DRIVE SAVE MODE)\n",
            "================================================================================\n",
            "Dossier de sortie    : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder\n",
            "Fichier de r√©sultats : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "Nombre d'exp√©riences : 15\n",
            "--------------------------------------------------------------------------------\n",
            "üîÑ Reprise du fichier existant : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "================================================================================\n",
            "RUN 1/15 : Freeze 6 Layers\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 6 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 6\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-10 16:26:11.177075: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-10 16:26:11.199466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768062371.224796    4666 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768062371.231896    4666 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768062371.250536    4666 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768062371.250559    4666 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768062371.250563    4666 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768062371.250564    4666 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-10 16:26:11.255714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "‚ùÑÔ∏è Gel des 6 premi√®res couches de BERT\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2089 | Val MRR: 0.1569 | R@1: 0.0670\n",
            "  üíæ New Best MRR: 0.1569 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1723 | Val MRR: 0.2954 | R@1: 0.1650\n",
            "  üíæ New Best MRR: 0.2954 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.1105 | Val MRR: 0.4081 | R@1: 0.2530\n",
            "  üíæ New Best MRR: 0.4081 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0755 | Val MRR: 0.4810 | R@1: 0.3260\n",
            "  üíæ New Best MRR: 0.4810 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0594 | Val MRR: 0.5246 | R@1: 0.3740\n",
            "  üíæ New Best MRR: 0.5246 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0493 | Val MRR: 0.5552 | R@1: 0.3990\n",
            "  üíæ New Best MRR: 0.5552 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0425 | Val MRR: 0.5729 | R@1: 0.4110\n",
            "  üíæ New Best MRR: 0.5729 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0375 | Val MRR: 0.5970 | R@1: 0.4430\n",
            "  üíæ New Best MRR: 0.5970 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0325 | Val MRR: 0.6310 | R@1: 0.4770\n",
            "  üíæ New Best MRR: 0.6310 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0298 | Val MRR: 0.6332 | R@1: 0.4840\n",
            "  üíæ New Best MRR: 0.6332 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0257 | Val MRR: 0.6562 | R@1: 0.5110\n",
            "  üíæ New Best MRR: 0.6562 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0233 | Val MRR: 0.6800 | R@1: 0.5360\n",
            "  üíæ New Best MRR: 0.6800 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0218 | Val MRR: 0.7051 | R@1: 0.5700\n",
            "  üíæ New Best MRR: 0.7051 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0194 | Val MRR: 0.7057 | R@1: 0.5730\n",
            "  üíæ New Best MRR: 0.7057 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0184 | Val MRR: 0.7329 | R@1: 0.6080\n",
            "  üíæ New Best MRR: 0.7329 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0175 | Val MRR: 0.7235 | R@1: 0.5950\n",
            "Epoch 17/100 | Train Loss: 0.0166 | Val MRR: 0.7468 | R@1: 0.6270\n",
            "  üíæ New Best MRR: 0.7468 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 18/100 | Train Loss: 0.0155 | Val MRR: 0.7493 | R@1: 0.6320\n",
            "  üíæ New Best MRR: 0.7493 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0152 | Val MRR: 0.7542 | R@1: 0.6340\n",
            "  üíæ New Best MRR: 0.7542 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0145 | Val MRR: 0.7764 | R@1: 0.6620\n",
            "  üíæ New Best MRR: 0.7764 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 21/100 | Train Loss: 0.0140 | Val MRR: 0.7658 | R@1: 0.6460\n",
            "Epoch 22/100 | Train Loss: 0.0129 | Val MRR: 0.7628 | R@1: 0.6430\n",
            "Epoch 23/100 | Train Loss: 0.0126 | Val MRR: 0.7765 | R@1: 0.6660\n",
            "  üíæ New Best MRR: 0.7765 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 24/100 | Train Loss: 0.0125 | Val MRR: 0.7804 | R@1: 0.6680\n",
            "  üíæ New Best MRR: 0.7804 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0120 | Val MRR: 0.7801 | R@1: 0.6670\n",
            "Epoch 26/100 | Train Loss: 0.0116 | Val MRR: 0.7745 | R@1: 0.6550\n",
            "Epoch 27/100 | Train Loss: 0.0113 | Val MRR: 0.8061 | R@1: 0.7020\n",
            "  üíæ New Best MRR: 0.8061 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0105 | Val MRR: 0.7970 | R@1: 0.6950\n",
            "Epoch 29/100 | Train Loss: 0.0106 | Val MRR: 0.7977 | R@1: 0.6910\n",
            "Epoch 30/100 | Train Loss: 0.0107 | Val MRR: 0.7960 | R@1: 0.6850\n",
            "Epoch 31/100 | Train Loss: 0.0098 | Val MRR: 0.8044 | R@1: 0.7090\n",
            "Epoch 32/100 | Train Loss: 0.0093 | Val MRR: 0.8121 | R@1: 0.7160\n",
            "  üíæ New Best MRR: 0.8121 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 33/100 | Train Loss: 0.0094 | Val MRR: 0.8092 | R@1: 0.7080\n",
            "Epoch 34/100 | Train Loss: 0.0087 | Val MRR: 0.8047 | R@1: 0.6990\n",
            "Epoch 35/100 | Train Loss: 0.0095 | Val MRR: 0.8190 | R@1: 0.7200\n",
            "  üíæ New Best MRR: 0.8190 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 36/100 | Train Loss: 0.0087 | Val MRR: 0.8160 | R@1: 0.7140\n",
            "Epoch 37/100 | Train Loss: 0.0087 | Val MRR: 0.8225 | R@1: 0.7240\n",
            "  üíæ New Best MRR: 0.8225 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 38/100 | Train Loss: 0.0075 | Val MRR: 0.8307 | R@1: 0.7410\n",
            "  üíæ New Best MRR: 0.8307 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 39/100 | Train Loss: 0.0074 | Val MRR: 0.8293 | R@1: 0.7350\n",
            "Epoch 40/100 | Train Loss: 0.0078 | Val MRR: 0.8270 | R@1: 0.7280\n",
            "Epoch 41/100 | Train Loss: 0.0077 | Val MRR: 0.8336 | R@1: 0.7400\n",
            "  üíæ New Best MRR: 0.8336 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 42/100 | Train Loss: 0.0074 | Val MRR: 0.8353 | R@1: 0.7440\n",
            "  üíæ New Best MRR: 0.8353 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0073 | Val MRR: 0.8306 | R@1: 0.7330\n",
            "Epoch 44/100 | Train Loss: 0.0069 | Val MRR: 0.8432 | R@1: 0.7550\n",
            "  üíæ New Best MRR: 0.8432 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 45/100 | Train Loss: 0.0069 | Val MRR: 0.8341 | R@1: 0.7430\n",
            "Epoch 46/100 | Train Loss: 0.0074 | Val MRR: 0.8370 | R@1: 0.7470\n",
            "Epoch 47/100 | Train Loss: 0.0062 | Val MRR: 0.8445 | R@1: 0.7570\n",
            "  üíæ New Best MRR: 0.8445 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 48/100 | Train Loss: 0.0061 | Val MRR: 0.8425 | R@1: 0.7560\n",
            "Epoch 49/100 | Train Loss: 0.0060 | Val MRR: 0.8391 | R@1: 0.7470\n",
            "Epoch 50/100 | Train Loss: 0.0060 | Val MRR: 0.8477 | R@1: 0.7580\n",
            "  üíæ New Best MRR: 0.8477 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 51/100 | Train Loss: 0.0061 | Val MRR: 0.8495 | R@1: 0.7640\n",
            "  üíæ New Best MRR: 0.8495 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 52/100 | Train Loss: 0.0059 | Val MRR: 0.8372 | R@1: 0.7390\n",
            "Epoch 53/100 | Train Loss: 0.0057 | Val MRR: 0.8497 | R@1: 0.7590\n",
            "  üíæ New Best MRR: 0.8497 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 54/100 | Train Loss: 0.0055 | Val MRR: 0.8598 | R@1: 0.7800\n",
            "  üíæ New Best MRR: 0.8598 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 55/100 | Train Loss: 0.0053 | Val MRR: 0.8520 | R@1: 0.7650\n",
            "Epoch 56/100 | Train Loss: 0.0052 | Val MRR: 0.8577 | R@1: 0.7760\n",
            "Epoch 57/100 | Train Loss: 0.0053 | Val MRR: 0.8529 | R@1: 0.7690\n",
            "Epoch 58/100 | Train Loss: 0.0049 | Val MRR: 0.8637 | R@1: 0.7820\n",
            "  üíæ New Best MRR: 0.8637 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 59/100 | Train Loss: 0.0049 | Val MRR: 0.8696 | R@1: 0.7920\n",
            "  üíæ New Best MRR: 0.8696 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 60/100 | Train Loss: 0.0048 | Val MRR: 0.8590 | R@1: 0.7750\n",
            "Epoch 61/100 | Train Loss: 0.0046 | Val MRR: 0.8666 | R@1: 0.7920\n",
            "Epoch 62/100 | Train Loss: 0.0047 | Val MRR: 0.8737 | R@1: 0.8020\n",
            "  üíæ New Best MRR: 0.8737 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 63/100 | Train Loss: 0.0045 | Val MRR: 0.8709 | R@1: 0.7950\n",
            "Epoch 64/100 | Train Loss: 0.0043 | Val MRR: 0.8745 | R@1: 0.8040\n",
            "  üíæ New Best MRR: 0.8745 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 65/100 | Train Loss: 0.0043 | Val MRR: 0.8596 | R@1: 0.7740\n",
            "Epoch 66/100 | Train Loss: 0.0042 | Val MRR: 0.8723 | R@1: 0.7960\n",
            "Epoch 67/100 | Train Loss: 0.0044 | Val MRR: 0.8753 | R@1: 0.7990\n",
            "  üíæ New Best MRR: 0.8753 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 68/100 | Train Loss: 0.0040 | Val MRR: 0.8725 | R@1: 0.7970\n",
            "Epoch 69/100 | Train Loss: 0.0042 | Val MRR: 0.8621 | R@1: 0.7830\n",
            "Epoch 70/100 | Train Loss: 0.0039 | Val MRR: 0.8793 | R@1: 0.8080\n",
            "  üíæ New Best MRR: 0.8793 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 71/100 | Train Loss: 0.0034 | Val MRR: 0.8760 | R@1: 0.8020\n",
            "Epoch 72/100 | Train Loss: 0.0039 | Val MRR: 0.8787 | R@1: 0.8050\n",
            "Epoch 73/100 | Train Loss: 0.0037 | Val MRR: 0.8819 | R@1: 0.8130\n",
            "  üíæ New Best MRR: 0.8819 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 74/100 | Train Loss: 0.0036 | Val MRR: 0.8857 | R@1: 0.8170\n",
            "  üíæ New Best MRR: 0.8857 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 75/100 | Train Loss: 0.0035 | Val MRR: 0.8743 | R@1: 0.8040\n",
            "Epoch 76/100 | Train Loss: 0.0037 | Val MRR: 0.8782 | R@1: 0.8040\n",
            "Epoch 77/100 | Train Loss: 0.0034 | Val MRR: 0.8833 | R@1: 0.8160\n",
            "Epoch 78/100 | Train Loss: 0.0035 | Val MRR: 0.8852 | R@1: 0.8170\n",
            "Epoch 79/100 | Train Loss: 0.0034 | Val MRR: 0.8879 | R@1: 0.8220\n",
            "  üíæ New Best MRR: 0.8879 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 80/100 | Train Loss: 0.0038 | Val MRR: 0.8904 | R@1: 0.8250\n",
            "  üíæ New Best MRR: 0.8904 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 81/100 | Train Loss: 0.0032 | Val MRR: 0.8863 | R@1: 0.8170\n",
            "Epoch 82/100 | Train Loss: 0.0030 | Val MRR: 0.8901 | R@1: 0.8250\n",
            "Epoch 83/100 | Train Loss: 0.0031 | Val MRR: 0.8859 | R@1: 0.8190\n",
            "Epoch 84/100 | Train Loss: 0.0032 | Val MRR: 0.8860 | R@1: 0.8180\n",
            "Epoch 85/100 | Train Loss: 0.0030 | Val MRR: 0.8922 | R@1: 0.8290\n",
            "  üíæ New Best MRR: 0.8922 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 86/100 | Train Loss: 0.0029 | Val MRR: 0.8923 | R@1: 0.8300\n",
            "  üíæ New Best MRR: 0.8923 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 87/100 | Train Loss: 0.0029 | Val MRR: 0.8899 | R@1: 0.8250\n",
            "Epoch 88/100 | Train Loss: 0.0030 | Val MRR: 0.8928 | R@1: 0.8300\n",
            "  üíæ New Best MRR: 0.8928 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 89/100 | Train Loss: 0.0029 | Val MRR: 0.8941 | R@1: 0.8330\n",
            "  üíæ New Best MRR: 0.8941 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 90/100 | Train Loss: 0.0029 | Val MRR: 0.8924 | R@1: 0.8300\n",
            "Epoch 91/100 | Train Loss: 0.0029 | Val MRR: 0.8976 | R@1: 0.8370\n",
            "  üíæ New Best MRR: 0.8976 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 92/100 | Train Loss: 0.0028 | Val MRR: 0.8950 | R@1: 0.8330\n",
            "Epoch 93/100 | Train Loss: 0.0029 | Val MRR: 0.8922 | R@1: 0.8280\n",
            "Epoch 94/100 | Train Loss: 0.0027 | Val MRR: 0.8949 | R@1: 0.8340\n",
            "Epoch 95/100 | Train Loss: 0.0028 | Val MRR: 0.8914 | R@1: 0.8280\n",
            "Epoch 96/100 | Train Loss: 0.0029 | Val MRR: 0.8918 | R@1: 0.8260\n",
            "Epoch 97/100 | Train Loss: 0.0027 | Val MRR: 0.8924 | R@1: 0.8280\n",
            "Epoch 98/100 | Train Loss: 0.0028 | Val MRR: 0.8935 | R@1: 0.8310\n",
            "Epoch 99/100 | Train Loss: 0.0028 | Val MRR: 0.8916 | R@1: 0.8260\n",
            "Epoch 100/100 | Train Loss: 0.0028 | Val MRR: 0.8953 | R@1: 0.8330\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz6_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 215.4min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 2/15 : Freeze 6 + High LR\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 5e-05\n",
            "Freeze      : 6 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 5e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 6\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-10 20:02:02.300780: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-10 20:02:02.321955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768075322.347180   66974 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768075322.354428   66974 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768075322.372359   66974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768075322.372379   66974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768075322.372382   66974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768075322.372384   66974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-10 20:02:02.377281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "‚ùÑÔ∏è Gel des 6 premi√®res couches de BERT\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2087 | Val MRR: 0.1530 | R@1: 0.0570\n",
            "  üíæ New Best MRR: 0.1530 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1642 | Val MRR: 0.3188 | R@1: 0.1800\n",
            "  üíæ New Best MRR: 0.3188 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.1003 | Val MRR: 0.4426 | R@1: 0.2900\n",
            "  üíæ New Best MRR: 0.4426 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0682 | Val MRR: 0.5204 | R@1: 0.3660\n",
            "  üíæ New Best MRR: 0.5204 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0520 | Val MRR: 0.5380 | R@1: 0.3830\n",
            "  üíæ New Best MRR: 0.5380 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0433 | Val MRR: 0.5441 | R@1: 0.3900\n",
            "  üíæ New Best MRR: 0.5441 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0365 | Val MRR: 0.6014 | R@1: 0.4400\n",
            "  üíæ New Best MRR: 0.6014 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0321 | Val MRR: 0.6116 | R@1: 0.4530\n",
            "  üíæ New Best MRR: 0.6116 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0282 | Val MRR: 0.6615 | R@1: 0.5150\n",
            "  üíæ New Best MRR: 0.6615 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0257 | Val MRR: 0.6734 | R@1: 0.5270\n",
            "  üíæ New Best MRR: 0.6734 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0221 | Val MRR: 0.6860 | R@1: 0.5390\n",
            "  üíæ New Best MRR: 0.6860 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0198 | Val MRR: 0.6967 | R@1: 0.5470\n",
            "  üíæ New Best MRR: 0.6967 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0181 | Val MRR: 0.7341 | R@1: 0.6060\n",
            "  üíæ New Best MRR: 0.7341 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0167 | Val MRR: 0.7320 | R@1: 0.6000\n",
            "Epoch 15/100 | Train Loss: 0.0160 | Val MRR: 0.7236 | R@1: 0.5820\n",
            "Epoch 16/100 | Train Loss: 0.0155 | Val MRR: 0.7442 | R@1: 0.6180\n",
            "  üíæ New Best MRR: 0.7442 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0147 | Val MRR: 0.7612 | R@1: 0.6290\n",
            "  üíæ New Best MRR: 0.7612 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 18/100 | Train Loss: 0.0134 | Val MRR: 0.7663 | R@1: 0.6380\n",
            "  üíæ New Best MRR: 0.7663 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0128 | Val MRR: 0.7746 | R@1: 0.6580\n",
            "  üíæ New Best MRR: 0.7746 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0121 | Val MRR: 0.7713 | R@1: 0.6530\n",
            "Epoch 21/100 | Train Loss: 0.0114 | Val MRR: 0.7738 | R@1: 0.6570\n",
            "Epoch 22/100 | Train Loss: 0.0112 | Val MRR: 0.7890 | R@1: 0.6700\n",
            "  üíæ New Best MRR: 0.7890 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0110 | Val MRR: 0.7860 | R@1: 0.6680\n",
            "Epoch 24/100 | Train Loss: 0.0104 | Val MRR: 0.8001 | R@1: 0.6910\n",
            "  üíæ New Best MRR: 0.8001 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0099 | Val MRR: 0.7891 | R@1: 0.6730\n",
            "Epoch 26/100 | Train Loss: 0.0100 | Val MRR: 0.7831 | R@1: 0.6670\n",
            "Epoch 27/100 | Train Loss: 0.0098 | Val MRR: 0.7894 | R@1: 0.6770\n",
            "Epoch 28/100 | Train Loss: 0.0094 | Val MRR: 0.8008 | R@1: 0.6970\n",
            "  üíæ New Best MRR: 0.8008 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 29/100 | Train Loss: 0.0091 | Val MRR: 0.8059 | R@1: 0.7040\n",
            "  üíæ New Best MRR: 0.8059 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 30/100 | Train Loss: 0.0087 | Val MRR: 0.8020 | R@1: 0.6950\n",
            "Epoch 31/100 | Train Loss: 0.0082 | Val MRR: 0.8197 | R@1: 0.7230\n",
            "  üíæ New Best MRR: 0.8197 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 32/100 | Train Loss: 0.0082 | Val MRR: 0.8149 | R@1: 0.7170\n",
            "Epoch 33/100 | Train Loss: 0.0076 | Val MRR: 0.8204 | R@1: 0.7200\n",
            "  üíæ New Best MRR: 0.8204 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 34/100 | Train Loss: 0.0079 | Val MRR: 0.8231 | R@1: 0.7250\n",
            "  üíæ New Best MRR: 0.8231 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 35/100 | Train Loss: 0.0076 | Val MRR: 0.8209 | R@1: 0.7290\n",
            "Epoch 36/100 | Train Loss: 0.0074 | Val MRR: 0.8208 | R@1: 0.7200\n",
            "Epoch 37/100 | Train Loss: 0.0075 | Val MRR: 0.8156 | R@1: 0.7160\n",
            "Epoch 38/100 | Train Loss: 0.0079 | Val MRR: 0.8217 | R@1: 0.7230\n",
            "Epoch 39/100 | Train Loss: 0.0069 | Val MRR: 0.8307 | R@1: 0.7380\n",
            "  üíæ New Best MRR: 0.8307 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 40/100 | Train Loss: 0.0072 | Val MRR: 0.8332 | R@1: 0.7400\n",
            "  üíæ New Best MRR: 0.8332 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 41/100 | Train Loss: 0.0071 | Val MRR: 0.8139 | R@1: 0.7070\n",
            "Epoch 42/100 | Train Loss: 0.0065 | Val MRR: 0.8432 | R@1: 0.7540\n",
            "  üíæ New Best MRR: 0.8432 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0060 | Val MRR: 0.8458 | R@1: 0.7590\n",
            "  üíæ New Best MRR: 0.8458 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 44/100 | Train Loss: 0.0062 | Val MRR: 0.8308 | R@1: 0.7300\n",
            "Epoch 45/100 | Train Loss: 0.0054 | Val MRR: 0.8372 | R@1: 0.7420\n",
            "Epoch 46/100 | Train Loss: 0.0056 | Val MRR: 0.8417 | R@1: 0.7520\n",
            "Epoch 47/100 | Train Loss: 0.0053 | Val MRR: 0.8493 | R@1: 0.7600\n",
            "  üíæ New Best MRR: 0.8493 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 48/100 | Train Loss: 0.0055 | Val MRR: 0.8463 | R@1: 0.7580\n",
            "Epoch 49/100 | Train Loss: 0.0049 | Val MRR: 0.8466 | R@1: 0.7570\n",
            "Epoch 50/100 | Train Loss: 0.0050 | Val MRR: 0.8649 | R@1: 0.7850\n",
            "  üíæ New Best MRR: 0.8649 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 51/100 | Train Loss: 0.0051 | Val MRR: 0.8571 | R@1: 0.7760\n",
            "Epoch 52/100 | Train Loss: 0.0050 | Val MRR: 0.8559 | R@1: 0.7710\n",
            "Epoch 53/100 | Train Loss: 0.0046 | Val MRR: 0.8682 | R@1: 0.7900\n",
            "  üíæ New Best MRR: 0.8682 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 54/100 | Train Loss: 0.0045 | Val MRR: 0.8619 | R@1: 0.7790\n",
            "Epoch 55/100 | Train Loss: 0.0046 | Val MRR: 0.8643 | R@1: 0.7820\n",
            "Epoch 56/100 | Train Loss: 0.0044 | Val MRR: 0.8630 | R@1: 0.7840\n",
            "Epoch 57/100 | Train Loss: 0.0040 | Val MRR: 0.8707 | R@1: 0.7950\n",
            "  üíæ New Best MRR: 0.8707 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 58/100 | Train Loss: 0.0041 | Val MRR: 0.8726 | R@1: 0.8010\n",
            "  üíæ New Best MRR: 0.8726 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 59/100 | Train Loss: 0.0040 | Val MRR: 0.8777 | R@1: 0.8060\n",
            "  üíæ New Best MRR: 0.8777 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 60/100 | Train Loss: 0.0039 | Val MRR: 0.8691 | R@1: 0.7870\n",
            "Epoch 61/100 | Train Loss: 0.0038 | Val MRR: 0.8729 | R@1: 0.7910\n",
            "Epoch 62/100 | Train Loss: 0.0037 | Val MRR: 0.8814 | R@1: 0.8090\n",
            "  üíæ New Best MRR: 0.8814 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 63/100 | Train Loss: 0.0038 | Val MRR: 0.8722 | R@1: 0.7920\n",
            "Epoch 64/100 | Train Loss: 0.0036 | Val MRR: 0.8754 | R@1: 0.8010\n",
            "Epoch 65/100 | Train Loss: 0.0037 | Val MRR: 0.8773 | R@1: 0.8050\n",
            "Epoch 66/100 | Train Loss: 0.0036 | Val MRR: 0.8730 | R@1: 0.7960\n",
            "Epoch 67/100 | Train Loss: 0.0034 | Val MRR: 0.8805 | R@1: 0.8080\n",
            "Epoch 68/100 | Train Loss: 0.0035 | Val MRR: 0.8774 | R@1: 0.8000\n",
            "Epoch 69/100 | Train Loss: 0.0031 | Val MRR: 0.8832 | R@1: 0.8080\n",
            "  üíæ New Best MRR: 0.8832 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 70/100 | Train Loss: 0.0031 | Val MRR: 0.8894 | R@1: 0.8210\n",
            "  üíæ New Best MRR: 0.8894 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 71/100 | Train Loss: 0.0030 | Val MRR: 0.8896 | R@1: 0.8220\n",
            "  üíæ New Best MRR: 0.8896 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 72/100 | Train Loss: 0.0031 | Val MRR: 0.8876 | R@1: 0.8170\n",
            "Epoch 73/100 | Train Loss: 0.0032 | Val MRR: 0.8853 | R@1: 0.8120\n",
            "Epoch 74/100 | Train Loss: 0.0027 | Val MRR: 0.8890 | R@1: 0.8210\n",
            "Epoch 75/100 | Train Loss: 0.0031 | Val MRR: 0.8920 | R@1: 0.8250\n",
            "  üíæ New Best MRR: 0.8920 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 76/100 | Train Loss: 0.0029 | Val MRR: 0.8849 | R@1: 0.8120\n",
            "Epoch 77/100 | Train Loss: 0.0026 | Val MRR: 0.8871 | R@1: 0.8170\n",
            "Epoch 78/100 | Train Loss: 0.0028 | Val MRR: 0.8922 | R@1: 0.8280\n",
            "  üíæ New Best MRR: 0.8922 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 79/100 | Train Loss: 0.0027 | Val MRR: 0.8934 | R@1: 0.8280\n",
            "  üíæ New Best MRR: 0.8934 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 80/100 | Train Loss: 0.0025 | Val MRR: 0.8927 | R@1: 0.8270\n",
            "Epoch 81/100 | Train Loss: 0.0026 | Val MRR: 0.8897 | R@1: 0.8200\n",
            "Epoch 82/100 | Train Loss: 0.0027 | Val MRR: 0.8944 | R@1: 0.8320\n",
            "  üíæ New Best MRR: 0.8944 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 83/100 | Train Loss: 0.0024 | Val MRR: 0.8913 | R@1: 0.8250\n",
            "Epoch 84/100 | Train Loss: 0.0024 | Val MRR: 0.8933 | R@1: 0.8250\n",
            "Epoch 85/100 | Train Loss: 0.0025 | Val MRR: 0.8919 | R@1: 0.8240\n",
            "Epoch 86/100 | Train Loss: 0.0024 | Val MRR: 0.8885 | R@1: 0.8180\n",
            "Epoch 87/100 | Train Loss: 0.0024 | Val MRR: 0.8960 | R@1: 0.8310\n",
            "  üíæ New Best MRR: 0.8960 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 88/100 | Train Loss: 0.0022 | Val MRR: 0.8936 | R@1: 0.8290\n",
            "Epoch 89/100 | Train Loss: 0.0024 | Val MRR: 0.8954 | R@1: 0.8300\n",
            "Epoch 90/100 | Train Loss: 0.0026 | Val MRR: 0.8973 | R@1: 0.8360\n",
            "  üíæ New Best MRR: 0.8973 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 91/100 | Train Loss: 0.0024 | Val MRR: 0.8963 | R@1: 0.8330\n",
            "Epoch 92/100 | Train Loss: 0.0023 | Val MRR: 0.8968 | R@1: 0.8320\n",
            "Epoch 93/100 | Train Loss: 0.0022 | Val MRR: 0.8991 | R@1: 0.8380\n",
            "  üíæ New Best MRR: 0.8991 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 94/100 | Train Loss: 0.0021 | Val MRR: 0.8946 | R@1: 0.8280\n",
            "Epoch 95/100 | Train Loss: 0.0023 | Val MRR: 0.8944 | R@1: 0.8280\n",
            "Epoch 96/100 | Train Loss: 0.0024 | Val MRR: 0.8959 | R@1: 0.8310\n",
            "Epoch 97/100 | Train Loss: 0.0023 | Val MRR: 0.8996 | R@1: 0.8370\n",
            "  üíæ New Best MRR: 0.8996 | Saved: dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt\n",
            "Epoch 98/100 | Train Loss: 0.0024 | Val MRR: 0.8916 | R@1: 0.8220\n",
            "Epoch 99/100 | Train Loss: 0.0024 | Val MRR: 0.8941 | R@1: 0.8280\n",
            "Epoch 100/100 | Train Loss: 0.0023 | Val MRR: 0.8978 | R@1: 0.8360\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT5e-05_wd0.0001_frz6_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 432.0min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 3/15 : Freeze 9 Layers\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 9 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 9\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-10 23:38:41.930408: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-10 23:38:41.951680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768088321.977737  129569 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768088321.985119  129569 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768088322.004258  129569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768088322.004284  129569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768088322.004288  129569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768088322.004290  129569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-10 23:38:42.009514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "‚ùÑÔ∏è Gel des 9 premi√®res couches de BERT\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2100 | Val MRR: 0.1408 | R@1: 0.0550\n",
            "  üíæ New Best MRR: 0.1408 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1835 | Val MRR: 0.2492 | R@1: 0.1210\n",
            "  üíæ New Best MRR: 0.2492 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.1291 | Val MRR: 0.3746 | R@1: 0.2330\n",
            "  üíæ New Best MRR: 0.3746 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0897 | Val MRR: 0.4398 | R@1: 0.2880\n",
            "  üíæ New Best MRR: 0.4398 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0689 | Val MRR: 0.4761 | R@1: 0.3180\n",
            "  üíæ New Best MRR: 0.4761 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0578 | Val MRR: 0.5219 | R@1: 0.3560\n",
            "  üíæ New Best MRR: 0.5219 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0500 | Val MRR: 0.5449 | R@1: 0.3900\n",
            "  üíæ New Best MRR: 0.5449 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0447 | Val MRR: 0.5702 | R@1: 0.4160\n",
            "  üíæ New Best MRR: 0.5702 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0392 | Val MRR: 0.5709 | R@1: 0.4190\n",
            "  üíæ New Best MRR: 0.5709 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0363 | Val MRR: 0.6074 | R@1: 0.4610\n",
            "  üíæ New Best MRR: 0.6074 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0326 | Val MRR: 0.6367 | R@1: 0.4890\n",
            "  üíæ New Best MRR: 0.6367 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0288 | Val MRR: 0.6543 | R@1: 0.5100\n",
            "  üíæ New Best MRR: 0.6543 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0268 | Val MRR: 0.6611 | R@1: 0.5180\n",
            "  üíæ New Best MRR: 0.6611 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0241 | Val MRR: 0.6808 | R@1: 0.5340\n",
            "  üíæ New Best MRR: 0.6808 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0231 | Val MRR: 0.6827 | R@1: 0.5380\n",
            "  üíæ New Best MRR: 0.6827 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0214 | Val MRR: 0.7060 | R@1: 0.5670\n",
            "  üíæ New Best MRR: 0.7060 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0209 | Val MRR: 0.7049 | R@1: 0.5640\n",
            "Epoch 18/100 | Train Loss: 0.0201 | Val MRR: 0.7115 | R@1: 0.5690\n",
            "  üíæ New Best MRR: 0.7115 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0193 | Val MRR: 0.7426 | R@1: 0.6200\n",
            "  üíæ New Best MRR: 0.7426 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0183 | Val MRR: 0.7410 | R@1: 0.6090\n",
            "Epoch 21/100 | Train Loss: 0.0166 | Val MRR: 0.7273 | R@1: 0.5950\n",
            "Epoch 22/100 | Train Loss: 0.0159 | Val MRR: 0.7490 | R@1: 0.6220\n",
            "  üíæ New Best MRR: 0.7490 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0164 | Val MRR: 0.7401 | R@1: 0.6090\n",
            "Epoch 24/100 | Train Loss: 0.0150 | Val MRR: 0.7513 | R@1: 0.6230\n",
            "  üíæ New Best MRR: 0.7513 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0155 | Val MRR: 0.7424 | R@1: 0.6150\n",
            "Epoch 26/100 | Train Loss: 0.0149 | Val MRR: 0.7577 | R@1: 0.6320\n",
            "  üíæ New Best MRR: 0.7577 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 27/100 | Train Loss: 0.0142 | Val MRR: 0.7628 | R@1: 0.6440\n",
            "  üíæ New Best MRR: 0.7628 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0140 | Val MRR: 0.7673 | R@1: 0.6490\n",
            "  üíæ New Best MRR: 0.7673 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 29/100 | Train Loss: 0.0138 | Val MRR: 0.7605 | R@1: 0.6400\n",
            "Epoch 30/100 | Train Loss: 0.0137 | Val MRR: 0.7729 | R@1: 0.6540\n",
            "  üíæ New Best MRR: 0.7729 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 31/100 | Train Loss: 0.0127 | Val MRR: 0.7720 | R@1: 0.6550\n",
            "Epoch 32/100 | Train Loss: 0.0122 | Val MRR: 0.7869 | R@1: 0.6740\n",
            "  üíæ New Best MRR: 0.7869 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 33/100 | Train Loss: 0.0118 | Val MRR: 0.7876 | R@1: 0.6690\n",
            "  üíæ New Best MRR: 0.7876 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 34/100 | Train Loss: 0.0116 | Val MRR: 0.7932 | R@1: 0.6820\n",
            "  üíæ New Best MRR: 0.7932 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 35/100 | Train Loss: 0.0117 | Val MRR: 0.8164 | R@1: 0.7200\n",
            "  üíæ New Best MRR: 0.8164 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 36/100 | Train Loss: 0.0115 | Val MRR: 0.7902 | R@1: 0.6710\n",
            "Epoch 37/100 | Train Loss: 0.0107 | Val MRR: 0.7998 | R@1: 0.6880\n",
            "Epoch 38/100 | Train Loss: 0.0104 | Val MRR: 0.8088 | R@1: 0.6980\n",
            "Epoch 39/100 | Train Loss: 0.0102 | Val MRR: 0.8115 | R@1: 0.7080\n",
            "Epoch 40/100 | Train Loss: 0.0094 | Val MRR: 0.8053 | R@1: 0.6940\n",
            "Epoch 41/100 | Train Loss: 0.0095 | Val MRR: 0.8046 | R@1: 0.6930\n",
            "Epoch 42/100 | Train Loss: 0.0095 | Val MRR: 0.8124 | R@1: 0.7110\n",
            "Epoch 43/100 | Train Loss: 0.0091 | Val MRR: 0.7991 | R@1: 0.6900\n",
            "Epoch 44/100 | Train Loss: 0.0086 | Val MRR: 0.8327 | R@1: 0.7400\n",
            "  üíæ New Best MRR: 0.8327 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 45/100 | Train Loss: 0.0089 | Val MRR: 0.8237 | R@1: 0.7240\n",
            "Epoch 46/100 | Train Loss: 0.0080 | Val MRR: 0.8306 | R@1: 0.7400\n",
            "Epoch 47/100 | Train Loss: 0.0082 | Val MRR: 0.8182 | R@1: 0.7130\n",
            "Epoch 48/100 | Train Loss: 0.0079 | Val MRR: 0.8261 | R@1: 0.7320\n",
            "Epoch 49/100 | Train Loss: 0.0080 | Val MRR: 0.8280 | R@1: 0.7290\n",
            "Epoch 50/100 | Train Loss: 0.0073 | Val MRR: 0.8211 | R@1: 0.7210\n",
            "Epoch 51/100 | Train Loss: 0.0072 | Val MRR: 0.8295 | R@1: 0.7350\n",
            "Epoch 52/100 | Train Loss: 0.0073 | Val MRR: 0.8423 | R@1: 0.7540\n",
            "  üíæ New Best MRR: 0.8423 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 53/100 | Train Loss: 0.0068 | Val MRR: 0.8378 | R@1: 0.7490\n",
            "Epoch 54/100 | Train Loss: 0.0070 | Val MRR: 0.8440 | R@1: 0.7530\n",
            "  üíæ New Best MRR: 0.8440 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 55/100 | Train Loss: 0.0063 | Val MRR: 0.8442 | R@1: 0.7560\n",
            "  üíæ New Best MRR: 0.8442 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 56/100 | Train Loss: 0.0066 | Val MRR: 0.8445 | R@1: 0.7550\n",
            "  üíæ New Best MRR: 0.8445 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 57/100 | Train Loss: 0.0066 | Val MRR: 0.8531 | R@1: 0.7690\n",
            "  üíæ New Best MRR: 0.8531 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 58/100 | Train Loss: 0.0063 | Val MRR: 0.8429 | R@1: 0.7490\n",
            "Epoch 59/100 | Train Loss: 0.0061 | Val MRR: 0.8489 | R@1: 0.7650\n",
            "Epoch 60/100 | Train Loss: 0.0062 | Val MRR: 0.8521 | R@1: 0.7650\n",
            "Epoch 61/100 | Train Loss: 0.0058 | Val MRR: 0.8533 | R@1: 0.7680\n",
            "  üíæ New Best MRR: 0.8533 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 62/100 | Train Loss: 0.0057 | Val MRR: 0.8495 | R@1: 0.7580\n",
            "Epoch 63/100 | Train Loss: 0.0055 | Val MRR: 0.8578 | R@1: 0.7730\n",
            "  üíæ New Best MRR: 0.8578 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 64/100 | Train Loss: 0.0055 | Val MRR: 0.8551 | R@1: 0.7690\n",
            "Epoch 65/100 | Train Loss: 0.0054 | Val MRR: 0.8561 | R@1: 0.7740\n",
            "Epoch 66/100 | Train Loss: 0.0050 | Val MRR: 0.8558 | R@1: 0.7700\n",
            "Epoch 67/100 | Train Loss: 0.0054 | Val MRR: 0.8601 | R@1: 0.7760\n",
            "  üíæ New Best MRR: 0.8601 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 68/100 | Train Loss: 0.0054 | Val MRR: 0.8682 | R@1: 0.7910\n",
            "  üíæ New Best MRR: 0.8682 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 69/100 | Train Loss: 0.0052 | Val MRR: 0.8688 | R@1: 0.7920\n",
            "  üíæ New Best MRR: 0.8688 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 70/100 | Train Loss: 0.0051 | Val MRR: 0.8607 | R@1: 0.7790\n",
            "Epoch 71/100 | Train Loss: 0.0046 | Val MRR: 0.8611 | R@1: 0.7820\n",
            "Epoch 72/100 | Train Loss: 0.0050 | Val MRR: 0.8697 | R@1: 0.7930\n",
            "  üíæ New Best MRR: 0.8697 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 73/100 | Train Loss: 0.0048 | Val MRR: 0.8666 | R@1: 0.7900\n",
            "Epoch 74/100 | Train Loss: 0.0045 | Val MRR: 0.8738 | R@1: 0.8010\n",
            "  üíæ New Best MRR: 0.8738 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 75/100 | Train Loss: 0.0043 | Val MRR: 0.8689 | R@1: 0.7930\n",
            "Epoch 76/100 | Train Loss: 0.0043 | Val MRR: 0.8783 | R@1: 0.8080\n",
            "  üíæ New Best MRR: 0.8783 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 77/100 | Train Loss: 0.0044 | Val MRR: 0.8814 | R@1: 0.8140\n",
            "  üíæ New Best MRR: 0.8814 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 78/100 | Train Loss: 0.0044 | Val MRR: 0.8769 | R@1: 0.8040\n",
            "Epoch 79/100 | Train Loss: 0.0040 | Val MRR: 0.8747 | R@1: 0.8020\n",
            "Epoch 80/100 | Train Loss: 0.0046 | Val MRR: 0.8756 | R@1: 0.8030\n",
            "Epoch 81/100 | Train Loss: 0.0040 | Val MRR: 0.8780 | R@1: 0.8060\n",
            "Epoch 82/100 | Train Loss: 0.0041 | Val MRR: 0.8778 | R@1: 0.8050\n",
            "Epoch 83/100 | Train Loss: 0.0043 | Val MRR: 0.8818 | R@1: 0.8120\n",
            "  üíæ New Best MRR: 0.8818 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 84/100 | Train Loss: 0.0040 | Val MRR: 0.8817 | R@1: 0.8110\n",
            "Epoch 85/100 | Train Loss: 0.0043 | Val MRR: 0.8785 | R@1: 0.8060\n",
            "Epoch 86/100 | Train Loss: 0.0042 | Val MRR: 0.8832 | R@1: 0.8140\n",
            "  üíæ New Best MRR: 0.8832 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 87/100 | Train Loss: 0.0039 | Val MRR: 0.8808 | R@1: 0.8110\n",
            "Epoch 88/100 | Train Loss: 0.0037 | Val MRR: 0.8829 | R@1: 0.8170\n",
            "Epoch 89/100 | Train Loss: 0.0039 | Val MRR: 0.8765 | R@1: 0.8020\n",
            "Epoch 90/100 | Train Loss: 0.0039 | Val MRR: 0.8817 | R@1: 0.8110\n",
            "Epoch 91/100 | Train Loss: 0.0041 | Val MRR: 0.8776 | R@1: 0.8030\n",
            "Epoch 92/100 | Train Loss: 0.0037 | Val MRR: 0.8847 | R@1: 0.8160\n",
            "  üíæ New Best MRR: 0.8847 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 93/100 | Train Loss: 0.0037 | Val MRR: 0.8829 | R@1: 0.8150\n",
            "Epoch 94/100 | Train Loss: 0.0038 | Val MRR: 0.8802 | R@1: 0.8080\n",
            "Epoch 95/100 | Train Loss: 0.0042 | Val MRR: 0.8822 | R@1: 0.8120\n",
            "Epoch 96/100 | Train Loss: 0.0039 | Val MRR: 0.8833 | R@1: 0.8150\n",
            "Epoch 97/100 | Train Loss: 0.0036 | Val MRR: 0.8818 | R@1: 0.8100\n",
            "Epoch 98/100 | Train Loss: 0.0039 | Val MRR: 0.8847 | R@1: 0.8160\n",
            "  üíæ New Best MRR: 0.8847 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "Epoch 99/100 | Train Loss: 0.0035 | Val MRR: 0.8839 | R@1: 0.8140\n",
            "Epoch 100/100 | Train Loss: 0.0039 | Val MRR: 0.8872 | R@1: 0.8220\n",
            "  üíæ New Best MRR: 0.8872 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz9_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 623.9min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 4/15 : Low WD\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 1e-05\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 1e-05\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-11 02:50:35.479739: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-11 02:50:35.502168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768099835.528533  183732 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768099835.536180  183732 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768099835.555095  183732 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768099835.555118  183732 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768099835.555121  183732 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768099835.555123  183732 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 02:50:35.560298: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2096 | Val MRR: 0.1546 | R@1: 0.0640\n",
            "  üíæ New Best MRR: 0.1546 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1677 | Val MRR: 0.3225 | R@1: 0.1850\n",
            "  üíæ New Best MRR: 0.3225 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.0963 | Val MRR: 0.4664 | R@1: 0.3180\n",
            "  üíæ New Best MRR: 0.4664 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0620 | Val MRR: 0.5387 | R@1: 0.3830\n",
            "  üíæ New Best MRR: 0.5387 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0463 | Val MRR: 0.5670 | R@1: 0.4160\n",
            "  üíæ New Best MRR: 0.5670 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0375 | Val MRR: 0.6405 | R@1: 0.4960\n",
            "  üíæ New Best MRR: 0.6405 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0304 | Val MRR: 0.6544 | R@1: 0.5080\n",
            "  üíæ New Best MRR: 0.6544 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0261 | Val MRR: 0.6736 | R@1: 0.5230\n",
            "  üíæ New Best MRR: 0.6736 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0222 | Val MRR: 0.6951 | R@1: 0.5560\n",
            "  üíæ New Best MRR: 0.6951 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0208 | Val MRR: 0.7181 | R@1: 0.5750\n",
            "  üíæ New Best MRR: 0.7181 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0178 | Val MRR: 0.7366 | R@1: 0.6060\n",
            "  üíæ New Best MRR: 0.7366 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0165 | Val MRR: 0.7519 | R@1: 0.6320\n",
            "  üíæ New Best MRR: 0.7519 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0149 | Val MRR: 0.7732 | R@1: 0.6550\n",
            "  üíæ New Best MRR: 0.7732 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0135 | Val MRR: 0.7661 | R@1: 0.6450\n",
            "Epoch 15/100 | Train Loss: 0.0122 | Val MRR: 0.7925 | R@1: 0.6780\n",
            "  üíæ New Best MRR: 0.7925 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0118 | Val MRR: 0.7923 | R@1: 0.6810\n",
            "Epoch 17/100 | Train Loss: 0.0116 | Val MRR: 0.7904 | R@1: 0.6760\n",
            "Epoch 18/100 | Train Loss: 0.0110 | Val MRR: 0.8140 | R@1: 0.7030\n",
            "  üíæ New Best MRR: 0.8140 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 19/100 | Train Loss: 0.0110 | Val MRR: 0.8083 | R@1: 0.7060\n",
            "Epoch 20/100 | Train Loss: 0.0098 | Val MRR: 0.8003 | R@1: 0.6900\n",
            "Epoch 21/100 | Train Loss: 0.0098 | Val MRR: 0.8166 | R@1: 0.7180\n",
            "  üíæ New Best MRR: 0.8166 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 22/100 | Train Loss: 0.0095 | Val MRR: 0.8014 | R@1: 0.6980\n",
            "Epoch 23/100 | Train Loss: 0.0089 | Val MRR: 0.8246 | R@1: 0.7240\n",
            "  üíæ New Best MRR: 0.8246 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 24/100 | Train Loss: 0.0089 | Val MRR: 0.8322 | R@1: 0.7370\n",
            "  üíæ New Best MRR: 0.8322 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0083 | Val MRR: 0.8421 | R@1: 0.7500\n",
            "  üíæ New Best MRR: 0.8421 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 26/100 | Train Loss: 0.0079 | Val MRR: 0.8354 | R@1: 0.7420\n",
            "Epoch 27/100 | Train Loss: 0.0079 | Val MRR: 0.8423 | R@1: 0.7550\n",
            "  üíæ New Best MRR: 0.8423 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0072 | Val MRR: 0.8324 | R@1: 0.7380\n",
            "Epoch 29/100 | Train Loss: 0.0075 | Val MRR: 0.8339 | R@1: 0.7440\n",
            "Epoch 30/100 | Train Loss: 0.0070 | Val MRR: 0.8468 | R@1: 0.7580\n",
            "  üíæ New Best MRR: 0.8468 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 31/100 | Train Loss: 0.0067 | Val MRR: 0.8414 | R@1: 0.7520\n",
            "Epoch 32/100 | Train Loss: 0.0063 | Val MRR: 0.8431 | R@1: 0.7520\n",
            "Epoch 33/100 | Train Loss: 0.0062 | Val MRR: 0.8435 | R@1: 0.7580\n",
            "Epoch 34/100 | Train Loss: 0.0062 | Val MRR: 0.8506 | R@1: 0.7650\n",
            "  üíæ New Best MRR: 0.8506 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 35/100 | Train Loss: 0.0060 | Val MRR: 0.8649 | R@1: 0.7880\n",
            "  üíæ New Best MRR: 0.8649 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 36/100 | Train Loss: 0.0057 | Val MRR: 0.8607 | R@1: 0.7770\n",
            "Epoch 37/100 | Train Loss: 0.0059 | Val MRR: 0.8576 | R@1: 0.7750\n",
            "Epoch 38/100 | Train Loss: 0.0053 | Val MRR: 0.8562 | R@1: 0.7680\n",
            "Epoch 39/100 | Train Loss: 0.0054 | Val MRR: 0.8629 | R@1: 0.7820\n",
            "Epoch 40/100 | Train Loss: 0.0057 | Val MRR: 0.8624 | R@1: 0.7770\n",
            "Epoch 41/100 | Train Loss: 0.0059 | Val MRR: 0.8610 | R@1: 0.7790\n",
            "Epoch 42/100 | Train Loss: 0.0049 | Val MRR: 0.8646 | R@1: 0.7850\n",
            "Epoch 43/100 | Train Loss: 0.0051 | Val MRR: 0.8746 | R@1: 0.8010\n",
            "  üíæ New Best MRR: 0.8746 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 44/100 | Train Loss: 0.0051 | Val MRR: 0.8776 | R@1: 0.8070\n",
            "  üíæ New Best MRR: 0.8776 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 45/100 | Train Loss: 0.0044 | Val MRR: 0.8672 | R@1: 0.7900\n",
            "Epoch 46/100 | Train Loss: 0.0047 | Val MRR: 0.8825 | R@1: 0.8150\n",
            "  üíæ New Best MRR: 0.8825 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 47/100 | Train Loss: 0.0045 | Val MRR: 0.8780 | R@1: 0.8050\n",
            "Epoch 48/100 | Train Loss: 0.0043 | Val MRR: 0.8856 | R@1: 0.8190\n",
            "  üíæ New Best MRR: 0.8856 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 49/100 | Train Loss: 0.0041 | Val MRR: 0.8804 | R@1: 0.8090\n",
            "Epoch 50/100 | Train Loss: 0.0043 | Val MRR: 0.8838 | R@1: 0.8130\n",
            "Epoch 51/100 | Train Loss: 0.0041 | Val MRR: 0.8791 | R@1: 0.8030\n",
            "Epoch 52/100 | Train Loss: 0.0041 | Val MRR: 0.8845 | R@1: 0.8150\n",
            "Epoch 53/100 | Train Loss: 0.0041 | Val MRR: 0.8876 | R@1: 0.8180\n",
            "  üíæ New Best MRR: 0.8876 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 54/100 | Train Loss: 0.0039 | Val MRR: 0.8912 | R@1: 0.8250\n",
            "  üíæ New Best MRR: 0.8912 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 55/100 | Train Loss: 0.0037 | Val MRR: 0.9001 | R@1: 0.8380\n",
            "  üíæ New Best MRR: 0.9001 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 56/100 | Train Loss: 0.0035 | Val MRR: 0.8909 | R@1: 0.8240\n",
            "Epoch 57/100 | Train Loss: 0.0037 | Val MRR: 0.8919 | R@1: 0.8290\n",
            "Epoch 58/100 | Train Loss: 0.0032 | Val MRR: 0.8980 | R@1: 0.8360\n",
            "Epoch 59/100 | Train Loss: 0.0034 | Val MRR: 0.8896 | R@1: 0.8210\n",
            "Epoch 60/100 | Train Loss: 0.0032 | Val MRR: 0.8923 | R@1: 0.8210\n",
            "Epoch 61/100 | Train Loss: 0.0032 | Val MRR: 0.8935 | R@1: 0.8300\n",
            "Epoch 62/100 | Train Loss: 0.0034 | Val MRR: 0.9041 | R@1: 0.8440\n",
            "  üíæ New Best MRR: 0.9041 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 63/100 | Train Loss: 0.0033 | Val MRR: 0.9049 | R@1: 0.8480\n",
            "  üíæ New Best MRR: 0.9049 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 64/100 | Train Loss: 0.0031 | Val MRR: 0.8966 | R@1: 0.8320\n",
            "Epoch 65/100 | Train Loss: 0.0028 | Val MRR: 0.8944 | R@1: 0.8280\n",
            "Epoch 66/100 | Train Loss: 0.0028 | Val MRR: 0.9011 | R@1: 0.8410\n",
            "Epoch 67/100 | Train Loss: 0.0027 | Val MRR: 0.8993 | R@1: 0.8350\n",
            "Epoch 68/100 | Train Loss: 0.0027 | Val MRR: 0.9070 | R@1: 0.8480\n",
            "  üíæ New Best MRR: 0.9070 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 69/100 | Train Loss: 0.0027 | Val MRR: 0.9056 | R@1: 0.8450\n",
            "Epoch 70/100 | Train Loss: 0.0027 | Val MRR: 0.9100 | R@1: 0.8540\n",
            "  üíæ New Best MRR: 0.9100 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 71/100 | Train Loss: 0.0027 | Val MRR: 0.9120 | R@1: 0.8550\n",
            "  üíæ New Best MRR: 0.9120 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 72/100 | Train Loss: 0.0027 | Val MRR: 0.9063 | R@1: 0.8470\n",
            "Epoch 73/100 | Train Loss: 0.0024 | Val MRR: 0.9099 | R@1: 0.8530\n",
            "Epoch 74/100 | Train Loss: 0.0025 | Val MRR: 0.9165 | R@1: 0.8630\n",
            "  üíæ New Best MRR: 0.9165 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 75/100 | Train Loss: 0.0023 | Val MRR: 0.9220 | R@1: 0.8750\n",
            "  üíæ New Best MRR: 0.9220 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 76/100 | Train Loss: 0.0023 | Val MRR: 0.9158 | R@1: 0.8630\n",
            "Epoch 77/100 | Train Loss: 0.0023 | Val MRR: 0.9223 | R@1: 0.8740\n",
            "  üíæ New Best MRR: 0.9223 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 78/100 | Train Loss: 0.0023 | Val MRR: 0.9195 | R@1: 0.8710\n",
            "Epoch 79/100 | Train Loss: 0.0022 | Val MRR: 0.9148 | R@1: 0.8590\n",
            "Epoch 80/100 | Train Loss: 0.0022 | Val MRR: 0.9169 | R@1: 0.8660\n",
            "Epoch 81/100 | Train Loss: 0.0021 | Val MRR: 0.9218 | R@1: 0.8710\n",
            "Epoch 82/100 | Train Loss: 0.0020 | Val MRR: 0.9167 | R@1: 0.8630\n",
            "Epoch 83/100 | Train Loss: 0.0020 | Val MRR: 0.9152 | R@1: 0.8600\n",
            "Epoch 84/100 | Train Loss: 0.0023 | Val MRR: 0.9187 | R@1: 0.8660\n",
            "Epoch 85/100 | Train Loss: 0.0020 | Val MRR: 0.9250 | R@1: 0.8770\n",
            "  üíæ New Best MRR: 0.9250 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt\n",
            "Epoch 86/100 | Train Loss: 0.0021 | Val MRR: 0.9231 | R@1: 0.8740\n",
            "Epoch 87/100 | Train Loss: 0.0021 | Val MRR: 0.9221 | R@1: 0.8720\n",
            "Epoch 88/100 | Train Loss: 0.0019 | Val MRR: 0.9207 | R@1: 0.8680\n",
            "Epoch 89/100 | Train Loss: 0.0019 | Val MRR: 0.9167 | R@1: 0.8610\n",
            "Epoch 90/100 | Train Loss: 0.0019 | Val MRR: 0.9175 | R@1: 0.8640\n",
            "Epoch 91/100 | Train Loss: 0.0020 | Val MRR: 0.9222 | R@1: 0.8710\n",
            "Epoch 92/100 | Train Loss: 0.0020 | Val MRR: 0.9220 | R@1: 0.8700\n",
            "Epoch 93/100 | Train Loss: 0.0020 | Val MRR: 0.9227 | R@1: 0.8710\n",
            "Epoch 94/100 | Train Loss: 0.0020 | Val MRR: 0.9225 | R@1: 0.8710\n",
            "Epoch 95/100 | Train Loss: 0.0020 | Val MRR: 0.9221 | R@1: 0.8690\n",
            "üõë Early stopping\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd1e-05_frz0_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 890.8min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 5/15 : Medium WD\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0005\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0005\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-11 07:17:27.080252: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-11 07:17:27.102093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768115847.127379  257813 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768115847.134552  257813 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768115847.152763  257813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768115847.152785  257813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768115847.152788  257813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768115847.152790  257813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 07:17:27.157746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2084 | Val MRR: 0.1656 | R@1: 0.0710\n",
            "  üíæ New Best MRR: 0.1656 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1621 | Val MRR: 0.3295 | R@1: 0.1840\n",
            "  üíæ New Best MRR: 0.3295 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.0947 | Val MRR: 0.4523 | R@1: 0.2970\n",
            "  üíæ New Best MRR: 0.4523 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0620 | Val MRR: 0.5329 | R@1: 0.3780\n",
            "  üíæ New Best MRR: 0.5329 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0461 | Val MRR: 0.6102 | R@1: 0.4600\n",
            "  üíæ New Best MRR: 0.6102 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0371 | Val MRR: 0.6247 | R@1: 0.4700\n",
            "  üíæ New Best MRR: 0.6247 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0305 | Val MRR: 0.6412 | R@1: 0.4910\n",
            "  üíæ New Best MRR: 0.6412 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0262 | Val MRR: 0.6917 | R@1: 0.5530\n",
            "  üíæ New Best MRR: 0.6917 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0229 | Val MRR: 0.6898 | R@1: 0.5500\n",
            "Epoch 10/100 | Train Loss: 0.0195 | Val MRR: 0.7045 | R@1: 0.5670\n",
            "  üíæ New Best MRR: 0.7045 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0186 | Val MRR: 0.7345 | R@1: 0.6060\n",
            "  üíæ New Best MRR: 0.7345 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0161 | Val MRR: 0.7259 | R@1: 0.5890\n",
            "Epoch 13/100 | Train Loss: 0.0146 | Val MRR: 0.7629 | R@1: 0.6320\n",
            "  üíæ New Best MRR: 0.7629 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 14/100 | Train Loss: 0.0139 | Val MRR: 0.7677 | R@1: 0.6500\n",
            "  üíæ New Best MRR: 0.7677 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0125 | Val MRR: 0.7831 | R@1: 0.6630\n",
            "  üíæ New Best MRR: 0.7831 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 16/100 | Train Loss: 0.0116 | Val MRR: 0.7998 | R@1: 0.6920\n",
            "  üíæ New Best MRR: 0.7998 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0113 | Val MRR: 0.7928 | R@1: 0.6870\n",
            "Epoch 18/100 | Train Loss: 0.0111 | Val MRR: 0.7968 | R@1: 0.6850\n",
            "Epoch 19/100 | Train Loss: 0.0107 | Val MRR: 0.8056 | R@1: 0.7030\n",
            "  üíæ New Best MRR: 0.8056 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 20/100 | Train Loss: 0.0101 | Val MRR: 0.7981 | R@1: 0.6900\n",
            "Epoch 21/100 | Train Loss: 0.0091 | Val MRR: 0.8169 | R@1: 0.7130\n",
            "  üíæ New Best MRR: 0.8169 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 22/100 | Train Loss: 0.0088 | Val MRR: 0.8214 | R@1: 0.7180\n",
            "  üíæ New Best MRR: 0.8214 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0087 | Val MRR: 0.8105 | R@1: 0.7050\n",
            "Epoch 24/100 | Train Loss: 0.0082 | Val MRR: 0.8081 | R@1: 0.7030\n",
            "Epoch 25/100 | Train Loss: 0.0088 | Val MRR: 0.8071 | R@1: 0.7040\n",
            "Epoch 26/100 | Train Loss: 0.0089 | Val MRR: 0.8185 | R@1: 0.7260\n",
            "Epoch 27/100 | Train Loss: 0.0085 | Val MRR: 0.8319 | R@1: 0.7400\n",
            "  üíæ New Best MRR: 0.8319 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0079 | Val MRR: 0.8408 | R@1: 0.7560\n",
            "  üíæ New Best MRR: 0.8408 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 29/100 | Train Loss: 0.0072 | Val MRR: 0.8300 | R@1: 0.7370\n",
            "Epoch 30/100 | Train Loss: 0.0073 | Val MRR: 0.8449 | R@1: 0.7580\n",
            "  üíæ New Best MRR: 0.8449 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 31/100 | Train Loss: 0.0073 | Val MRR: 0.8278 | R@1: 0.7300\n",
            "Epoch 32/100 | Train Loss: 0.0074 | Val MRR: 0.8284 | R@1: 0.7350\n",
            "Epoch 33/100 | Train Loss: 0.0074 | Val MRR: 0.8327 | R@1: 0.7410\n",
            "Epoch 34/100 | Train Loss: 0.0069 | Val MRR: 0.8264 | R@1: 0.7280\n",
            "Epoch 35/100 | Train Loss: 0.0069 | Val MRR: 0.8375 | R@1: 0.7490\n",
            "Epoch 36/100 | Train Loss: 0.0063 | Val MRR: 0.8423 | R@1: 0.7540\n",
            "Epoch 37/100 | Train Loss: 0.0055 | Val MRR: 0.8537 | R@1: 0.7670\n",
            "  üíæ New Best MRR: 0.8537 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 38/100 | Train Loss: 0.0060 | Val MRR: 0.8643 | R@1: 0.7840\n",
            "  üíæ New Best MRR: 0.8643 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 39/100 | Train Loss: 0.0062 | Val MRR: 0.8527 | R@1: 0.7660\n",
            "Epoch 40/100 | Train Loss: 0.0062 | Val MRR: 0.8548 | R@1: 0.7760\n",
            "Epoch 41/100 | Train Loss: 0.0059 | Val MRR: 0.8658 | R@1: 0.7860\n",
            "  üíæ New Best MRR: 0.8658 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 42/100 | Train Loss: 0.0053 | Val MRR: 0.8569 | R@1: 0.7740\n",
            "Epoch 43/100 | Train Loss: 0.0053 | Val MRR: 0.8686 | R@1: 0.7900\n",
            "  üíæ New Best MRR: 0.8686 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 44/100 | Train Loss: 0.0052 | Val MRR: 0.8599 | R@1: 0.7790\n",
            "Epoch 45/100 | Train Loss: 0.0050 | Val MRR: 0.8662 | R@1: 0.7860\n",
            "Epoch 46/100 | Train Loss: 0.0048 | Val MRR: 0.8781 | R@1: 0.8030\n",
            "  üíæ New Best MRR: 0.8781 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 47/100 | Train Loss: 0.0045 | Val MRR: 0.8786 | R@1: 0.8090\n",
            "  üíæ New Best MRR: 0.8786 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 48/100 | Train Loss: 0.0044 | Val MRR: 0.8791 | R@1: 0.8070\n",
            "  üíæ New Best MRR: 0.8791 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 49/100 | Train Loss: 0.0046 | Val MRR: 0.8856 | R@1: 0.8170\n",
            "  üíæ New Best MRR: 0.8856 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 50/100 | Train Loss: 0.0043 | Val MRR: 0.8780 | R@1: 0.8050\n",
            "Epoch 51/100 | Train Loss: 0.0042 | Val MRR: 0.8722 | R@1: 0.7960\n",
            "Epoch 52/100 | Train Loss: 0.0040 | Val MRR: 0.8824 | R@1: 0.8140\n",
            "Epoch 53/100 | Train Loss: 0.0040 | Val MRR: 0.8814 | R@1: 0.8120\n",
            "Epoch 54/100 | Train Loss: 0.0041 | Val MRR: 0.8780 | R@1: 0.8060\n",
            "Epoch 55/100 | Train Loss: 0.0038 | Val MRR: 0.8839 | R@1: 0.8180\n",
            "Epoch 56/100 | Train Loss: 0.0036 | Val MRR: 0.8811 | R@1: 0.8090\n",
            "Epoch 57/100 | Train Loss: 0.0036 | Val MRR: 0.8902 | R@1: 0.8220\n",
            "  üíæ New Best MRR: 0.8902 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 58/100 | Train Loss: 0.0037 | Val MRR: 0.8881 | R@1: 0.8200\n",
            "Epoch 59/100 | Train Loss: 0.0034 | Val MRR: 0.9040 | R@1: 0.8440\n",
            "  üíæ New Best MRR: 0.9040 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt\n",
            "Epoch 60/100 | Train Loss: 0.0034 | Val MRR: 0.8918 | R@1: 0.8290\n",
            "Epoch 61/100 | Train Loss: 0.0030 | Val MRR: 0.8928 | R@1: 0.8250\n",
            "Epoch 62/100 | Train Loss: 0.0033 | Val MRR: 0.8905 | R@1: 0.8210\n",
            "Epoch 63/100 | Train Loss: 0.0031 | Val MRR: 0.8983 | R@1: 0.8350\n",
            "Epoch 64/100 | Train Loss: 0.0032 | Val MRR: 0.8957 | R@1: 0.8300\n",
            "Epoch 65/100 | Train Loss: 0.0031 | Val MRR: 0.9022 | R@1: 0.8400\n",
            "Epoch 66/100 | Train Loss: 0.0028 | Val MRR: 0.8939 | R@1: 0.8300\n",
            "Epoch 67/100 | Train Loss: 0.0027 | Val MRR: 0.9021 | R@1: 0.8380\n",
            "Epoch 68/100 | Train Loss: 0.0030 | Val MRR: 0.8955 | R@1: 0.8290\n",
            "Epoch 69/100 | Train Loss: 0.0030 | Val MRR: 0.9017 | R@1: 0.8380\n",
            "üõë Early stopping\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd0.0005_frz0_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 1084.2min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 6/15 : High WD\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.001\n",
            "Margin      : 0.2\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.001\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.2\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-11 10:30:50.876125: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-11 10:30:50.898089: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768127450.925413  310279 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768127450.932863  310279 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768127450.951598  310279 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768127450.951621  310279 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768127450.951625  310279 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768127450.951626  310279 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 10:30:50.956663: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.2076 | Val MRR: 0.1638 | R@1: 0.0630\n",
            "  üíæ New Best MRR: 0.1638 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1603 | Val MRR: 0.3343 | R@1: 0.1970\n",
            "  üíæ New Best MRR: 0.3343 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.0946 | Val MRR: 0.4282 | R@1: 0.2600\n",
            "  üíæ New Best MRR: 0.4282 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0624 | Val MRR: 0.5223 | R@1: 0.3640\n",
            "  üíæ New Best MRR: 0.5223 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0459 | Val MRR: 0.5684 | R@1: 0.4080\n",
            "  üíæ New Best MRR: 0.5684 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0370 | Val MRR: 0.6409 | R@1: 0.4990\n",
            "  üíæ New Best MRR: 0.6409 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0307 | Val MRR: 0.6528 | R@1: 0.5080\n",
            "  üíæ New Best MRR: 0.6528 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0276 | Val MRR: 0.6653 | R@1: 0.5200\n",
            "  üíæ New Best MRR: 0.6653 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0237 | Val MRR: 0.6961 | R@1: 0.5520\n",
            "  üíæ New Best MRR: 0.6961 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0205 | Val MRR: 0.7277 | R@1: 0.5980\n",
            "  üíæ New Best MRR: 0.7277 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0192 | Val MRR: 0.7353 | R@1: 0.6060\n",
            "  üíæ New Best MRR: 0.7353 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0168 | Val MRR: 0.7563 | R@1: 0.6330\n",
            "  üíæ New Best MRR: 0.7563 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0147 | Val MRR: 0.7475 | R@1: 0.6250\n",
            "Epoch 14/100 | Train Loss: 0.0133 | Val MRR: 0.7713 | R@1: 0.6580\n",
            "  üíæ New Best MRR: 0.7713 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0125 | Val MRR: 0.7695 | R@1: 0.6490\n",
            "Epoch 16/100 | Train Loss: 0.0118 | Val MRR: 0.7944 | R@1: 0.6860\n",
            "  üíæ New Best MRR: 0.7944 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0118 | Val MRR: 0.8081 | R@1: 0.6990\n",
            "  üíæ New Best MRR: 0.8081 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 18/100 | Train Loss: 0.0110 | Val MRR: 0.7896 | R@1: 0.6780\n",
            "Epoch 19/100 | Train Loss: 0.0104 | Val MRR: 0.7947 | R@1: 0.6800\n",
            "Epoch 20/100 | Train Loss: 0.0098 | Val MRR: 0.7928 | R@1: 0.6820\n",
            "Epoch 21/100 | Train Loss: 0.0098 | Val MRR: 0.8176 | R@1: 0.7170\n",
            "  üíæ New Best MRR: 0.8176 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 22/100 | Train Loss: 0.0092 | Val MRR: 0.8192 | R@1: 0.7210\n",
            "  üíæ New Best MRR: 0.8192 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 23/100 | Train Loss: 0.0087 | Val MRR: 0.8171 | R@1: 0.7140\n",
            "Epoch 24/100 | Train Loss: 0.0088 | Val MRR: 0.8347 | R@1: 0.7450\n",
            "  üíæ New Best MRR: 0.8347 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 25/100 | Train Loss: 0.0084 | Val MRR: 0.8153 | R@1: 0.7080\n",
            "Epoch 26/100 | Train Loss: 0.0084 | Val MRR: 0.8219 | R@1: 0.7270\n",
            "Epoch 27/100 | Train Loss: 0.0080 | Val MRR: 0.8381 | R@1: 0.7500\n",
            "  üíæ New Best MRR: 0.8381 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 28/100 | Train Loss: 0.0079 | Val MRR: 0.8300 | R@1: 0.7310\n",
            "Epoch 29/100 | Train Loss: 0.0078 | Val MRR: 0.8259 | R@1: 0.7270\n",
            "Epoch 30/100 | Train Loss: 0.0082 | Val MRR: 0.8266 | R@1: 0.7270\n",
            "Epoch 31/100 | Train Loss: 0.0078 | Val MRR: 0.8452 | R@1: 0.7520\n",
            "  üíæ New Best MRR: 0.8452 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 32/100 | Train Loss: 0.0072 | Val MRR: 0.8315 | R@1: 0.7320\n",
            "Epoch 33/100 | Train Loss: 0.0068 | Val MRR: 0.8431 | R@1: 0.7540\n",
            "Epoch 34/100 | Train Loss: 0.0074 | Val MRR: 0.8474 | R@1: 0.7550\n",
            "  üíæ New Best MRR: 0.8474 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 35/100 | Train Loss: 0.0065 | Val MRR: 0.8599 | R@1: 0.7840\n",
            "  üíæ New Best MRR: 0.8599 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 36/100 | Train Loss: 0.0065 | Val MRR: 0.8486 | R@1: 0.7550\n",
            "Epoch 37/100 | Train Loss: 0.0059 | Val MRR: 0.8605 | R@1: 0.7740\n",
            "  üíæ New Best MRR: 0.8605 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 38/100 | Train Loss: 0.0060 | Val MRR: 0.8594 | R@1: 0.7760\n",
            "Epoch 39/100 | Train Loss: 0.0058 | Val MRR: 0.8462 | R@1: 0.7510\n",
            "Epoch 40/100 | Train Loss: 0.0058 | Val MRR: 0.8533 | R@1: 0.7650\n",
            "Epoch 41/100 | Train Loss: 0.0054 | Val MRR: 0.8623 | R@1: 0.7760\n",
            "  üíæ New Best MRR: 0.8623 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 42/100 | Train Loss: 0.0055 | Val MRR: 0.8670 | R@1: 0.7870\n",
            "  üíæ New Best MRR: 0.8670 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 43/100 | Train Loss: 0.0056 | Val MRR: 0.8623 | R@1: 0.7770\n",
            "Epoch 44/100 | Train Loss: 0.0052 | Val MRR: 0.8721 | R@1: 0.7980\n",
            "  üíæ New Best MRR: 0.8721 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 45/100 | Train Loss: 0.0050 | Val MRR: 0.8683 | R@1: 0.7900\n",
            "Epoch 46/100 | Train Loss: 0.0045 | Val MRR: 0.8677 | R@1: 0.7860\n",
            "Epoch 47/100 | Train Loss: 0.0047 | Val MRR: 0.8801 | R@1: 0.8020\n",
            "  üíæ New Best MRR: 0.8801 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 48/100 | Train Loss: 0.0045 | Val MRR: 0.8766 | R@1: 0.8020\n",
            "Epoch 49/100 | Train Loss: 0.0042 | Val MRR: 0.8712 | R@1: 0.7950\n",
            "Epoch 50/100 | Train Loss: 0.0042 | Val MRR: 0.8708 | R@1: 0.7880\n",
            "Epoch 51/100 | Train Loss: 0.0044 | Val MRR: 0.8876 | R@1: 0.8220\n",
            "  üíæ New Best MRR: 0.8876 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 52/100 | Train Loss: 0.0042 | Val MRR: 0.8841 | R@1: 0.8130\n",
            "Epoch 53/100 | Train Loss: 0.0039 | Val MRR: 0.8782 | R@1: 0.8020\n",
            "Epoch 54/100 | Train Loss: 0.0038 | Val MRR: 0.8775 | R@1: 0.8020\n",
            "Epoch 55/100 | Train Loss: 0.0037 | Val MRR: 0.8968 | R@1: 0.8320\n",
            "  üíæ New Best MRR: 0.8968 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 56/100 | Train Loss: 0.0037 | Val MRR: 0.8871 | R@1: 0.8150\n",
            "Epoch 57/100 | Train Loss: 0.0037 | Val MRR: 0.8834 | R@1: 0.8090\n",
            "Epoch 58/100 | Train Loss: 0.0034 | Val MRR: 0.8971 | R@1: 0.8300\n",
            "  üíæ New Best MRR: 0.8971 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 59/100 | Train Loss: 0.0035 | Val MRR: 0.8987 | R@1: 0.8310\n",
            "  üíæ New Best MRR: 0.8987 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 60/100 | Train Loss: 0.0036 | Val MRR: 0.8993 | R@1: 0.8360\n",
            "  üíæ New Best MRR: 0.8993 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 61/100 | Train Loss: 0.0033 | Val MRR: 0.8977 | R@1: 0.8320\n",
            "Epoch 62/100 | Train Loss: 0.0033 | Val MRR: 0.9032 | R@1: 0.8400\n",
            "  üíæ New Best MRR: 0.9032 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 63/100 | Train Loss: 0.0032 | Val MRR: 0.8953 | R@1: 0.8320\n",
            "Epoch 64/100 | Train Loss: 0.0030 | Val MRR: 0.8974 | R@1: 0.8310\n",
            "Epoch 65/100 | Train Loss: 0.0029 | Val MRR: 0.9008 | R@1: 0.8390\n",
            "Epoch 66/100 | Train Loss: 0.0029 | Val MRR: 0.9047 | R@1: 0.8480\n",
            "  üíæ New Best MRR: 0.9047 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 67/100 | Train Loss: 0.0028 | Val MRR: 0.8939 | R@1: 0.8270\n",
            "Epoch 68/100 | Train Loss: 0.0031 | Val MRR: 0.9019 | R@1: 0.8400\n",
            "Epoch 69/100 | Train Loss: 0.0027 | Val MRR: 0.8985 | R@1: 0.8370\n",
            "Epoch 70/100 | Train Loss: 0.0027 | Val MRR: 0.8998 | R@1: 0.8390\n",
            "Epoch 71/100 | Train Loss: 0.0024 | Val MRR: 0.9069 | R@1: 0.8450\n",
            "  üíæ New Best MRR: 0.9069 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 72/100 | Train Loss: 0.0028 | Val MRR: 0.9078 | R@1: 0.8480\n",
            "  üíæ New Best MRR: 0.9078 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 73/100 | Train Loss: 0.0023 | Val MRR: 0.9075 | R@1: 0.8480\n",
            "Epoch 74/100 | Train Loss: 0.0026 | Val MRR: 0.9054 | R@1: 0.8470\n",
            "Epoch 75/100 | Train Loss: 0.0024 | Val MRR: 0.9066 | R@1: 0.8470\n",
            "Epoch 76/100 | Train Loss: 0.0025 | Val MRR: 0.9131 | R@1: 0.8570\n",
            "  üíæ New Best MRR: 0.9131 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 77/100 | Train Loss: 0.0022 | Val MRR: 0.9137 | R@1: 0.8580\n",
            "  üíæ New Best MRR: 0.9137 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 78/100 | Train Loss: 0.0023 | Val MRR: 0.9123 | R@1: 0.8580\n",
            "Epoch 79/100 | Train Loss: 0.0025 | Val MRR: 0.9117 | R@1: 0.8540\n",
            "Epoch 80/100 | Train Loss: 0.0022 | Val MRR: 0.9162 | R@1: 0.8630\n",
            "  üíæ New Best MRR: 0.9162 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 81/100 | Train Loss: 0.0023 | Val MRR: 0.9186 | R@1: 0.8690\n",
            "  üíæ New Best MRR: 0.9186 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 82/100 | Train Loss: 0.0025 | Val MRR: 0.9157 | R@1: 0.8610\n",
            "Epoch 83/100 | Train Loss: 0.0022 | Val MRR: 0.9181 | R@1: 0.8650\n",
            "Epoch 84/100 | Train Loss: 0.0021 | Val MRR: 0.9184 | R@1: 0.8660\n",
            "Epoch 85/100 | Train Loss: 0.0022 | Val MRR: 0.9117 | R@1: 0.8550\n",
            "Epoch 86/100 | Train Loss: 0.0020 | Val MRR: 0.9178 | R@1: 0.8650\n",
            "Epoch 87/100 | Train Loss: 0.0020 | Val MRR: 0.9182 | R@1: 0.8660\n",
            "Epoch 88/100 | Train Loss: 0.0020 | Val MRR: 0.9193 | R@1: 0.8680\n",
            "  üíæ New Best MRR: 0.9193 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 89/100 | Train Loss: 0.0022 | Val MRR: 0.9218 | R@1: 0.8730\n",
            "  üíæ New Best MRR: 0.9218 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 90/100 | Train Loss: 0.0022 | Val MRR: 0.9230 | R@1: 0.8740\n",
            "  üíæ New Best MRR: 0.9230 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 91/100 | Train Loss: 0.0019 | Val MRR: 0.9165 | R@1: 0.8640\n",
            "Epoch 92/100 | Train Loss: 0.0020 | Val MRR: 0.9216 | R@1: 0.8720\n",
            "Epoch 93/100 | Train Loss: 0.0022 | Val MRR: 0.9199 | R@1: 0.8690\n",
            "Epoch 94/100 | Train Loss: 0.0021 | Val MRR: 0.9209 | R@1: 0.8700\n",
            "Epoch 95/100 | Train Loss: 0.0021 | Val MRR: 0.9182 | R@1: 0.8670\n",
            "Epoch 96/100 | Train Loss: 0.0020 | Val MRR: 0.9242 | R@1: 0.8770\n",
            "  üíæ New Best MRR: 0.9242 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt\n",
            "Epoch 97/100 | Train Loss: 0.0020 | Val MRR: 0.9196 | R@1: 0.8700\n",
            "Epoch 98/100 | Train Loss: 0.0019 | Val MRR: 0.9213 | R@1: 0.8720\n",
            "Epoch 99/100 | Train Loss: 0.0020 | Val MRR: 0.9195 | R@1: 0.8670\n",
            "Epoch 100/100 | Train Loss: 0.0020 | Val MRR: 0.9208 | R@1: 0.8720\n",
            "üì¶ Copie vers Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_lrGNN0.0008_lrBERT3e-05_wd0.001_frz0_margin0.2_bs128.pt ...\n",
            "‚úÖ Copie termin√©e.\n",
            "\n",
            "üíæ CSV mis √† jour sur Drive : /content/drive/MyDrive/Altegrad_Results/GridSearch_DualEncoder/dual_encoder_results.csv\n",
            "\n",
            "‚è±Ô∏è  Temps √©coul√© : 1362.3min\n",
            "\n",
            "‚è∏Ô∏è  Pause de 30s...\n",
            "\n",
            "================================================================================\n",
            "RUN 7/15 : Low Margin\n",
            "================================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Freeze      : 0 layers\n",
            "Weight Decay: 0.0001\n",
            "Margin      : 0.15\n",
            "================================================================================\n",
            "======================================================================\n",
            "üöÄ DUAL ENCODER TRAINING - OPTIMIZED (AMP FIX)\n",
            "======================================================================\n",
            "LR GNN      : 0.0008\n",
            "LR BERT     : 3e-05\n",
            "Weight Decay: 0.0001\n",
            "Freeze Layers: 0\n",
            "Margin      : 0.15\n",
            "Batch Size  : 16 √ó 8 = 128 (effective)\n",
            "======================================================================\n",
            "2026-01-11 15:08:58.182618: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-11 15:08:58.204781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768144138.230260  384895 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768144138.237541  384895 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768144138.256326  384895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768144138.256351  384895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768144138.256355  384895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768144138.256357  384895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 15:08:58.261302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/content/BornToOverfit/data_baseline/train_dual_encoder_optimized.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100 | Train Loss: 0.1590 | Val MRR: 0.1472 | R@1: 0.0580\n",
            "  üíæ New Best MRR: 0.1472 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 2/100 | Train Loss: 0.1197 | Val MRR: 0.3237 | R@1: 0.1910\n",
            "  üíæ New Best MRR: 0.3237 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 3/100 | Train Loss: 0.0662 | Val MRR: 0.4821 | R@1: 0.3290\n",
            "  üíæ New Best MRR: 0.4821 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 4/100 | Train Loss: 0.0434 | Val MRR: 0.5166 | R@1: 0.3520\n",
            "  üíæ New Best MRR: 0.5166 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 5/100 | Train Loss: 0.0313 | Val MRR: 0.5893 | R@1: 0.4360\n",
            "  üíæ New Best MRR: 0.5893 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 6/100 | Train Loss: 0.0256 | Val MRR: 0.6291 | R@1: 0.4820\n",
            "  üíæ New Best MRR: 0.6291 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 7/100 | Train Loss: 0.0207 | Val MRR: 0.6382 | R@1: 0.4900\n",
            "  üíæ New Best MRR: 0.6382 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 8/100 | Train Loss: 0.0179 | Val MRR: 0.6575 | R@1: 0.5100\n",
            "  üíæ New Best MRR: 0.6575 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 9/100 | Train Loss: 0.0156 | Val MRR: 0.6846 | R@1: 0.5420\n",
            "  üíæ New Best MRR: 0.6846 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 10/100 | Train Loss: 0.0136 | Val MRR: 0.7036 | R@1: 0.5700\n",
            "  üíæ New Best MRR: 0.7036 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 11/100 | Train Loss: 0.0125 | Val MRR: 0.7262 | R@1: 0.5960\n",
            "  üíæ New Best MRR: 0.7262 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 12/100 | Train Loss: 0.0114 | Val MRR: 0.7469 | R@1: 0.6200\n",
            "  üíæ New Best MRR: 0.7469 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 13/100 | Train Loss: 0.0101 | Val MRR: 0.7405 | R@1: 0.6150\n",
            "Epoch 14/100 | Train Loss: 0.0096 | Val MRR: 0.7661 | R@1: 0.6440\n",
            "  üíæ New Best MRR: 0.7661 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 15/100 | Train Loss: 0.0090 | Val MRR: 0.7194 | R@1: 0.5780\n",
            "Epoch 16/100 | Train Loss: 0.0082 | Val MRR: 0.7671 | R@1: 0.6370\n",
            "  üíæ New Best MRR: 0.7671 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 17/100 | Train Loss: 0.0078 | Val MRR: 0.7989 | R@1: 0.6920\n",
            "  üíæ New Best MRR: 0.7989 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 18/100 | Train Loss: 0.0074 | Val MRR: 0.7880 | R@1: 0.6710\n",
            "Epoch 19/100 | Train Loss: 0.0069 | Val MRR: 0.7891 | R@1: 0.6810\n",
            "Epoch 20/100 | Train Loss: 0.0067 | Val MRR: 0.7993 | R@1: 0.6920\n",
            "  üíæ New Best MRR: 0.7993 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 21/100 | Train Loss: 0.0064 | Val MRR: 0.7938 | R@1: 0.6830\n",
            "Epoch 22/100 | Train Loss: 0.0063 | Val MRR: 0.7915 | R@1: 0.6810\n",
            "Epoch 23/100 | Train Loss: 0.0067 | Val MRR: 0.8017 | R@1: 0.6910\n",
            "  üíæ New Best MRR: 0.8017 | Saved: dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.15_bs128.pt\n",
            "Epoch 24/100 | Train Loss: 0.0066 | Val MRR: 0.7997 | R@1: 0.6910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## other code analyse"
      ],
      "metadata": {
        "id": "IcJuG_yLbFXF"
      },
      "id": "IcJuG_yLbFXF"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# =========================================================\n",
        "# ANALYSE DES R√âSULTATS DUAL ENCODER\n",
        "# =========================================================\n",
        "csv_path = 'data_baseline/dual_encoder_results.csv'\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df_sorted = df.sort_values(by='MRR', ascending=False)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìä ANALYSE D√âTAILL√âE - DUAL ENCODER\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Statistiques globales\n",
        "print(f\"\\nNombre d'exp√©riences : {len(df)}\")\n",
        "print(f\"Runs r√©ussis         : {sum('‚úÖ' in str(s) for s in df['Status'])}\")\n",
        "print(f\"Temps total          : {df['Time_min'].sum() / 60:.1f}h\")\n",
        "print(f\"Temps moyen/run      : {df['Time_min'].mean():.1f}min\")\n",
        "\n",
        "print(f\"\\nüìà STATISTIQUES MRR :\")\n",
        "print(f\"   Moyenne : {df['MRR'].mean():.4f}\")\n",
        "print(f\"   M√©diane : {df['MRR'].median():.4f}\")\n",
        "print(f\"   Min     : {df['MRR'].min():.4f}\")\n",
        "print(f\"   Max     : {df['MRR'].max():.4f}\")\n",
        "print(f\"   Std     : {df['MRR'].std():.4f}\")\n",
        "\n",
        "# TOP 10\n",
        "print(\"\\nüèÜ TOP 10 CONFIGURATIONS :\")\n",
        "print(\"-\" * 80)\n",
        "cols = ['Run', 'Name', 'LR_BERT', 'Freeze_Layers', 'Weight_Decay', 'Margin', 'MRR', 'R@1']\n",
        "print(df_sorted[cols].head(10).to_string(index=False))\n",
        "\n",
        "# MEILLEURE PAR CAT√âGORIE\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ü•á MEILLEURES CONFIGS PAR CAT√âGORIE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Meilleure Full Training\n",
        "df_full = df[df['Freeze_Layers'] == 0].sort_values('MRR', ascending=False)\n",
        "if len(df_full) > 0:\n",
        "    best_full = df_full.iloc[0]\n",
        "    print(f\"\\n1. FULL TRAINING (Freeze=0)\")\n",
        "    print(f\"   Config : {best_full['Name']}\")\n",
        "    print(f\"   LR BERT: {best_full['LR_BERT']}\")\n",
        "    print(f\"   MRR    : {best_full['MRR']:.4f}\")\n",
        "\n",
        "# Meilleure Freeze\n",
        "df_freeze = df[df['Freeze_Layers'] > 0].sort_values('MRR', ascending=False)\n",
        "if len(df_freeze) > 0:\n",
        "    best_freeze = df_freeze.iloc[0]\n",
        "    print(f\"\\n2. FROZEN LAYERS (Freeze>0)\")\n",
        "    print(f\"   Config : {best_freeze['Name']}\")\n",
        "    print(f\"   Freeze : {best_freeze['Freeze_Layers']} layers\")\n",
        "    print(f\"   MRR    : {best_freeze['MRR']:.4f}\")\n",
        "\n",
        "    # Comparaison Full vs Freeze\n",
        "    if len(df_full) > 0:\n",
        "        print(f\"\\n   üìä Full vs Freeze :\")\n",
        "        print(f\"      Full : MRR {best_full['MRR']:.4f} | Temps {best_full['Time_min']:.1f}min\")\n",
        "        print(f\"      Freeze: MRR {best_freeze['MRR']:.4f} | Temps {best_freeze['Time_min']:.1f}min\")\n",
        "        print(f\"      Gain MRR   : {(best_full['MRR'] - best_freeze['MRR']):+.4f}\")\n",
        "        print(f\"      Gain Temps : {(best_freeze['Time_min'] - best_full['Time_min']):.1f}min\")\n",
        "\n",
        "# Heatmap LR BERT vs Freeze\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üî• HEATMAP : LR_BERT √ó FREEZE_LAYERS (MRR moyen)\")\n",
        "print(\"=\" * 80)\n",
        "heatmap = df.pivot_table(values='MRR', index='LR_BERT', columns='Freeze_Layers', aggfunc='mean')\n",
        "print(heatmap.to_string())\n",
        "\n",
        "# Recommandations\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üí° RECOMMANDATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "best_overall = df_sorted.iloc[0]\n",
        "print(f\"\\n1. MEILLEURE CONFIG GLOBALE :\")\n",
        "print(f\"   ‚Üí {best_overall['Name']}\")\n",
        "print(f\"   ‚Üí MRR : {best_overall['MRR']:.4f}\")\n",
        "\n",
        "# Meilleur compromis temps/perf\n",
        "df['efficiency'] = df['MRR'] / (df['Time_min'] / 60)  # MRR par heure\n",
        "best_efficient = df.sort_values('efficiency', ascending=False).iloc[0]\n",
        "print(f\"\\n2. MEILLEUR COMPROMIS TEMPS/PERFORMANCE :\")\n",
        "print(f\"   ‚Üí {best_efficient['Name']}\")\n",
        "print(f\"   ‚Üí MRR : {best_efficient['MRR']:.4f} en {best_efficient['Time_min']:.1f}min\")\n",
        "print(f\"   ‚Üí Efficiency : {best_efficient['efficiency']:.4f} MRR/h\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ],
      "metadata": {
        "id": "TevV8Lcl_8l5"
      },
      "id": "TevV8Lcl_8l5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip -q install -U evaluate bert-score sacrebleu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfvTZSwjMYJF",
        "outputId": "aaccc9b0-dd0f-4fed-8ca8-8310b61c7113"
      },
      "id": "NfvTZSwjMYJF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# autre test √† check si les suivant marchent pas"
      ],
      "metadata": {
        "id": "RrqA0r_abAR5"
      },
      "id": "RrqA0r_abAR5"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dual_encoder(checkpoint_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Charge un DualEncoder depuis un checkpoint (g√®re nouveau et ancien format).\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path: Chemin vers le fichier .pt\n",
        "        device: 'cuda' ou 'cpu'\n",
        "\n",
        "    Returns:\n",
        "        model: DualEncoder charg√©\n",
        "        config: Dictionnaire de config (si disponible)\n",
        "    \"\"\"\n",
        "    from data_baseline.train_dual_encoder_optimized import DualEncoder\n",
        "\n",
        "    checkpoint_path = Path(checkpoint_path)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # === FORMAT DETECTION ===\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        # ‚úÖ NOUVEAU FORMAT (avec metadata)\n",
        "        print(f\"‚úÖ Nouveau format d√©tect√©\")\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "\n",
        "        # Extrait config si disponible\n",
        "        if 'args' in checkpoint:\n",
        "            args = checkpoint['args']\n",
        "            gnn_config = {\n",
        "                'hidden_dim': args.get('hidden_dim', 256),\n",
        "                'out_dim': 768,\n",
        "                'num_layers': args.get('num_layers', 4),\n",
        "                'num_heads': args.get('num_heads', 4),\n",
        "                'dropout': args.get('dropout', 0.1),\n",
        "            }\n",
        "            freeze_layers = args.get('freeze_layers', 0)\n",
        "            model_name = args.get('model_name', 'recobo/chemical-bert-uncased')\n",
        "        else:\n",
        "            # Config par d√©faut\n",
        "            gnn_config = {\n",
        "                'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4,\n",
        "                'num_heads': 4, 'dropout': 0.1\n",
        "            }\n",
        "            freeze_layers = 0\n",
        "            model_name = 'recobo/chemical-bert-uncased'\n",
        "\n",
        "        print(f\"   Config GNN : {gnn_config}\")\n",
        "        print(f\"   Freeze     : {freeze_layers} layers\")\n",
        "\n",
        "    elif isinstance(checkpoint, dict) and 'config' in checkpoint:\n",
        "        # ‚úÖ AUTRE NOUVEAU FORMAT (avec 'config' directement)\n",
        "        print(f\"‚úÖ Nouveau format (avec config) d√©tect√©\")\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        config = checkpoint['config']\n",
        "        # Adapter selon ta structure\n",
        "        gnn_config = config.get('gnn_config', {})\n",
        "        freeze_layers = config.get('freeze_layers', 0)\n",
        "        model_name = config.get('model_name', 'recobo/chemical-bert-uncased')\n",
        "\n",
        "    else:\n",
        "        # ‚ùå ANCIEN FORMAT (juste state_dict)\n",
        "        print(f\"‚ö†Ô∏è  Ancien format d√©tect√© (pas de metadata)\")\n",
        "        state_dict = checkpoint\n",
        "\n",
        "        # Config par d√©faut (√† ajuster selon tes besoins)\n",
        "        gnn_config = {\n",
        "            'hidden_dim': 256,\n",
        "            'out_dim': 768,\n",
        "            'num_layers': 4,\n",
        "            'num_heads': 4,\n",
        "            'dropout': 0.1,\n",
        "        }\n",
        "        freeze_layers = 0\n",
        "        model_name = 'recobo/chemical-bert-uncased'\n",
        "\n",
        "        print(f\"   ‚ö†Ô∏è  Utilisation de config par d√©faut : {gnn_config}\")\n",
        "\n",
        "    # === CR√âATION DU MOD√àLE ===\n",
        "    model = DualEncoder(\n",
        "        model_name=model_name,\n",
        "        gnn_args=gnn_config,\n",
        "        freeze_layers=freeze_layers\n",
        "    )\n",
        "\n",
        "    # === CHARGEMENT DES POIDS ===\n",
        "    try:\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        print(f\"‚úÖ Mod√®le charg√© avec succ√®s (strict=True)\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"‚ö†Ô∏è  Chargement strict √©chou√©, essai non-strict...\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "        print(f\"‚ö†Ô∏è  Mod√®le charg√© (strict=False) - Certains poids peuvent manquer\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, gnn_config\n",
        "\n",
        "\n",
        "# === UTILISATION ===\n",
        "checkpoint_path = \"data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\"\n",
        "model, config = load_dual_encoder(checkpoint_path, device='cuda')\n",
        "\n",
        "print(f\"\\nüìä Mod√®le pr√™t pour √©valuation\")\n",
        "print(f\"   Config : {config}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jguhrdW6NHSp",
        "outputId": "6f42e3e5-d533-4b23-f23b-b0ff5e00735f"
      },
      "id": "jguhrdW6NHSp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Nouveau format d√©tect√©\n",
            "   Config GNN : {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}\n",
            "   Freeze     : 0 layers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© avec succ√®s (strict=True)\n",
            "\n",
            "üìä Mod√®le pr√™t pour √©valuation\n",
            "   Config : {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "from data_baseline.train_dual_encoder_optimized import DualEncoder, RawTextGraphDataset, DualCollate\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def load_dual_encoder(checkpoint_path, device='cuda'):\n",
        "    \"\"\"Charge un DualEncoder (g√®re nouveau et ancien format).\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # D√©tection du format\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        # Nouveau format\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        args = checkpoint.get('args', {})\n",
        "\n",
        "        gnn_config = {\n",
        "            'hidden_dim': args.get('hidden_dim', 256),\n",
        "            'out_dim': 768,\n",
        "            'num_layers': args.get('num_layers', 4),\n",
        "            'num_heads': args.get('num_heads', 4),\n",
        "            'dropout': args.get('dropout', 0.1),\n",
        "        }\n",
        "        freeze_layers = args.get('freeze_layers', 0)\n",
        "        model_name = args.get('model_name', 'recobo/chemical-bert-uncased')\n",
        "\n",
        "        print(f\"‚úÖ Nouveau format - Config: {gnn_config}, Freeze: {freeze_layers}\")\n",
        "    else:\n",
        "        # Ancien format\n",
        "        state_dict = checkpoint\n",
        "        gnn_config = {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}\n",
        "        freeze_layers = 0\n",
        "        model_name = 'recobo/chemical-bert-uncased'\n",
        "        print(f\"‚ö†Ô∏è  Ancien format - Config par d√©faut\")\n",
        "\n",
        "    # Cr√©ation et chargement\n",
        "    model = DualEncoder(model_name, gnn_config, freeze_layers)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, gnn_config\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_dual_encoder(model, val_loader, device):\n",
        "    \"\"\"√âvalue le MRR sur le validation set.\"\"\"\n",
        "    all_g_emb, all_t_emb = [], []\n",
        "\n",
        "    for graphs, text_inputs in val_loader:\n",
        "        graphs = graphs.to(device)\n",
        "        text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
        "\n",
        "        g_emb, t_emb = model(graphs, text_inputs)\n",
        "        all_g_emb.append(g_emb)\n",
        "        all_t_emb.append(t_emb)\n",
        "\n",
        "    all_g_emb = torch.cat(all_g_emb, dim=0)\n",
        "    all_t_emb = torch.cat(all_t_emb, dim=0)\n",
        "\n",
        "    # Text-to-Molecule retrieval\n",
        "    sims = all_t_emb @ all_g_emb.t()\n",
        "    ranks = sims.argsort(dim=-1, descending=True)\n",
        "\n",
        "    N = sims.size(0)\n",
        "    correct = torch.arange(N, device=device)\n",
        "    positions = (ranks == correct.unsqueeze(1)).nonzero()[:, 1] + 1\n",
        "\n",
        "    mrr = (1.0 / positions.float()).mean().item()\n",
        "    r1 = (positions <= 1).float().mean().item()\n",
        "    r5 = (positions <= 5).float().mean().item()\n",
        "    r10 = (positions <= 10).float().mean().item()\n",
        "\n",
        "    return {'MRR': mrr, 'R@1': r1, 'R@5': r5, 'R@10': r10}\n",
        "\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Fonction principale d'√©valuation.\"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"‚öôÔ∏è  Configuration : {device}\")\n",
        "\n",
        "    # Chemins\n",
        "    checkpoint_path = \"data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\"\n",
        "    val_data_path = \"data_baseline/data/validation_graphs.pkl\"\n",
        "\n",
        "    print(f\"üì• Chargement du Dual Encoder depuis {checkpoint_path}\")\n",
        "\n",
        "    # Charge le mod√®le\n",
        "    model, config = load_dual_encoder(checkpoint_path, device)\n",
        "\n",
        "    # Pr√©pare le DataLoader\n",
        "    tokenizer = AutoTokenizer.from_pretrained('recobo/chemical-bert-uncased')\n",
        "    val_dataset = RawTextGraphDataset(val_data_path)\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=64,\n",
        "        shuffle=False,\n",
        "        collate_fn=DualCollate(tokenizer),\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    print(f\"üìä √âvaluation sur {len(val_dataset)} exemples...\")\n",
        "\n",
        "    # √âvaluation\n",
        "    metrics = evaluate_dual_encoder(model, val_loader, device)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üèÜ R√âSULTATS DUAL ENCODER\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"MRR  : {metrics['MRR']:.4f}\")\n",
        "    print(f\"R@1  : {metrics['R@1']:.4f}\")\n",
        "    print(f\"R@5  : {metrics['R@5']:.4f}\")\n",
        "    print(f\"R@10 : {metrics['R@10']:.4f}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUJKYtW8Nnr8",
        "outputId": "8b19dbc2-92e9-45a5-e677-6f6d420bc582"
      },
      "id": "yUJKYtW8Nnr8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è  Configuration : cuda\n",
            "üì• Chargement du Dual Encoder depuis data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Nouveau format - Config: {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}, Freeze: 0\n",
            "üìä √âvaluation sur 1000 exemples...\n",
            "\n",
            "============================================================\n",
            "üèÜ R√âSULTATS DUAL ENCODER\n",
            "============================================================\n",
            "MRR  : 0.9398\n",
            "R@1  : 0.9030\n",
            "R@5  : 0.9850\n",
            "R@10 : 0.9920\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.nn import GPSConv, GINEConv, global_add_pool\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import evaluate\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================================================================\n",
        "# 0. CONFIGURATION\n",
        "# ==============================================================================\n",
        "MODEL_PATH = \"data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\"\n",
        "DATA_DIR = Path(\"data_baseline/data\")\n",
        "MODEL_NAME = \"recobo/chemical-bert-uncased\"\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"‚öôÔ∏è Configuration : {DEVICE}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. D√âFINITION DE L'ARCHITECTURE\n",
        "# ==============================================================================\n",
        "ATOM_DIMS = [119, 4, 11, 12, 9, 5, 8, 2, 2]\n",
        "BOND_DIMS = [22, 6, 2]\n",
        "\n",
        "class AtomEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in ATOM_DIMS])\n",
        "    def forward(self, x):\n",
        "        return sum(emb(x[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class BondEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in BOND_DIMS])\n",
        "    def forward(self, edge_attr):\n",
        "        return sum(emb(edge_attr[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class MolGNN(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, out_dim=768, num_layers=4, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.atom_encoder = AtomEncoder(hidden_dim)\n",
        "        self.bond_encoder = BondEncoder(hidden_dim)\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            local_nn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, 2 * hidden_dim),\n",
        "                nn.BatchNorm1d(2 * hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GPSConv(\n",
        "                hidden_dim,\n",
        "                GINEConv(local_nn, train_eps=True, edge_dim=hidden_dim),\n",
        "                heads=num_heads,\n",
        "                dropout=dropout,\n",
        "                attn_type='multihead'\n",
        "            ))\n",
        "        self.pool = global_add_pool\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        h = self.atom_encoder(batch.x)\n",
        "        edge_attr = self.bond_encoder(batch.edge_attr)\n",
        "        for conv in self.convs:\n",
        "            h = conv(h, batch.edge_index, batch.batch, edge_attr=edge_attr)\n",
        "        return self.proj(self.pool(h, batch.batch))\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, model_name, gnn_args, freeze_layers=0):\n",
        "        super().__init__()\n",
        "        self.graph_encoder = MolGNN(**gnn_args)\n",
        "        self.text_encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Freeze layers si n√©cessaire\n",
        "        if freeze_layers > 0:\n",
        "            print(f\"‚ùÑÔ∏è Gel des {freeze_layers} premi√®res couches de BERT\")\n",
        "            for param in self.text_encoder.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "            for i in range(freeze_layers):\n",
        "                if i < len(self.text_encoder.encoder.layer):\n",
        "                    for param in self.text_encoder.encoder.layer[i].parameters():\n",
        "                        param.requires_grad = False\n",
        "\n",
        "        bert_dim = self.text_encoder.config.hidden_size\n",
        "        out_dim = gnn_args['out_dim']\n",
        "        self.text_proj = nn.Linear(bert_dim, out_dim) if bert_dim != out_dim else nn.Identity()\n",
        "\n",
        "    def forward_text(self, input_ids, attention_mask):\n",
        "        t_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return F.normalize(self.text_proj(t_out.last_hidden_state[:, 0, :]), dim=-1)\n",
        "\n",
        "    def forward_graph(self, batch):\n",
        "        return F.normalize(self.graph_encoder(batch), dim=-1)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FONCTIONS DE CHARGEMENT\n",
        "# ==============================================================================\n",
        "def load_dual_encoder(checkpoint_path, device='cuda'):\n",
        "    \"\"\"Charge le DualEncoder (g√®re nouveau format).\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # D√©tection format\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        # ‚úÖ Nouveau format\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        args = checkpoint.get('args', {})\n",
        "\n",
        "        gnn_config = {\n",
        "            'hidden_dim': args.get('hidden_dim', 256),\n",
        "            'out_dim': 768,\n",
        "            'num_layers': args.get('num_layers', 4),\n",
        "            'num_heads': args.get('num_heads', 4),\n",
        "            'dropout': args.get('dropout', 0.1),\n",
        "        }\n",
        "        freeze_layers = args.get('freeze_layers', 0)\n",
        "        model_name = args.get('model_name', MODEL_NAME)\n",
        "\n",
        "        print(f\"‚úÖ Nouveau format - Config: {gnn_config}, Freeze: {freeze_layers}\")\n",
        "    else:\n",
        "        # ‚ùå Ancien format\n",
        "        state_dict = checkpoint\n",
        "        gnn_config = {\n",
        "            'hidden_dim': 256,\n",
        "            'out_dim': 768,\n",
        "            'num_layers': 4,\n",
        "            'num_heads': 4,\n",
        "            'dropout': 0.1\n",
        "        }\n",
        "        freeze_layers = 0\n",
        "        model_name = MODEL_NAME\n",
        "        print(f\"‚ö†Ô∏è Ancien format - Config par d√©faut\")\n",
        "\n",
        "    # Cr√©ation mod√®le\n",
        "    model = DualEncoder(model_name, gnn_config, freeze_layers)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, gnn_config\n",
        "\n",
        "\n",
        "def load_texts_and_graphs(pkl_path):\n",
        "    \"\"\"Charge les graphes et extrait les descriptions.\"\"\"\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    texts = [d.description for d in data]\n",
        "    return data, texts\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, graphs):\n",
        "        self.graphs = graphs\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx]\n",
        "\n",
        "\n",
        "def collate_text(batch):\n",
        "    return batch\n",
        "\n",
        "\n",
        "def collate_graph(batch):\n",
        "    return Batch.from_data_list(batch)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MOTEUR D'INFERENCE\n",
        "# ==============================================================================\n",
        "@torch.no_grad()\n",
        "def generate_reference_embeddings(model, tokenizer, texts, device, batch_size=32):\n",
        "    \"\"\"Recalcule les embeddings du TRAIN avec le BERT fine-tun√©.\"\"\"\n",
        "    print(f\"üîÑ Recalcul des embeddings de r√©f√©rence ({len(texts)} textes) avec le mod√®le fine-tun√©...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(texts, batch_size=batch_size, collate_fn=collate_text)\n",
        "\n",
        "    for batch_texts in tqdm(loader, desc=\"Encoding Train Texts\"):\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "\n",
        "        emb = model.forward_text(inputs['input_ids'], inputs['attention_mask'])\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_graphs(model, graphs, device, batch_size=32):\n",
        "    \"\"\"Encode les graphes en embeddings.\"\"\"\n",
        "    print(f\"üß™ Encodage de {len(graphs)} graphes...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(\n",
        "        GraphDataset(graphs),\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_graph\n",
        "    )\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Encoding Graphs\"):\n",
        "        batch = batch.to(device)\n",
        "        emb = model.forward_graph(batch)\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_evaluation():\n",
        "    \"\"\"√âvaluation compl√®te avec BLEU-4 et BERTScore.\"\"\"\n",
        "\n",
        "    # === 1. CHARGEMENT MOD√àLE ===\n",
        "    print(f\"üì• Chargement du Dual Encoder depuis {MODEL_PATH}\")\n",
        "    model, config = load_dual_encoder(MODEL_PATH, DEVICE)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # === 2. CHARGEMENT DONN√âES ===\n",
        "    print(\"üìÇ Chargement des datasets...\")\n",
        "    train_graphs, train_texts = load_texts_and_graphs(DATA_DIR / \"train_graphs.pkl\")\n",
        "    val_graphs, val_texts = load_texts_and_graphs(DATA_DIR / \"validation_graphs.pkl\")\n",
        "\n",
        "    print(f\"   Train: {len(train_graphs)} exemples\")\n",
        "    print(f\"   Val:   {len(val_graphs)} exemples\")\n",
        "\n",
        "    # === 3. CR√âATION BANQUE DE R√âF√âRENCE (TRAIN) ===\n",
        "    # Encode tous les textes du train avec le BERT fine-tun√©\n",
        "    train_embs = generate_reference_embeddings(\n",
        "        model, tokenizer, train_texts, DEVICE, batch_size=BATCH_SIZE\n",
        "    )\n",
        "    train_embs = train_embs.to(DEVICE)  # [N_train, 768]\n",
        "\n",
        "    print(f\"   Embeddings train: {train_embs.shape}\")\n",
        "\n",
        "    # === 4. ENCODAGE GRAPHES VALIDATION ===\n",
        "    val_mol_embs = encode_graphs(model, val_graphs, DEVICE, batch_size=BATCH_SIZE)\n",
        "    val_mol_embs = val_mol_embs.to(DEVICE)  # [N_val, 768]\n",
        "\n",
        "    print(f\"   Embeddings val:   {val_mol_embs.shape}\")\n",
        "\n",
        "    # === 5. RETRIEVAL (Recherche du plus proche voisin) ===\n",
        "    print(\"üîç Recherche des descriptions les plus proches dans le TRAIN...\")\n",
        "\n",
        "    # Similarit√© cosine : [N_val, N_train]\n",
        "    sims = val_mol_embs @ train_embs.t()\n",
        "\n",
        "    # Meilleur match pour chaque graphe de validation\n",
        "    best_indices = sims.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    # R√©cup√©ration des textes pr√©dits\n",
        "    preds = [train_texts[idx] for idx in best_indices]\n",
        "    refs = val_texts\n",
        "\n",
        "    # === 6. CALCUL DES M√âTRIQUES NLP ===\n",
        "    print(\"üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\")\n",
        "\n",
        "    # BLEU-4\n",
        "    bleu_metric = evaluate.load(\"bleu\")\n",
        "    bleu_res = bleu_metric.compute(\n",
        "        predictions=preds,\n",
        "        references=[[r] for r in refs],  # Format attendu : liste de listes\n",
        "        max_order=4\n",
        "    )\n",
        "    bleu4 = bleu_res[\"bleu\"]\n",
        "\n",
        "    # BERTScore\n",
        "    bert_metric = evaluate.load(\"bertscore\")\n",
        "    bert_res = bert_metric.compute(\n",
        "        predictions=preds,\n",
        "        references=refs,\n",
        "        model_type=\"roberta-base\",\n",
        "        lang=\"en\"\n",
        "    )\n",
        "    bert_f1 = float(np.mean(bert_res[\"f1\"]))\n",
        "\n",
        "    # Score final (comme dans ta formule)\n",
        "    final_proxy = 0.5 * (bleu4 if bleu4 <= 1.0 else bleu4/100) + 0.5 * bert_f1\n",
        "\n",
        "    # === 7. AFFICHAGE R√âSULTATS ===\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üèÜ R√âSULTATS DUAL ENCODER (NLP METRICS)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"BLEU-4        : {bleu4:.5f}\")\n",
        "    print(f\"BERTScore F1  : {bert_f1:.5f}\")\n",
        "    print(f\"Final Score   : {final_proxy:.5f}\")\n",
        "    print(f\"Kaggle Score  : {0.925 * final_proxy:.5f}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Exemples de pr√©dictions\n",
        "    print(\"\\nüìù EXEMPLES DE PR√âDICTIONS :\")\n",
        "    print(\"-\" * 70)\n",
        "    for i in range(min(3, len(preds))):\n",
        "        print(f\"\\nExemple {i+1}:\")\n",
        "        print(f\"  Pr√©dit  : {preds[i][:100]}...\")\n",
        "        print(f\"  R√©f√©rence: {refs[i][:100]}...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    return {\n",
        "        'bleu4': bleu4,\n",
        "        'bertscore_f1': bert_f1,\n",
        "        'final_score': final_proxy,\n",
        "        'kaggle_score': 0.925 * final_proxy\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "22f14b651d0c483197d985a0ed743975",
            "ec5d9472afbf462f94e677a7d8658163",
            "612a660de5d74c449f7db0e7077688bc",
            "a360ef17f6ab406caabe9bf1012b165f",
            "2c289592c58541dd8b7dfe6ec6a12b83",
            "6e6ee5a715244b8ebd5d3911368ee9d1",
            "f1c1255ec1934dbea5feda16f9e33f3c",
            "576a3f265609420a88d9392a293a5085",
            "df5ca6276bc34bc59e7cd0955010af6a",
            "33b5a05311f24855986cb0221ac3a851",
            "b071554e9bb04b03bff4bfde6f971562",
            "d3188a4f8ece433e92e4d11e640eeae5",
            "4293c7d0a789455392410d6cd68d3165",
            "66da2f7f15de4586ab6a1681cf6d2c39",
            "bf61011980174b7e8a687e85c0fb96ff",
            "018e3a5eca4848a8b17563ee7853c01c",
            "d43a2c3c92614df09d1e79ae2d1e594c",
            "1c1f42c07936420c92b7873a692c2445",
            "ae08f58d6c51412c868d47db2ad039d7",
            "fc67545634704040be48934527550299",
            "b01a21b2fa4d43a38857ca71fdba9f1a",
            "83c2ce459f0047d0b28e0a3daa88936f",
            "bd871904ed8248b5a058ea4749ec0da6",
            "a103979c82b74ec5af1c44b9db93c1af",
            "e93414daeb174cb492ef92bf378b94d8",
            "83cf769bb77c456d9e2170157d73dba0",
            "ed9285948a6246978b3a9771c212d855",
            "fcaaafb68a234b3e9dd20c6c578e634a",
            "70aacfc8c195457881546bd0862a8474",
            "46a534e2427f496c9b11a7a4b31ec884",
            "30f1b9d817e44dff946385c6a53bf557",
            "cc4c53ee9703451d8fa2fd897c38abc8",
            "fa45ea8b3c72434ab0d7f76e21e384c6",
            "5bd7e8c4c95946f9ba0b594c4ec2ec85",
            "23ad470308384e9f8736ecfeb85972d7",
            "b8f1c45456694cb894305e4317d55551",
            "8f687189aadf4cd1af18c5a64b1ab3f7",
            "65bf5346c1ac43068c748e4e6e5edfc5",
            "e25bc195432a4fe18b071e68d596c122",
            "ed076412275f487c8249a13387dec8fb",
            "56aab96d91104e6faae979a53587fbd8",
            "b8da92899ba54222994de380ed2219e9",
            "bf626f40a51f4c63ba899868bd0b0506",
            "4df00895eb224f06bf9ee2fc6df75feb",
            "073b847f3f5c4c98ab5114b995409e55",
            "80f45627bbf24890a75af8e1dfe0df78",
            "898c04be9c8741d9818657abc5d9d47f",
            "27d3d20fcc8a4497bac8fac93a6e6e96",
            "b19818c53bbc40a98171da0a99deb159",
            "0c454a95c9e84a9183f9046d1e4a692f",
            "69493bbfad4e46d6b5e970739c59b58f",
            "82e2c2e1790544d2924495b809b7dd9f",
            "9c9c280fbc224fdf83b27c1409762d24",
            "a384ce655cc54d8c8cc9f023bc86dcde",
            "3804a1ce7fba44679d42544c58d32b2c",
            "a1db6a8a2c714a94ae0b41061b9966c7",
            "5a4393d52fca481181125bfe9e936471",
            "e59274c01402411ab51b5ebb8ef08526",
            "6a019d294c4a45ac880e9f0eaebb52f4",
            "f98a8c4b4e8040468878f23669f7ace7",
            "ca8d35302e7d4059bb9fcee66c89a41c",
            "c6a314957b2e4a94b4b3ade7ea1c4df0",
            "c9a7411fc6d24ae3bc0d555f6b039032",
            "04a537cd120347ab94e4b1cf1084808b",
            "5b89ea37e43d45f0b9ca627617f1561e",
            "2ab3035240314713a46a0e1a8119a9a5",
            "83e455196777495e94d8a71d3b17b289",
            "0e30ed62f1a3417b9c1496563b27c94a",
            "0f7c04799e5d4fe2a79e4a8b640ad00b",
            "9c37884b4dd64859a5aa1b17e7df38a7",
            "da89e03a97214702aac671003082f8af",
            "66981c20b0594db7ad7e0f8ac3775615",
            "b63557b0715a4b5dbf9cfe81f05c765f",
            "79192f8d9cb14e369af8bf9d2a360226",
            "e8e57ae5f4594a5c856bcbca9b8d2f35",
            "67ef02b04c5f4d8e95b383b125312f6a",
            "bc95f65a420f48e494b521d972420d89",
            "5ff935535f4b4374a7dea56153578456",
            "a8456c7baac0466d8a76f62626a9a0df",
            "8561ac92e5c2469c8100565615fc23ec",
            "fd2edee379214cfea6847365882a7219",
            "9c174621c4e54a09b21bc11dfcaa2bff",
            "c91ea2211d564994981d1b99888b9bb5",
            "387e4c8b9f5f499fb4cc2639ac96d987",
            "7455d76129ac458f9a6ae5fc6538e835",
            "cf579325c6dd4aaba6a451bfadbf72de",
            "6c14a2f729bc44809ff030810b4cec29",
            "5c7ac2a64dd14131955a0a1fc4c17f3a",
            "acc9f739e94a4aa08b1d933dbe38647c",
            "e187c853604648158b4c75074515e554",
            "377147c20e2b4fe3b493076c0c8fb71b",
            "38c309f4630c4691a0f7be256002d410",
            "ead6799706144dacba0b74911364370c",
            "0ae2eb3bd42a453298c6d67b4f7a9226",
            "db4337f7f86944e0a8e45e726172dbca",
            "8492511e4c7d4a889f4f58297cfb0129",
            "22d55a453aa24caba94c7872e247052b",
            "aa8261c575fa46608c4e5de02ed1bcec",
            "062870db74ba4ed98c56d3f41f15db44",
            "52d7f90ca0d34f21b948c1ea9e7da1ce",
            "37933e5bb78c4ce18a9680f090c12a6f",
            "51ba12e6f23943579b4807e7b3cdd425",
            "01c0a46db1404356994736edcc5418ff",
            "900dfda4a2c74e92ae8e21f853b19909",
            "bbdc72c230e440b6a1bd9798a6371e7a",
            "60a7139386054932869775e6b022bec6",
            "38b0e76e2f454f4cb5f73b9534920a06",
            "505d8e147e4b4e2b952e4033f3c3150c",
            "c6411eb66dd747cb94a4f53fe1a3622a",
            "03a5bae804674bbfa02ce56afdb341ea"
          ]
        },
        "id": "08JQ5w32OmP1",
        "outputId": "00f0ebd7-efa9-4ecc-ec5c-07a992809b99"
      },
      "id": "08JQ5w32OmP1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Configuration : cuda\n",
            "üì• Chargement du Dual Encoder depuis data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "‚úÖ Nouveau format - Config: {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}, Freeze: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Chargement des datasets...\n",
            "   Train: 31008 exemples\n",
            "   Val:   1000 exemples\n",
            "üîÑ Recalcul des embeddings de r√©f√©rence (31008 textes) avec le mod√®le fine-tun√©...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Train Texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 969/969 [01:40<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings train: torch.Size([31008, 768])\n",
            "üß™ Encodage de 1000 graphes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Graphs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 66.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings val:   torch.Size([1000, 768])\n",
            "üîç Recherche des descriptions les plus proches dans le TRAIN...\n",
            "üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22f14b651d0c483197d985a0ed743975"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3188a4f8ece433e92e4d11e640eeae5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd871904ed8248b5a058ea4749ec0da6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bd7e8c4c95946f9ba0b594c4ec2ec85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "073b847f3f5c4c98ab5114b995409e55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1db6a8a2c714a94ae0b41061b9966c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e455196777495e94d8a71d3b17b289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ff935535f4b4374a7dea56153578456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acc9f739e94a4aa08b1d933dbe38647c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52d7f90ca0d34f21b948c1ea9e7da1ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üèÜ R√âSULTATS DUAL ENCODER (NLP METRICS)\n",
            "======================================================================\n",
            "BLEU-4        : 0.43530\n",
            "BERTScore F1  : 0.92371\n",
            "Final Score   : 0.67950\n",
            "Kaggle Score  : 0.62854\n",
            "======================================================================\n",
            "\n",
            "üìù EXEMPLES DE PR√âDICTIONS :\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Exemple 1:\n",
            "  Pr√©dit  : The molecule is an aminotetrasaccharide consisting of two units of 2-acetamido-2-deoxy-4-O-sulfo-bet...\n",
            "  R√©f√©rence: The molecule is an amino tetrasaccharide comprised of an L-iduronic acid residue, sulfated on O-2, a...\n",
            "\n",
            "Exemple 2:\n",
            "  Pr√©dit  : The molecule is the D-enantiomer of the alpha-amino acid lysine. It has a role as a bacterial metabo...\n",
            "  R√©f√©rence: The molecule is the non-proteinogenic L-alpha-amino acid that is norspermidine (1,5,9-triazanonane) ...\n",
            "\n",
            "Exemple 3:\n",
            "  Pr√©dit  : The molecule is an (omega-1)-hydroxy fatty acid ascaroside obtained by formal condensation of the al...\n",
            "  R√©f√©rence: The molecule is an (omega-1)-hydroxy fatty acid ascaroside obtained by formal condensation of the al...\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.nn import GPSConv, GINEConv, global_add_pool\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import evaluate\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================================================================\n",
        "# 0. CONFIGURATION\n",
        "# ==============================================================================\n",
        "MODEL_PATH = \"data_baseline/data/dual_lrGNN0.0008_lrBERT1e-05_wd0.0001_frz0_margin0.2_bs128.pt\"\n",
        "DATA_DIR = Path(\"data_baseline/data\")\n",
        "MODEL_NAME = \"recobo/chemical-bert-uncased\"\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"‚öôÔ∏è Configuration : {DEVICE}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. D√âFINITION DE L'ARCHITECTURE\n",
        "# ==============================================================================\n",
        "ATOM_DIMS = [119, 4, 11, 12, 9, 5, 8, 2, 2]\n",
        "BOND_DIMS = [22, 6, 2]\n",
        "\n",
        "class AtomEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in ATOM_DIMS])\n",
        "    def forward(self, x):\n",
        "        return sum(emb(x[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class BondEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in BOND_DIMS])\n",
        "    def forward(self, edge_attr):\n",
        "        return sum(emb(edge_attr[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class MolGNN(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, out_dim=768, num_layers=4, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.atom_encoder = AtomEncoder(hidden_dim)\n",
        "        self.bond_encoder = BondEncoder(hidden_dim)\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            local_nn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, 2 * hidden_dim),\n",
        "                nn.BatchNorm1d(2 * hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GPSConv(\n",
        "                hidden_dim,\n",
        "                GINEConv(local_nn, train_eps=True, edge_dim=hidden_dim),\n",
        "                heads=num_heads,\n",
        "                dropout=dropout,\n",
        "                attn_type='multihead'\n",
        "            ))\n",
        "        self.pool = global_add_pool\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        h = self.atom_encoder(batch.x)\n",
        "        edge_attr = self.bond_encoder(batch.edge_attr)\n",
        "        for conv in self.convs:\n",
        "            h = conv(h, batch.edge_index, batch.batch, edge_attr=edge_attr)\n",
        "        return self.proj(self.pool(h, batch.batch))\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, model_name, gnn_args, freeze_layers=0):\n",
        "        super().__init__()\n",
        "        self.graph_encoder = MolGNN(**gnn_args)\n",
        "        self.text_encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Freeze layers si n√©cessaire\n",
        "        if freeze_layers > 0:\n",
        "            print(f\"‚ùÑÔ∏è Gel des {freeze_layers} premi√®res couches de BERT\")\n",
        "            for param in self.text_encoder.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "            for i in range(freeze_layers):\n",
        "                if i < len(self.text_encoder.encoder.layer):\n",
        "                    for param in self.text_encoder.encoder.layer[i].parameters():\n",
        "                        param.requires_grad = False\n",
        "\n",
        "        bert_dim = self.text_encoder.config.hidden_size\n",
        "        out_dim = gnn_args['out_dim']\n",
        "        self.text_proj = nn.Linear(bert_dim, out_dim) if bert_dim != out_dim else nn.Identity()\n",
        "\n",
        "    def forward_text(self, input_ids, attention_mask):\n",
        "        t_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return F.normalize(self.text_proj(t_out.last_hidden_state[:, 0, :]), dim=-1)\n",
        "\n",
        "    def forward_graph(self, batch):\n",
        "        return F.normalize(self.graph_encoder(batch), dim=-1)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FONCTIONS DE CHARGEMENT\n",
        "# ==============================================================================\n",
        "def load_dual_encoder(checkpoint_path, device='cuda'):\n",
        "    \"\"\"Charge le DualEncoder (g√®re nouveau format).\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # D√©tection format\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        # ‚úÖ Nouveau format\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        args = checkpoint.get('args', {})\n",
        "\n",
        "        gnn_config = {\n",
        "            'hidden_dim': args.get('hidden_dim', 256),\n",
        "            'out_dim': 768,\n",
        "            'num_layers': args.get('num_layers', 4),\n",
        "            'num_heads': args.get('num_heads', 4),\n",
        "            'dropout': args.get('dropout', 0.1),\n",
        "        }\n",
        "        freeze_layers = args.get('freeze_layers', 0)\n",
        "        model_name = args.get('model_name', MODEL_NAME)\n",
        "\n",
        "        print(f\"‚úÖ Nouveau format - Config: {gnn_config}, Freeze: {freeze_layers}\")\n",
        "    else:\n",
        "        # ‚ùå Ancien format\n",
        "        state_dict = checkpoint\n",
        "        gnn_config = {\n",
        "            'hidden_dim': 256,\n",
        "            'out_dim': 768,\n",
        "            'num_layers': 4,\n",
        "            'num_heads': 4,\n",
        "            'dropout': 0.1\n",
        "        }\n",
        "        freeze_layers = 0\n",
        "        model_name = MODEL_NAME\n",
        "        print(f\"‚ö†Ô∏è Ancien format - Config par d√©faut\")\n",
        "\n",
        "    # Cr√©ation mod√®le\n",
        "    model = DualEncoder(model_name, gnn_config, freeze_layers)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, gnn_config\n",
        "\n",
        "\n",
        "def load_texts_and_graphs(pkl_path):\n",
        "    \"\"\"Charge les graphes et extrait les descriptions.\"\"\"\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    texts = [d.description for d in data]\n",
        "    return data, texts\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, graphs):\n",
        "        self.graphs = graphs\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx]\n",
        "\n",
        "\n",
        "def collate_text(batch):\n",
        "    return batch\n",
        "\n",
        "\n",
        "def collate_graph(batch):\n",
        "    return Batch.from_data_list(batch)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MOTEUR D'INFERENCE\n",
        "# ==============================================================================\n",
        "@torch.no_grad()\n",
        "def generate_reference_embeddings(model, tokenizer, texts, device, batch_size=32):\n",
        "    \"\"\"Recalcule les embeddings du TRAIN avec le BERT fine-tun√©.\"\"\"\n",
        "    print(f\"üîÑ Recalcul des embeddings de r√©f√©rence ({len(texts)} textes) avec le mod√®le fine-tun√©...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(texts, batch_size=batch_size, collate_fn=collate_text)\n",
        "\n",
        "    for batch_texts in tqdm(loader, desc=\"Encoding Train Texts\"):\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "\n",
        "        emb = model.forward_text(inputs['input_ids'], inputs['attention_mask'])\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_graphs(model, graphs, device, batch_size=32):\n",
        "    \"\"\"Encode les graphes en embeddings.\"\"\"\n",
        "    print(f\"üß™ Encodage de {len(graphs)} graphes...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(\n",
        "        GraphDataset(graphs),\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_graph\n",
        "    )\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Encoding Graphs\"):\n",
        "        batch = batch.to(device)\n",
        "        emb = model.forward_graph(batch)\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_evaluation():\n",
        "    \"\"\"√âvaluation compl√®te avec BLEU-4 et BERTScore.\"\"\"\n",
        "\n",
        "    # === 1. CHARGEMENT MOD√àLE ===\n",
        "    print(f\"üì• Chargement du Dual Encoder depuis {MODEL_PATH}\")\n",
        "    model, config = load_dual_encoder(MODEL_PATH, DEVICE)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # === 2. CHARGEMENT DONN√âES ===\n",
        "    print(\"üìÇ Chargement des datasets...\")\n",
        "    train_graphs, train_texts = load_texts_and_graphs(DATA_DIR / \"train_graphs.pkl\")\n",
        "    val_graphs, val_texts = load_texts_and_graphs(DATA_DIR / \"validation_graphs.pkl\")\n",
        "\n",
        "    print(f\"   Train: {len(train_graphs)} exemples\")\n",
        "    print(f\"   Val:   {len(val_graphs)} exemples\")\n",
        "\n",
        "    # === 3. CR√âATION BANQUE DE R√âF√âRENCE (TRAIN) ===\n",
        "    # Encode tous les textes du train avec le BERT fine-tun√©\n",
        "    train_embs = generate_reference_embeddings(\n",
        "        model, tokenizer, train_texts, DEVICE, batch_size=BATCH_SIZE\n",
        "    )\n",
        "    train_embs = train_embs.to(DEVICE)  # [N_train, 768]\n",
        "\n",
        "    print(f\"   Embeddings train: {train_embs.shape}\")\n",
        "\n",
        "    # === 4. ENCODAGE GRAPHES VALIDATION ===\n",
        "    val_mol_embs = encode_graphs(model, val_graphs, DEVICE, batch_size=BATCH_SIZE)\n",
        "    val_mol_embs = val_mol_embs.to(DEVICE)  # [N_val, 768]\n",
        "\n",
        "    print(f\"   Embeddings val:   {val_mol_embs.shape}\")\n",
        "\n",
        "    # === 5. RETRIEVAL (Recherche du plus proche voisin) ===\n",
        "    print(\"üîç Recherche des descriptions les plus proches dans le TRAIN...\")\n",
        "\n",
        "    # Similarit√© cosine : [N_val, N_train]\n",
        "    sims = val_mol_embs @ train_embs.t()\n",
        "\n",
        "    # Meilleur match pour chaque graphe de validation\n",
        "    best_indices = sims.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    # R√©cup√©ration des textes pr√©dits\n",
        "    preds = [train_texts[idx] for idx in best_indices]\n",
        "    refs = val_texts\n",
        "\n",
        "    # === 6. CALCUL DES M√âTRIQUES NLP ===\n",
        "    print(\"üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\")\n",
        "\n",
        "    # BLEU-4\n",
        "    bleu_metric = evaluate.load(\"bleu\")\n",
        "    bleu_res = bleu_metric.compute(\n",
        "        predictions=preds,\n",
        "        references=[[r] for r in refs],  # Format attendu : liste de listes\n",
        "        max_order=4\n",
        "    )\n",
        "    bleu4 = bleu_res[\"bleu\"]\n",
        "\n",
        "    # BERTScore\n",
        "    bert_metric = evaluate.load(\"bertscore\")\n",
        "    bert_res = bert_metric.compute(\n",
        "        predictions=preds,\n",
        "        references=refs,\n",
        "        model_type=\"roberta-base\",\n",
        "        lang=\"en\"\n",
        "    )\n",
        "    bert_f1 = float(np.mean(bert_res[\"f1\"]))\n",
        "\n",
        "    # Score final (comme dans ta formule)\n",
        "    final_proxy = 0.5 * (bleu4 if bleu4 <= 1.0 else bleu4/100) + 0.5 * bert_f1\n",
        "\n",
        "    # === 7. AFFICHAGE R√âSULTATS ===\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üèÜ R√âSULTATS DUAL ENCODER (NLP METRICS)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"BLEU-4        : {bleu4:.5f}\")\n",
        "    print(f\"BERTScore F1  : {bert_f1:.5f}\")\n",
        "    print(f\"Final Score   : {final_proxy:.5f}\")\n",
        "    print(f\"Kaggle Score  : {0.925 * final_proxy:.5f}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Exemples de pr√©dictions\n",
        "    print(\"\\nüìù EXEMPLES DE PR√âDICTIONS :\")\n",
        "    print(\"-\" * 70)\n",
        "    for i in range(min(3, len(preds))):\n",
        "        print(f\"\\nExemple {i+1}:\")\n",
        "        print(f\"  Pr√©dit  : {preds[i][:100]}...\")\n",
        "        print(f\"  R√©f√©rence: {refs[i][:100]}...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    return {\n",
        "        'bleu4': bleu4,\n",
        "        'bertscore_f1': bert_f1,\n",
        "        'final_score': final_proxy,\n",
        "        'kaggle_score': 0.925 * final_proxy\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODhxRan6Qywr",
        "outputId": "9915181b-4222-4679-acb2-18e1c31e091f"
      },
      "id": "ODhxRan6Qywr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Configuration : cuda\n",
            "üì• Chargement du Dual Encoder depuis data_baseline/data/dual_lrGNN0.0008_lrBERT1e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "‚úÖ Nouveau format - Config: {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}, Freeze: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Chargement des datasets...\n",
            "   Train: 31008 exemples\n",
            "   Val:   1000 exemples\n",
            "üîÑ Recalcul des embeddings de r√©f√©rence (31008 textes) avec le mod√®le fine-tun√©...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Train Texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 969/969 [01:40<00:00,  9.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings train: torch.Size([31008, 768])\n",
            "üß™ Encodage de 1000 graphes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Graphs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 74.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings val:   torch.Size([1000, 768])\n",
            "üîç Recherche des descriptions les plus proches dans le TRAIN...\n",
            "üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üèÜ R√âSULTATS DUAL ENCODER (NLP METRICS)\n",
            "======================================================================\n",
            "BLEU-4        : 0.42114\n",
            "BERTScore F1  : 0.92167\n",
            "Final Score   : 0.67141\n",
            "Kaggle Score  : 0.62105\n",
            "======================================================================\n",
            "\n",
            "üìù EXEMPLES DE PR√âDICTIONS :\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Exemple 1:\n",
            "  Pr√©dit  : The molecule is an aminotetrasaccharide consisting of two units of 2-acetamido-2-deoxy-4-O-sulfo-bet...\n",
            "  R√©f√©rence: The molecule is an amino tetrasaccharide comprised of an L-iduronic acid residue, sulfated on O-2, a...\n",
            "\n",
            "Exemple 2:\n",
            "  Pr√©dit  : The molecule is the D-enantiomer of the alpha-amino acid lysine. It has a role as a bacterial metabo...\n",
            "  R√©f√©rence: The molecule is the non-proteinogenic L-alpha-amino acid that is norspermidine (1,5,9-triazanonane) ...\n",
            "\n",
            "Exemple 3:\n",
            "  Pr√©dit  : The molecule is an (omega-1)-hydroxy fatty acid ascaroside obtained by formal condensation of the al...\n",
            "  R√©f√©rence: The molecule is an (omega-1)-hydroxy fatty acid ascaroside obtained by formal condensation of the al...\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code pour avoir les r√©sultats et convertir au format csv pour kaggle"
      ],
      "metadata": {
        "id": "xcXIGfyPXStJ"
      },
      "id": "xcXIGfyPXStJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.nn import GPSConv, GINEConv, global_add_pool\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import evaluate\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================================================================\n",
        "# 0. CONFIGURATION\n",
        "# ==============================================================================\n",
        "MODEL_PATH = \"data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\"\n",
        "DATA_DIR = Path(\"data_baseline/data\")\n",
        "MODEL_NAME = \"recobo/chemical-bert-uncased\"\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Output\n",
        "SUBMISSION_PATH = \"submission_dual_encoder.csv\"\n",
        "\n",
        "print(f\"‚öôÔ∏è Configuration : {DEVICE}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. D√âFINITION DE L'ARCHITECTURE\n",
        "# ==============================================================================\n",
        "ATOM_DIMS = [119, 4, 11, 12, 9, 5, 8, 2, 2]\n",
        "BOND_DIMS = [22, 6, 2]\n",
        "\n",
        "class AtomEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in ATOM_DIMS])\n",
        "    def forward(self, x):\n",
        "        return sum(emb(x[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class BondEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in BOND_DIMS])\n",
        "    def forward(self, edge_attr):\n",
        "        return sum(emb(edge_attr[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class MolGNN(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, out_dim=768, num_layers=4, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.atom_encoder = AtomEncoder(hidden_dim)\n",
        "        self.bond_encoder = BondEncoder(hidden_dim)\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            local_nn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, 2 * hidden_dim),\n",
        "                nn.BatchNorm1d(2 * hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GPSConv(\n",
        "                hidden_dim,\n",
        "                GINEConv(local_nn, train_eps=True, edge_dim=hidden_dim),\n",
        "                heads=num_heads,\n",
        "                dropout=dropout,\n",
        "                attn_type='multihead'\n",
        "            ))\n",
        "        self.pool = global_add_pool\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        h = self.atom_encoder(batch.x)\n",
        "        edge_attr = self.bond_encoder(batch.edge_attr)\n",
        "        for conv in self.convs:\n",
        "            h = conv(h, batch.edge_index, batch.batch, edge_attr=edge_attr)\n",
        "        return self.proj(self.pool(h, batch.batch))\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, model_name, gnn_args, freeze_layers=0):\n",
        "        super().__init__()\n",
        "        self.graph_encoder = MolGNN(**gnn_args)\n",
        "        self.text_encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        if freeze_layers > 0:\n",
        "            print(f\"‚ùÑÔ∏è Gel des {freeze_layers} premi√®res couches de BERT\")\n",
        "            for param in self.text_encoder.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "            for i in range(freeze_layers):\n",
        "                if i < len(self.text_encoder.encoder.layer):\n",
        "                    for param in self.text_encoder.encoder.layer[i].parameters():\n",
        "                        param.requires_grad = False\n",
        "\n",
        "        bert_dim = self.text_encoder.config.hidden_size\n",
        "        out_dim = gnn_args['out_dim']\n",
        "        self.text_proj = nn.Linear(bert_dim, out_dim) if bert_dim != out_dim else nn.Identity()\n",
        "\n",
        "    def forward_text(self, input_ids, attention_mask):\n",
        "        t_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return F.normalize(self.text_proj(t_out.last_hidden_state[:, 0, :]), dim=-1)\n",
        "\n",
        "    def forward_graph(self, batch):\n",
        "        return F.normalize(self.graph_encoder(batch), dim=-1)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FONCTIONS DE CHARGEMENT\n",
        "# ==============================================================================\n",
        "def load_dual_encoder(checkpoint_path, device='cuda'):\n",
        "    \"\"\"Charge le DualEncoder (g√®re nouveau format).\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        args = checkpoint.get('args', {})\n",
        "\n",
        "        gnn_config = {\n",
        "            'hidden_dim': args.get('hidden_dim', 256),\n",
        "            'out_dim': 768,\n",
        "            'num_layers': args.get('num_layers', 4),\n",
        "            'num_heads': args.get('num_heads', 4),\n",
        "            'dropout': args.get('dropout', 0.1),\n",
        "        }\n",
        "        freeze_layers = args.get('freeze_layers', 0)\n",
        "        model_name = args.get('model_name', MODEL_NAME)\n",
        "\n",
        "        print(f\"‚úÖ Nouveau format - Config: {gnn_config}, Freeze: {freeze_layers}\")\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "        gnn_config = {\n",
        "            'hidden_dim': 256,\n",
        "            'out_dim': 768,\n",
        "            'num_layers': 4,\n",
        "            'num_heads': 4,\n",
        "            'dropout': 0.1\n",
        "        }\n",
        "        freeze_layers = 0\n",
        "        model_name = MODEL_NAME\n",
        "        print(f\"‚ö†Ô∏è Ancien format - Config par d√©faut\")\n",
        "\n",
        "    model = DualEncoder(model_name, gnn_config, freeze_layers)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, gnn_config\n",
        "\n",
        "\n",
        "def load_texts_and_graphs(pkl_path, has_description=True):\n",
        "    \"\"\"\n",
        "    Charge les graphes et extrait les descriptions (si disponibles).\n",
        "\n",
        "    Args:\n",
        "        pkl_path: Chemin vers le fichier pickle\n",
        "        has_description: Si False, retourne None pour les textes\n",
        "    \"\"\"\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    if has_description:\n",
        "        texts = [d.description for d in data]\n",
        "    else:\n",
        "        texts = None  # Pas de description dans le test set\n",
        "\n",
        "    return data, texts\n",
        "\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, graphs):\n",
        "        self.graphs = graphs\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx]\n",
        "\n",
        "\n",
        "def collate_text(batch):\n",
        "    return batch\n",
        "\n",
        "\n",
        "def collate_graph(batch):\n",
        "    return Batch.from_data_list(batch)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MOTEUR D'INFERENCE\n",
        "# ==============================================================================\n",
        "@torch.no_grad()\n",
        "def generate_reference_embeddings(model, tokenizer, texts, device, batch_size=32):\n",
        "    \"\"\"Recalcule les embeddings du TRAIN avec le BERT fine-tun√©.\"\"\"\n",
        "    print(f\"üîÑ Recalcul des embeddings de r√©f√©rence ({len(texts)} textes)...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(texts, batch_size=batch_size, collate_fn=collate_text)\n",
        "\n",
        "    for batch_texts in tqdm(loader, desc=\"Encoding Train Texts\"):\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "\n",
        "        emb = model.forward_text(inputs['input_ids'], inputs['attention_mask'])\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_graphs(model, graphs, device, batch_size=32):\n",
        "    \"\"\"Encode les graphes en embeddings.\"\"\"\n",
        "    print(f\"üß™ Encodage de {len(graphs)} graphes...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(\n",
        "        GraphDataset(graphs),\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_graph\n",
        "    )\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Encoding Graphs\"):\n",
        "        batch = batch.to(device)\n",
        "        emb = model.forward_graph(batch)\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "def generate_submission(predictions, output_path):\n",
        "    \"\"\"\n",
        "    G√©n√®re le fichier de submission Kaggle.\n",
        "\n",
        "    Args:\n",
        "        predictions: Liste de textes pr√©dits (dans l'ordre du test set)\n",
        "        output_path: Chemin du fichier CSV √† cr√©er\n",
        "    \"\"\"\n",
        "    submission_df = pd.DataFrame({\n",
        "        'ID': range(len(predictions)),\n",
        "        'description': predictions\n",
        "    })\n",
        "\n",
        "    submission_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\nüíæ Submission sauvegard√©e : {output_path}\")\n",
        "    print(f\"   Nombre de pr√©dictions : {len(predictions)}\")\n",
        "    print(f\"   Preview :\")\n",
        "    print(submission_df.head(10).to_string(index=False))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_evaluation_and_submission():\n",
        "    \"\"\"√âvaluation + G√©n√©ration de submission Kaggle.\"\"\"\n",
        "\n",
        "    # === 1. CHARGEMENT MOD√àLE ===\n",
        "    print(f\"üì• Chargement du Dual Encoder depuis {MODEL_PATH}\")\n",
        "    model, config = load_dual_encoder(MODEL_PATH, DEVICE)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # === 2. CHARGEMENT DONN√âES ===\n",
        "    print(\"üìÇ Chargement des datasets...\")\n",
        "    train_graphs, train_texts = load_texts_and_graphs(DATA_DIR / \"train_graphs.pkl\")\n",
        "\n",
        "    # Test set pour Kaggle\n",
        "    # APR√àS\n",
        "    test_graphs, _ = load_texts_and_graphs(DATA_DIR / \"test_graphs.pkl\", has_description=False)\n",
        "\n",
        "\n",
        "    # Validation set (pour m√©triques locales)\n",
        "    val_graphs, val_texts = load_texts_and_graphs(DATA_DIR / \"validation_graphs.pkl\")\n",
        "\n",
        "    print(f\"   Train: {len(train_graphs)} exemples\")\n",
        "    print(f\"   Val:   {len(val_graphs)} exemples\")\n",
        "    print(f\"   Test:  {len(test_graphs)} exemples (pour Kaggle)\")\n",
        "\n",
        "    # === 3. CR√âATION BANQUE DE R√âF√âRENCE (TRAIN) ===\n",
        "    train_embs = generate_reference_embeddings(\n",
        "        model, tokenizer, train_texts, DEVICE, batch_size=BATCH_SIZE\n",
        "    )\n",
        "    train_embs = train_embs.to(DEVICE)\n",
        "\n",
        "    print(f\"   Embeddings train: {train_embs.shape}\")\n",
        "\n",
        "    # === 4A. ENCODAGE GRAPHES VALIDATION (pour m√©triques) ===\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üìä √âVALUATION SUR VALIDATION SET\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    val_mol_embs = encode_graphs(model, val_graphs, DEVICE, batch_size=BATCH_SIZE)\n",
        "    val_mol_embs = val_mol_embs.to(DEVICE)\n",
        "\n",
        "    # Retrieval validation\n",
        "    print(\"üîç Recherche des descriptions les plus proches (Validation)...\")\n",
        "    sims_val = val_mol_embs @ train_embs.t()\n",
        "    best_indices_val = sims_val.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    preds_val = [train_texts[idx] for idx in best_indices_val]\n",
        "    refs_val = val_texts\n",
        "\n",
        "    # Calcul m√©triques\n",
        "    print(\"üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\")\n",
        "\n",
        "    bleu_metric = evaluate.load(\"bleu\")\n",
        "    bleu_res = bleu_metric.compute(\n",
        "        predictions=preds_val,\n",
        "        references=[[r] for r in refs_val],\n",
        "        max_order=4\n",
        "    )\n",
        "    bleu4 = bleu_res[\"bleu\"]\n",
        "\n",
        "    bert_metric = evaluate.load(\"bertscore\")\n",
        "    bert_res = bert_metric.compute(\n",
        "        predictions=preds_val,\n",
        "        references=refs_val,\n",
        "        model_type=\"roberta-base\",\n",
        "        lang=\"en\"\n",
        "    )\n",
        "    bert_f1 = float(np.mean(bert_res[\"f1\"]))\n",
        "\n",
        "    final_proxy = 0.5 * (bleu4 if bleu4 <= 1.0 else bleu4/100) + 0.5 * bert_f1\n",
        "\n",
        "    # Affichage r√©sultats validation\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üèÜ R√âSULTATS VALIDATION (NLP METRICS)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"BLEU-4        : {bleu4:.5f}\")\n",
        "    print(f\"BERTScore F1  : {bert_f1:.5f}\")\n",
        "    print(f\"Final Score   : {final_proxy:.5f}\")\n",
        "    print(f\"Kaggle Score  : {0.925 * final_proxy:.5f}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # === 4B. G√âN√âRATION PR√âDICTIONS TEST (pour Kaggle) ===\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéØ G√âN√âRATION SUBMISSION KAGGLE (TEST SET)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    test_mol_embs = encode_graphs(model, test_graphs, DEVICE, batch_size=BATCH_SIZE)\n",
        "    test_mol_embs = test_mol_embs.to(DEVICE)\n",
        "\n",
        "    print(\"üîç Recherche des descriptions les plus proches (Test)...\")\n",
        "    sims_test = test_mol_embs @ train_embs.t()\n",
        "    best_indices_test = sims_test.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    preds_test = [train_texts[idx] for idx in best_indices_test]\n",
        "\n",
        "    # G√©n√©ration du fichier submission\n",
        "    generate_submission(preds_test, SUBMISSION_PATH)\n",
        "\n",
        "    # Exemples de pr√©dictions\n",
        "    print(\"\\nüìù EXEMPLES DE PR√âDICTIONS (TEST SET) :\")\n",
        "    print(\"-\" * 70)\n",
        "    for i in range(min(5, len(preds_test))):\n",
        "        print(f\"\\nId {i}:\")\n",
        "        print(f\"  {preds_test[i][:120]}...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    return {\n",
        "        'bleu4': bleu4,\n",
        "        'bertscore_f1': bert_f1,\n",
        "        'final_score': final_proxy,\n",
        "        'kaggle_score': 0.925 * final_proxy,\n",
        "        'submission_file': SUBMISSION_PATH\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_evaluation_and_submission()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ TERMIN√â !\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"üìÑ Fichier de submission : {results['submission_file']}\")\n",
        "    print(f\"üìä Score validation      : {results['final_score']:.5f}\")\n",
        "    print(f\"üéØ Score Kaggle estim√©   : {results['kaggle_score']:.5f}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nüí° Prochaine √©tape : Upload le fichier sur Kaggle !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLuyGcErSgL1",
        "outputId": "b97cc9fc-b23e-4969-ae83-4bae35278a88"
      },
      "id": "cLuyGcErSgL1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Configuration : cuda\n",
            "üì• Chargement du Dual Encoder depuis data_baseline/data/dual_lrGNN0.0008_lrBERT3e-05_wd0.0001_frz0_margin0.2_bs128.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Nouveau format - Config: {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}, Freeze: 0\n",
            "üìÇ Chargement des datasets...\n",
            "   Train: 31008 exemples\n",
            "   Val:   1000 exemples\n",
            "   Test:  1000 exemples (pour Kaggle)\n",
            "üîÑ Recalcul des embeddings de r√©f√©rence (31008 textes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Train Texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 969/969 [01:41<00:00,  9.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings train: torch.Size([31008, 768])\n",
            "\n",
            "======================================================================\n",
            "üìä √âVALUATION SUR VALIDATION SET\n",
            "======================================================================\n",
            "üß™ Encodage de 1000 graphes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Graphs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 75.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Recherche des descriptions les plus proches (Validation)...\n",
            "üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üèÜ R√âSULTATS VALIDATION (NLP METRICS)\n",
            "======================================================================\n",
            "BLEU-4        : 0.43530\n",
            "BERTScore F1  : 0.92371\n",
            "Final Score   : 0.67950\n",
            "Kaggle Score  : 0.62854\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üéØ G√âN√âRATION SUBMISSION KAGGLE (TEST SET)\n",
            "======================================================================\n",
            "üß™ Encodage de 1000 graphes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Graphs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 75.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Recherche des descriptions les plus proches (Test)...\n",
            "\n",
            "üíæ Submission sauvegard√©e : submission_dual_encoder.csv\n",
            "   Nombre de pr√©dictions : 1000\n",
            "   Preview :\n",
            " ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         description\n",
            "  0                                                                                                                                                                                                                               The molecule is a beta-D-glucosyl-(1<->1')-N-acylsphinganine in which the acyl group specified is eicosanoyl. It has a role as a mouse metabolite. It is a beta-D-glucosyl-(1<->1')-N-acylsphinganine and a secondary carboxamide. It derives from an icosanoic acid.\n",
            "  1 The molecule is the monohydrate form of doxapram hydrochloride. A central and respiratory stimulant with a brief duration of action, it is used as a temporary treatment of acute respiratory failure, particularly when superimposed on chronic obstructive pulmonary disease, and of postoperative respiratory depression. It has also been used for treatment of postoperative shivering. It has a role as a central nervous system stimulant. It contains a doxapram hydrochloride (anhydrous).\n",
            "  2                                                                                                                                                                                           The molecule is a steroid glucosiduronic acid having androsterone as the steroid component. It has a role as a metabolite, a human metabolite and a mouse metabolite. It is a beta-D-glucosiduronic acid and a steroid glucosiduronic acid. It derives from an androsterone and a beta-D-glucuronic acid.\n",
            "  3                                                                                                                                                                                                                                                                                         The molecule is a hydroxy fatty acid ascaroside anion that is the conjugate base of oscr#37, obtained by deprotonation of the carboxy group; major species at pH 7.3. It is a conjugate base of an oscr#37.\n",
            "  4                                                                                                                                                                                                                                      The molecule is an organochlorine compound that consists of acetaldehyde where all the methyl hydrogens are replaced by chloro groups. It has a role as a mouse metabolite. It is an organochlorine compound and an aldehyde. It derives from an acetaldehyde.\n",
            "  5                                                                                                                                                                                                                                                    The molecule is an amino disaccharide that consists of N-acetyl-beta-D-glucosamine having a 6-O-sulfo-beta-D-galactosyl residue attached at position 4. It has a role as an epitope. It is an amino disaccharide and an oligosaccharide sulfate.\n",
            "  6                                                                                                                                                                                                                                                                                                The molecule is a gluconic acid having D-configuration. It has a role as a chelator and a Penicillium metabolite. It is a conjugate acid of a D-gluconate. It is an enantiomer of a L-gluconic acid.\n",
            "  7                                                                                                                                                                  The molecule is a homodetic cyclic peptide that consists of L-valine as the amino acid residue. It is isolated from Lissoclinum bistratum and exhibits antitumour activity against the human colon tumour cell line. It has a role as a metabolite and an antineoplastic agent. It is a homodetic cyclic peptide and a macrocycle.\n",
            "  8                                                                                        The molecule is a monocarboxylic acid that is phenylacetic acid carrying a 4-methoxy substituent. It is used as an intermediate for pharmaceuticals and other organic synthesis. It has been found to inhibit the germination of cress and lettuce seeds. It has a role as a plant metabolite, a plant growth retardant and an Aspergillus metabolite. It is a monocarboxylic acid and a monomethoxybenzene.\n",
            "  9                                                                                                                                                                                                                            The molecule is an organic cation obtained by protonation of the two free amino groups of 2'-deamino-2'-hydroxyparomamine; major species at pH 7.3. It is an ammonium ion derivative and an organic cation. It is a conjugate acid of a 2'-deamino-2'-hydroxyparomamine.\n",
            "\n",
            "üìù EXEMPLES DE PR√âDICTIONS (TEST SET) :\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Id 0:\n",
            "  The molecule is a beta-D-glucosyl-(1<->1')-N-acylsphinganine in which the acyl group specified is eicosanoyl. It has a r...\n",
            "\n",
            "Id 1:\n",
            "  The molecule is the monohydrate form of doxapram hydrochloride. A central and respiratory stimulant with a brief duratio...\n",
            "\n",
            "Id 2:\n",
            "  The molecule is a steroid glucosiduronic acid having androsterone as the steroid component. It has a role as a metabolit...\n",
            "\n",
            "Id 3:\n",
            "  The molecule is a hydroxy fatty acid ascaroside anion that is the conjugate base of oscr#37, obtained by deprotonation o...\n",
            "\n",
            "Id 4:\n",
            "  The molecule is an organochlorine compound that consists of acetaldehyde where all the methyl hydrogens are replaced by ...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "‚úÖ TERMIN√â !\n",
            "======================================================================\n",
            "üìÑ Fichier de submission : submission_dual_encoder.csv\n",
            "üìä Score validation      : 0.67950\n",
            "üéØ Score Kaggle estim√©   : 0.62854\n",
            "======================================================================\n",
            "\n",
            "üí° Prochaine √©tape : Upload le fichier sur Kaggle !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.nn import GPSConv, GINEConv, global_add_pool\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import evaluate\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================================================================\n",
        "# 0. CONFIGURATION\n",
        "# ==============================================================================\n",
        "MODEL_PATH = \"data_baseline/data/dual_lrGNN0.0008_lrBERT1e-05_wd0.0001_frz0_margin0.2_bs128.pt\"\n",
        "DATA_DIR = Path(\"data_baseline/data\")\n",
        "MODEL_NAME = \"recobo/chemical-bert-uncased\"\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Output\n",
        "SUBMISSION_PATH = \"submission_dual_encoder.csv\"\n",
        "\n",
        "print(f\"‚öôÔ∏è Configuration : {DEVICE}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. D√âFINITION DE L'ARCHITECTURE\n",
        "# ==============================================================================\n",
        "ATOM_DIMS = [119, 4, 11, 12, 9, 5, 8, 2, 2]\n",
        "BOND_DIMS = [22, 6, 2]\n",
        "\n",
        "class AtomEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in ATOM_DIMS])\n",
        "    def forward(self, x):\n",
        "        return sum(emb(x[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class BondEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim, hidden_dim) for dim in BOND_DIMS])\n",
        "    def forward(self, edge_attr):\n",
        "        return sum(emb(edge_attr[:, i]) for i, emb in enumerate(self.embeddings))\n",
        "\n",
        "class MolGNN(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, out_dim=768, num_layers=4, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.atom_encoder = AtomEncoder(hidden_dim)\n",
        "        self.bond_encoder = BondEncoder(hidden_dim)\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            local_nn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, 2 * hidden_dim),\n",
        "                nn.BatchNorm1d(2 * hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GPSConv(\n",
        "                hidden_dim,\n",
        "                GINEConv(local_nn, train_eps=True, edge_dim=hidden_dim),\n",
        "                heads=num_heads,\n",
        "                dropout=dropout,\n",
        "                attn_type='multihead'\n",
        "            ))\n",
        "        self.pool = global_add_pool\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        h = self.atom_encoder(batch.x)\n",
        "        edge_attr = self.bond_encoder(batch.edge_attr)\n",
        "        for conv in self.convs:\n",
        "            h = conv(h, batch.edge_index, batch.batch, edge_attr=edge_attr)\n",
        "        return self.proj(self.pool(h, batch.batch))\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, model_name, gnn_args, freeze_layers=0):\n",
        "        super().__init__()\n",
        "        self.graph_encoder = MolGNN(**gnn_args)\n",
        "        self.text_encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        if freeze_layers > 0:\n",
        "            print(f\"‚ùÑÔ∏è Gel des {freeze_layers} premi√®res couches de BERT\")\n",
        "            for param in self.text_encoder.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "            for i in range(freeze_layers):\n",
        "                if i < len(self.text_encoder.encoder.layer):\n",
        "                    for param in self.text_encoder.encoder.layer[i].parameters():\n",
        "                        param.requires_grad = False\n",
        "\n",
        "        bert_dim = self.text_encoder.config.hidden_size\n",
        "        out_dim = gnn_args['out_dim']\n",
        "        self.text_proj = nn.Linear(bert_dim, out_dim) if bert_dim != out_dim else nn.Identity()\n",
        "\n",
        "    def forward_text(self, input_ids, attention_mask):\n",
        "        t_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return F.normalize(self.text_proj(t_out.last_hidden_state[:, 0, :]), dim=-1)\n",
        "\n",
        "    def forward_graph(self, batch):\n",
        "        return F.normalize(self.graph_encoder(batch), dim=-1)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FONCTIONS DE CHARGEMENT\n",
        "# ==============================================================================\n",
        "def load_dual_encoder(checkpoint_path, device='cuda'):\n",
        "    \"\"\"Charge le DualEncoder (g√®re nouveau format).\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        args = checkpoint.get('args', {})\n",
        "\n",
        "        gnn_config = {\n",
        "            'hidden_dim': args.get('hidden_dim', 256),\n",
        "            'out_dim': 768,\n",
        "            'num_layers': args.get('num_layers', 4),\n",
        "            'num_heads': args.get('num_heads', 4),\n",
        "            'dropout': args.get('dropout', 0.1),\n",
        "        }\n",
        "        freeze_layers = args.get('freeze_layers', 0)\n",
        "        model_name = args.get('model_name', MODEL_NAME)\n",
        "\n",
        "        print(f\"‚úÖ Nouveau format - Config: {gnn_config}, Freeze: {freeze_layers}\")\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "        gnn_config = {\n",
        "            'hidden_dim': 256,\n",
        "            'out_dim': 768,\n",
        "            'num_layers': 4,\n",
        "            'num_heads': 4,\n",
        "            'dropout': 0.1\n",
        "        }\n",
        "        freeze_layers = 0\n",
        "        model_name = MODEL_NAME\n",
        "        print(f\"‚ö†Ô∏è Ancien format - Config par d√©faut\")\n",
        "\n",
        "    model = DualEncoder(model_name, gnn_config, freeze_layers)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, gnn_config\n",
        "\n",
        "\n",
        "def load_texts_and_graphs(pkl_path, has_description=True):\n",
        "    \"\"\"\n",
        "    Charge les graphes et extrait les descriptions (si disponibles).\n",
        "\n",
        "    Args:\n",
        "        pkl_path: Chemin vers le fichier pickle\n",
        "        has_description: Si False, retourne None pour les textes\n",
        "    \"\"\"\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    if has_description:\n",
        "        texts = [d.description for d in data]\n",
        "    else:\n",
        "        texts = None  # Pas de description dans le test set\n",
        "\n",
        "    return data, texts\n",
        "\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, graphs):\n",
        "        self.graphs = graphs\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx]\n",
        "\n",
        "\n",
        "def collate_text(batch):\n",
        "    return batch\n",
        "\n",
        "\n",
        "def collate_graph(batch):\n",
        "    return Batch.from_data_list(batch)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MOTEUR D'INFERENCE\n",
        "# ==============================================================================\n",
        "@torch.no_grad()\n",
        "def generate_reference_embeddings(model, tokenizer, texts, device, batch_size=32):\n",
        "    \"\"\"Recalcule les embeddings du TRAIN avec le BERT fine-tun√©.\"\"\"\n",
        "    print(f\"üîÑ Recalcul des embeddings de r√©f√©rence ({len(texts)} textes)...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(texts, batch_size=batch_size, collate_fn=collate_text)\n",
        "\n",
        "    for batch_texts in tqdm(loader, desc=\"Encoding Train Texts\"):\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "\n",
        "        emb = model.forward_text(inputs['input_ids'], inputs['attention_mask'])\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_graphs(model, graphs, device, batch_size=32):\n",
        "    \"\"\"Encode les graphes en embeddings.\"\"\"\n",
        "    print(f\"üß™ Encodage de {len(graphs)} graphes...\")\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    loader = DataLoader(\n",
        "        GraphDataset(graphs),\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_graph\n",
        "    )\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Encoding Graphs\"):\n",
        "        batch = batch.to(device)\n",
        "        emb = model.forward_graph(batch)\n",
        "        embeddings.append(emb.cpu())\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "\n",
        "def generate_submission(predictions, output_path):\n",
        "\n",
        "#def generate_submission(predictions, output_path):\n",
        "    #submission_df = pd.DataFrame({\n",
        "    #    'ID': range(len(predictions)),      # ‚Üê Correction : 'ID' en majuscules\n",
        "    #    'Predicted': predictions\n",
        "    #})\n",
        "    #\n",
        "    #submission_df.to_csv(output_path, index=False)\n",
        "    #...\n",
        "    \"\"\"\n",
        "    G√©n√®re le fichier de submission Kaggle.\n",
        "\n",
        "    Args:\n",
        "        predictions: Liste de textes pr√©dits (dans l'ordre du test set)\n",
        "        output_path: Chemin du fichier CSV √† cr√©er\n",
        "    \"\"\"\n",
        "    submission_df = pd.DataFrame({\n",
        "        'ID': range(len(predictions)),\n",
        "        'description': predictions\n",
        "    })\n",
        "\n",
        "    submission_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\nüíæ Submission sauvegard√©e : {output_path}\")\n",
        "    print(f\"   Nombre de pr√©dictions : {len(predictions)}\")\n",
        "    print(f\"   Preview :\")\n",
        "    print(submission_df.head(10).to_string(index=False))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_evaluation_and_submission():\n",
        "    \"\"\"√âvaluation + G√©n√©ration de submission Kaggle.\"\"\"\n",
        "\n",
        "    # === 1. CHARGEMENT MOD√àLE ===\n",
        "    print(f\"üì• Chargement du Dual Encoder depuis {MODEL_PATH}\")\n",
        "    model, config = load_dual_encoder(MODEL_PATH, DEVICE)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # === 2. CHARGEMENT DONN√âES ===\n",
        "    print(\"üìÇ Chargement des datasets...\")\n",
        "    train_graphs, train_texts = load_texts_and_graphs(DATA_DIR / \"train_graphs.pkl\")\n",
        "\n",
        "    # Test set pour Kaggle\n",
        "    # APR√àS\n",
        "    test_graphs, _ = load_texts_and_graphs(DATA_DIR / \"test_graphs.pkl\", has_description=False)\n",
        "\n",
        "\n",
        "    # Validation set (pour m√©triques locales)\n",
        "    val_graphs, val_texts = load_texts_and_graphs(DATA_DIR / \"validation_graphs.pkl\")\n",
        "\n",
        "    print(f\"   Train: {len(train_graphs)} exemples\")\n",
        "    print(f\"   Val:   {len(val_graphs)} exemples\")\n",
        "    print(f\"   Test:  {len(test_graphs)} exemples (pour Kaggle)\")\n",
        "\n",
        "    # === 3. CR√âATION BANQUE DE R√âF√âRENCE (TRAIN) ===\n",
        "    train_embs = generate_reference_embeddings(\n",
        "        model, tokenizer, train_texts, DEVICE, batch_size=BATCH_SIZE\n",
        "    )\n",
        "    train_embs = train_embs.to(DEVICE)\n",
        "\n",
        "    print(f\"   Embeddings train: {train_embs.shape}\")\n",
        "\n",
        "    # === 4A. ENCODAGE GRAPHES VALIDATION (pour m√©triques) ===\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üìä √âVALUATION SUR VALIDATION SET\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    val_mol_embs = encode_graphs(model, val_graphs, DEVICE, batch_size=BATCH_SIZE)\n",
        "    val_mol_embs = val_mol_embs.to(DEVICE)\n",
        "\n",
        "    # Retrieval validation\n",
        "    print(\"üîç Recherche des descriptions les plus proches (Validation)...\")\n",
        "    sims_val = val_mol_embs @ train_embs.t()\n",
        "    best_indices_val = sims_val.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    preds_val = [train_texts[idx] for idx in best_indices_val]\n",
        "    refs_val = val_texts\n",
        "\n",
        "    # Calcul m√©triques\n",
        "    print(\"üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\")\n",
        "\n",
        "    bleu_metric = evaluate.load(\"bleu\")\n",
        "    bleu_res = bleu_metric.compute(\n",
        "        predictions=preds_val,\n",
        "        references=[[r] for r in refs_val],\n",
        "        max_order=4\n",
        "    )\n",
        "    bleu4 = bleu_res[\"bleu\"]\n",
        "\n",
        "    bert_metric = evaluate.load(\"bertscore\")\n",
        "    bert_res = bert_metric.compute(\n",
        "        predictions=preds_val,\n",
        "        references=refs_val,\n",
        "        model_type=\"roberta-base\",\n",
        "        lang=\"en\"\n",
        "    )\n",
        "    bert_f1 = float(np.mean(bert_res[\"f1\"]))\n",
        "\n",
        "    final_proxy = 0.5 * (bleu4 if bleu4 <= 1.0 else bleu4/100) + 0.5 * bert_f1\n",
        "\n",
        "    # Affichage r√©sultats validation\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üèÜ R√âSULTATS VALIDATION (NLP METRICS)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"BLEU-4        : {bleu4:.5f}\")\n",
        "    print(f\"BERTScore F1  : {bert_f1:.5f}\")\n",
        "    print(f\"Final Score   : {final_proxy:.5f}\")\n",
        "    print(f\"Kaggle Score  : {0.925 * final_proxy:.5f}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # === 4B. G√âN√âRATION PR√âDICTIONS TEST (pour Kaggle) ===\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéØ G√âN√âRATION SUBMISSION KAGGLE (TEST SET)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    test_mol_embs = encode_graphs(model, test_graphs, DEVICE, batch_size=BATCH_SIZE)\n",
        "    test_mol_embs = test_mol_embs.to(DEVICE)\n",
        "\n",
        "    print(\"üîç Recherche des descriptions les plus proches (Test)...\")\n",
        "    sims_test = test_mol_embs @ train_embs.t()\n",
        "    best_indices_test = sims_test.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    preds_test = [train_texts[idx] for idx in best_indices_test]\n",
        "\n",
        "    # G√©n√©ration du fichier submission\n",
        "    generate_submission(preds_test, SUBMISSION_PATH)\n",
        "\n",
        "    # Exemples de pr√©dictions\n",
        "    print(\"\\nüìù EXEMPLES DE PR√âDICTIONS (TEST SET) :\")\n",
        "    print(\"-\" * 70)\n",
        "    for i in range(min(5, len(preds_test))):\n",
        "        print(f\"\\nId {i}:\")\n",
        "        print(f\"  {preds_test[i][:120]}...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    return {\n",
        "        'bleu4': bleu4,\n",
        "        'bertscore_f1': bert_f1,\n",
        "        'final_score': final_proxy,\n",
        "        'kaggle_score': 0.925 * final_proxy,\n",
        "        'submission_file': SUBMISSION_PATH\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_evaluation_and_submission()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ TERMIN√â !\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"üìÑ Fichier de submission : {results['submission_file']}\")\n",
        "    print(f\"üìä Score validation      : {results['final_score']:.5f}\")\n",
        "    print(f\"üéØ Score Kaggle estim√©   : {results['kaggle_score']:.5f}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nüí° Prochaine √©tape : Upload le fichier sur Kaggle !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxlyWi6RUOfx",
        "outputId": "e3530eea-77ac-4a3b-e5f7-f5374a6e16d4"
      },
      "id": "FxlyWi6RUOfx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Configuration : cuda\n",
            "üì• Chargement du Dual Encoder depuis data_baseline/data/dual_lrGNN0.0008_lrBERT1e-05_wd0.0001_frz0_margin0.2_bs128.pt\n",
            "‚úÖ Nouveau format - Config: {'hidden_dim': 256, 'out_dim': 768, 'num_layers': 4, 'num_heads': 4, 'dropout': 0.1}, Freeze: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at recobo/chemical-bert-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Chargement des datasets...\n",
            "   Train: 31008 exemples\n",
            "   Val:   1000 exemples\n",
            "   Test:  1000 exemples (pour Kaggle)\n",
            "üîÑ Recalcul des embeddings de r√©f√©rence (31008 textes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Train Texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 969/969 [01:38<00:00,  9.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings train: torch.Size([31008, 768])\n",
            "\n",
            "======================================================================\n",
            "üìä √âVALUATION SUR VALIDATION SET\n",
            "======================================================================\n",
            "üß™ Encodage de 1000 graphes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Graphs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 75.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Recherche des descriptions les plus proches (Validation)...\n",
            "üìä Calcul des scores NLP (BLEU-4 & BERTScore)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üèÜ R√âSULTATS VALIDATION (NLP METRICS)\n",
            "======================================================================\n",
            "BLEU-4        : 0.42114\n",
            "BERTScore F1  : 0.92167\n",
            "Final Score   : 0.67141\n",
            "Kaggle Score  : 0.62105\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üéØ G√âN√âRATION SUBMISSION KAGGLE (TEST SET)\n",
            "======================================================================\n",
            "üß™ Encodage de 1000 graphes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding Graphs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 76.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Recherche des descriptions les plus proches (Test)...\n",
            "\n",
            "üíæ Submission sauvegard√©e : submission_dual_encoder.csv\n",
            "   Nombre de pr√©dictions : 1000\n",
            "   Preview :\n",
            " ID                                                                                                                                                                                                                                                                                                                           description\n",
            "  0                                                                                                                                               The molecule is a beta-D-galactosyl-(1<->1')-N-acylsphinganine in which the acyl group specified is docosanoyl. It has a role as a mouse metabolite. It derives from a docosanoic acid.\n",
            "  1                                            The molecule is an organic chloride salt of trospium. It is an antispasmodic drug used for the treatment of overactive bladder. It has a role as a muscarinic antagonist and an antispasmodic drug. It is an organic chloride salt and a quaternary ammonium salt. It contains a trospium.\n",
            "  2 The molecule is a steroid glucosiduronic acid that is 16-epiestriol having a single beta-D-glucuronic acid residue attached at position 16. It is a beta-D-glucosiduronic acid and a steroid glucosiduronic acid. It derives from a 16beta-hydroxyestradiol. It is a conjugate acid of a 16-epiestriol 16-O-(beta-D-glucuronide)(1-).\n",
            "  3                                                                                                                           The molecule is a hydroxy fatty acid ascaroside anion that is the conjugate base of oscr#37, obtained by deprotonation of the carboxy group; major species at pH 7.3. It is a conjugate base of an oscr#37.\n",
            "  4                                                                                                                                                                      The molecule is a chlorocarbon that is tetrachloro substituted ethene. It has a role as a nephrotoxic agent. It is a chlorocarbon and a member of chloroethenes.\n",
            "  5                                The molecule is an amino trisaccharide comprised of an 6-sulfated N-acetylglucosamine residue linked beta(1->3) to a galactose residue, which is itself linked beta(1->4) to an N-acetylglucosamine residue. It has a role as an epitope. It is an amino trisaccharide and an oligosaccharide sulfate.\n",
            "  6                                                                                                                            The molecule is a galactonic acid compound having L-configuration. It has a role as an Escherichia coli metabolite. It is a conjugate acid of a L-galactonate. It is an enantiomer of a D-galactonic acid.\n",
            "  7    The molecule is a homodetic cyclic peptide that consists of L-valine as the amino acid residue. It is isolated from Lissoclinum bistratum and exhibits antitumour activity against the human colon tumour cell line. It has a role as a metabolite and an antineoplastic agent. It is a homodetic cyclic peptide and a macrocycle.\n",
            "  8                                                                                                                          The molecule is a monocarboxylic acid that is propanoic acid substituted by a 3,4-dimethoxyphenyl group at position 3. It is a monocarboxylic acid and a dimethoxybenzene. It derives from a propionic acid.\n",
            "  9                                                                                               The molecule is an organic cation resulting from the protonation of the amino group of validoxylamine A; major species at pH 7.3. It is an ammonium ion derivative and an organic cation. It is a conjugate acid of a validoxylamine A.\n",
            "\n",
            "üìù EXEMPLES DE PR√âDICTIONS (TEST SET) :\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Id 0:\n",
            "  The molecule is a beta-D-galactosyl-(1<->1')-N-acylsphinganine in which the acyl group specified is docosanoyl. It has a...\n",
            "\n",
            "Id 1:\n",
            "  The molecule is an organic chloride salt of trospium. It is an antispasmodic drug used for the treatment of overactive b...\n",
            "\n",
            "Id 2:\n",
            "  The molecule is a steroid glucosiduronic acid that is 16-epiestriol having a single beta-D-glucuronic acid residue attac...\n",
            "\n",
            "Id 3:\n",
            "  The molecule is a hydroxy fatty acid ascaroside anion that is the conjugate base of oscr#37, obtained by deprotonation o...\n",
            "\n",
            "Id 4:\n",
            "  The molecule is a chlorocarbon that is tetrachloro substituted ethene. It has a role as a nephrotoxic agent. It is a chl...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "‚úÖ TERMIN√â !\n",
            "======================================================================\n",
            "üìÑ Fichier de submission : submission_dual_encoder.csv\n",
            "üìä Score validation      : 0.67141\n",
            "üéØ Score Kaggle estim√©   : 0.62105\n",
            "======================================================================\n",
            "\n",
            "üí° Prochaine √©tape : Upload le fichier sur Kaggle !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_____"
      ],
      "metadata": {
        "id": "iTGmXkh7_wIa"
      },
      "id": "iTGmXkh7_wIa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "9zO0bwAMOR9v",
        "5a92752f",
        "c2B-4AyZTpE7",
        "SjBS7_L6YHjw",
        "K-vUdCMMhAsx"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22f14b651d0c483197d985a0ed743975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec5d9472afbf462f94e677a7d8658163",
              "IPY_MODEL_612a660de5d74c449f7db0e7077688bc",
              "IPY_MODEL_a360ef17f6ab406caabe9bf1012b165f"
            ],
            "layout": "IPY_MODEL_2c289592c58541dd8b7dfe6ec6a12b83"
          }
        },
        "ec5d9472afbf462f94e677a7d8658163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6ee5a715244b8ebd5d3911368ee9d1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f1c1255ec1934dbea5feda16f9e33f3c",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
          }
        },
        "612a660de5d74c449f7db0e7077688bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_576a3f265609420a88d9392a293a5085",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df5ca6276bc34bc59e7cd0955010af6a",
            "value": 1
          }
        },
        "a360ef17f6ab406caabe9bf1012b165f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b5a05311f24855986cb0221ac3a851",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b071554e9bb04b03bff4bfde6f971562",
            "value": "‚Äá5.94k/?‚Äá[00:00&lt;00:00,‚Äá594kB/s]"
          }
        },
        "2c289592c58541dd8b7dfe6ec6a12b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6ee5a715244b8ebd5d3911368ee9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c1255ec1934dbea5feda16f9e33f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "576a3f265609420a88d9392a293a5085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "df5ca6276bc34bc59e7cd0955010af6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33b5a05311f24855986cb0221ac3a851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b071554e9bb04b03bff4bfde6f971562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3188a4f8ece433e92e4d11e640eeae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4293c7d0a789455392410d6cd68d3165",
              "IPY_MODEL_66da2f7f15de4586ab6a1681cf6d2c39",
              "IPY_MODEL_bf61011980174b7e8a687e85c0fb96ff"
            ],
            "layout": "IPY_MODEL_018e3a5eca4848a8b17563ee7853c01c"
          }
        },
        "4293c7d0a789455392410d6cd68d3165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43a2c3c92614df09d1e79ae2d1e594c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1c1f42c07936420c92b7873a692c2445",
            "value": "Downloading‚Äáextra‚Äámodules:‚Äá"
          }
        },
        "66da2f7f15de4586ab6a1681cf6d2c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae08f58d6c51412c868d47db2ad039d7",
            "max": 1554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc67545634704040be48934527550299",
            "value": 1554
          }
        },
        "bf61011980174b7e8a687e85c0fb96ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b01a21b2fa4d43a38857ca71fdba9f1a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_83c2ce459f0047d0b28e0a3daa88936f",
            "value": "‚Äá4.07k/?‚Äá[00:00&lt;00:00,‚Äá536kB/s]"
          }
        },
        "018e3a5eca4848a8b17563ee7853c01c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43a2c3c92614df09d1e79ae2d1e594c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1f42c07936420c92b7873a692c2445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae08f58d6c51412c868d47db2ad039d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc67545634704040be48934527550299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b01a21b2fa4d43a38857ca71fdba9f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c2ce459f0047d0b28e0a3daa88936f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd871904ed8248b5a058ea4749ec0da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a103979c82b74ec5af1c44b9db93c1af",
              "IPY_MODEL_e93414daeb174cb492ef92bf378b94d8",
              "IPY_MODEL_83cf769bb77c456d9e2170157d73dba0"
            ],
            "layout": "IPY_MODEL_ed9285948a6246978b3a9771c212d855"
          }
        },
        "a103979c82b74ec5af1c44b9db93c1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcaaafb68a234b3e9dd20c6c578e634a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_70aacfc8c195457881546bd0862a8474",
            "value": "Downloading‚Äáextra‚Äámodules:‚Äá"
          }
        },
        "e93414daeb174cb492ef92bf378b94d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a534e2427f496c9b11a7a4b31ec884",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f1b9d817e44dff946385c6a53bf557",
            "value": 1
          }
        },
        "83cf769bb77c456d9e2170157d73dba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc4c53ee9703451d8fa2fd897c38abc8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fa45ea8b3c72434ab0d7f76e21e384c6",
            "value": "‚Äá3.34k/?‚Äá[00:00&lt;00:00,‚Äá399kB/s]"
          }
        },
        "ed9285948a6246978b3a9771c212d855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcaaafb68a234b3e9dd20c6c578e634a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70aacfc8c195457881546bd0862a8474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a534e2427f496c9b11a7a4b31ec884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "30f1b9d817e44dff946385c6a53bf557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc4c53ee9703451d8fa2fd897c38abc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa45ea8b3c72434ab0d7f76e21e384c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd7e8c4c95946f9ba0b594c4ec2ec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ad470308384e9f8736ecfeb85972d7",
              "IPY_MODEL_b8f1c45456694cb894305e4317d55551",
              "IPY_MODEL_8f687189aadf4cd1af18c5a64b1ab3f7"
            ],
            "layout": "IPY_MODEL_65bf5346c1ac43068c748e4e6e5edfc5"
          }
        },
        "23ad470308384e9f8736ecfeb85972d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e25bc195432a4fe18b071e68d596c122",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ed076412275f487c8249a13387dec8fb",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
          }
        },
        "b8f1c45456694cb894305e4317d55551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56aab96d91104e6faae979a53587fbd8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8da92899ba54222994de380ed2219e9",
            "value": 1
          }
        },
        "8f687189aadf4cd1af18c5a64b1ab3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf626f40a51f4c63ba899868bd0b0506",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4df00895eb224f06bf9ee2fc6df75feb",
            "value": "‚Äá7.95k/?‚Äá[00:00&lt;00:00,‚Äá982kB/s]"
          }
        },
        "65bf5346c1ac43068c748e4e6e5edfc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e25bc195432a4fe18b071e68d596c122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed076412275f487c8249a13387dec8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56aab96d91104e6faae979a53587fbd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b8da92899ba54222994de380ed2219e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf626f40a51f4c63ba899868bd0b0506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df00895eb224f06bf9ee2fc6df75feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "073b847f3f5c4c98ab5114b995409e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80f45627bbf24890a75af8e1dfe0df78",
              "IPY_MODEL_898c04be9c8741d9818657abc5d9d47f",
              "IPY_MODEL_27d3d20fcc8a4497bac8fac93a6e6e96"
            ],
            "layout": "IPY_MODEL_b19818c53bbc40a98171da0a99deb159"
          }
        },
        "80f45627bbf24890a75af8e1dfe0df78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c454a95c9e84a9183f9046d1e4a692f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_69493bbfad4e46d6b5e970739c59b58f",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "898c04be9c8741d9818657abc5d9d47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e2c2e1790544d2924495b809b7dd9f",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c9c280fbc224fdf83b27c1409762d24",
            "value": 25
          }
        },
        "27d3d20fcc8a4497bac8fac93a6e6e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a384ce655cc54d8c8cc9f023bc86dcde",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3804a1ce7fba44679d42544c58d32b2c",
            "value": "‚Äá25.0/25.0‚Äá[00:00&lt;00:00,‚Äá3.29kB/s]"
          }
        },
        "b19818c53bbc40a98171da0a99deb159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c454a95c9e84a9183f9046d1e4a692f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69493bbfad4e46d6b5e970739c59b58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e2c2e1790544d2924495b809b7dd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9c280fbc224fdf83b27c1409762d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a384ce655cc54d8c8cc9f023bc86dcde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3804a1ce7fba44679d42544c58d32b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1db6a8a2c714a94ae0b41061b9966c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a4393d52fca481181125bfe9e936471",
              "IPY_MODEL_e59274c01402411ab51b5ebb8ef08526",
              "IPY_MODEL_6a019d294c4a45ac880e9f0eaebb52f4"
            ],
            "layout": "IPY_MODEL_f98a8c4b4e8040468878f23669f7ace7"
          }
        },
        "5a4393d52fca481181125bfe9e936471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8d35302e7d4059bb9fcee66c89a41c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6a314957b2e4a94b4b3ade7ea1c4df0",
            "value": "config.json:‚Äá100%"
          }
        },
        "e59274c01402411ab51b5ebb8ef08526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a7411fc6d24ae3bc0d555f6b039032",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04a537cd120347ab94e4b1cf1084808b",
            "value": 481
          }
        },
        "6a019d294c4a45ac880e9f0eaebb52f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b89ea37e43d45f0b9ca627617f1561e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2ab3035240314713a46a0e1a8119a9a5",
            "value": "‚Äá481/481‚Äá[00:00&lt;00:00,‚Äá68.6kB/s]"
          }
        },
        "f98a8c4b4e8040468878f23669f7ace7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8d35302e7d4059bb9fcee66c89a41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a314957b2e4a94b4b3ade7ea1c4df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9a7411fc6d24ae3bc0d555f6b039032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a537cd120347ab94e4b1cf1084808b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b89ea37e43d45f0b9ca627617f1561e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab3035240314713a46a0e1a8119a9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e455196777495e94d8a71d3b17b289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e30ed62f1a3417b9c1496563b27c94a",
              "IPY_MODEL_0f7c04799e5d4fe2a79e4a8b640ad00b",
              "IPY_MODEL_9c37884b4dd64859a5aa1b17e7df38a7"
            ],
            "layout": "IPY_MODEL_da89e03a97214702aac671003082f8af"
          }
        },
        "0e30ed62f1a3417b9c1496563b27c94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66981c20b0594db7ad7e0f8ac3775615",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b63557b0715a4b5dbf9cfe81f05c765f",
            "value": "vocab.json:‚Äá100%"
          }
        },
        "0f7c04799e5d4fe2a79e4a8b640ad00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79192f8d9cb14e369af8bf9d2a360226",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8e57ae5f4594a5c856bcbca9b8d2f35",
            "value": 898823
          }
        },
        "9c37884b4dd64859a5aa1b17e7df38a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ef02b04c5f4d8e95b383b125312f6a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bc95f65a420f48e494b521d972420d89",
            "value": "‚Äá899k/899k‚Äá[00:00&lt;00:00,‚Äá6.67MB/s]"
          }
        },
        "da89e03a97214702aac671003082f8af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66981c20b0594db7ad7e0f8ac3775615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b63557b0715a4b5dbf9cfe81f05c765f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79192f8d9cb14e369af8bf9d2a360226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e57ae5f4594a5c856bcbca9b8d2f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67ef02b04c5f4d8e95b383b125312f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc95f65a420f48e494b521d972420d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff935535f4b4374a7dea56153578456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8456c7baac0466d8a76f62626a9a0df",
              "IPY_MODEL_8561ac92e5c2469c8100565615fc23ec",
              "IPY_MODEL_fd2edee379214cfea6847365882a7219"
            ],
            "layout": "IPY_MODEL_9c174621c4e54a09b21bc11dfcaa2bff"
          }
        },
        "a8456c7baac0466d8a76f62626a9a0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c91ea2211d564994981d1b99888b9bb5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_387e4c8b9f5f499fb4cc2639ac96d987",
            "value": "merges.txt:‚Äá100%"
          }
        },
        "8561ac92e5c2469c8100565615fc23ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7455d76129ac458f9a6ae5fc6538e835",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf579325c6dd4aaba6a451bfadbf72de",
            "value": 456318
          }
        },
        "fd2edee379214cfea6847365882a7219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c14a2f729bc44809ff030810b4cec29",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5c7ac2a64dd14131955a0a1fc4c17f3a",
            "value": "‚Äá456k/456k‚Äá[00:00&lt;00:00,‚Äá7.33MB/s]"
          }
        },
        "9c174621c4e54a09b21bc11dfcaa2bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c91ea2211d564994981d1b99888b9bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387e4c8b9f5f499fb4cc2639ac96d987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7455d76129ac458f9a6ae5fc6538e835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf579325c6dd4aaba6a451bfadbf72de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c14a2f729bc44809ff030810b4cec29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7ac2a64dd14131955a0a1fc4c17f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acc9f739e94a4aa08b1d933dbe38647c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e187c853604648158b4c75074515e554",
              "IPY_MODEL_377147c20e2b4fe3b493076c0c8fb71b",
              "IPY_MODEL_38c309f4630c4691a0f7be256002d410"
            ],
            "layout": "IPY_MODEL_ead6799706144dacba0b74911364370c"
          }
        },
        "e187c853604648158b4c75074515e554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae2eb3bd42a453298c6d67b4f7a9226",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db4337f7f86944e0a8e45e726172dbca",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "377147c20e2b4fe3b493076c0c8fb71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8492511e4c7d4a889f4f58297cfb0129",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22d55a453aa24caba94c7872e247052b",
            "value": 1355863
          }
        },
        "38c309f4630c4691a0f7be256002d410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8261c575fa46608c4e5de02ed1bcec",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_062870db74ba4ed98c56d3f41f15db44",
            "value": "‚Äá1.36M/1.36M‚Äá[00:00&lt;00:00,‚Äá21.0MB/s]"
          }
        },
        "ead6799706144dacba0b74911364370c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae2eb3bd42a453298c6d67b4f7a9226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4337f7f86944e0a8e45e726172dbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8492511e4c7d4a889f4f58297cfb0129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d55a453aa24caba94c7872e247052b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa8261c575fa46608c4e5de02ed1bcec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062870db74ba4ed98c56d3f41f15db44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d7f90ca0d34f21b948c1ea9e7da1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37933e5bb78c4ce18a9680f090c12a6f",
              "IPY_MODEL_51ba12e6f23943579b4807e7b3cdd425",
              "IPY_MODEL_01c0a46db1404356994736edcc5418ff"
            ],
            "layout": "IPY_MODEL_900dfda4a2c74e92ae8e21f853b19909"
          }
        },
        "37933e5bb78c4ce18a9680f090c12a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdc72c230e440b6a1bd9798a6371e7a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_60a7139386054932869775e6b022bec6",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "51ba12e6f23943579b4807e7b3cdd425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b0e76e2f454f4cb5f73b9534920a06",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_505d8e147e4b4e2b952e4033f3c3150c",
            "value": 498818054
          }
        },
        "01c0a46db1404356994736edcc5418ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6411eb66dd747cb94a4f53fe1a3622a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_03a5bae804674bbfa02ce56afdb341ea",
            "value": "‚Äá499M/499M‚Äá[00:01&lt;00:00,‚Äá586MB/s]"
          }
        },
        "900dfda4a2c74e92ae8e21f853b19909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdc72c230e440b6a1bd9798a6371e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a7139386054932869775e6b022bec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38b0e76e2f454f4cb5f73b9534920a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505d8e147e4b4e2b952e4033f3c3150c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6411eb66dd747cb94a4f53fe1a3622a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a5bae804674bbfa02ce56afdb341ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}