# model_molca.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GINEConv, global_mean_pool

from data_utils import x_map, e_map, X_KEYS, E_KEYS

class CategoricalNodeEncoder(nn.Module):
    def __init__(self, hidden=256):
        super().__init__()
        self.hidden = hidden
        self.embs = nn.ModuleDict()
        for k in X_KEYS:
            self.embs[k] = nn.Embedding(len(x_map[k]), hidden)

    def forward(self, x):
        # x: [N, num_node_features] with ints
        # order assumed = X_KEYS
        h = 0
        for i, k in enumerate(X_KEYS):
            xi = x[:, i].clamp(min=0, max=len(x_map[k]) - 1)
            h = h + self.embs[k](xi)
        return h

class CategoricalEdgeEncoder(nn.Module):
    def __init__(self, hidden=256):
        super().__init__()
        self.embs = nn.ModuleDict()
        for k in E_KEYS:
            self.embs[k] = nn.Embedding(len(e_map[k]), hidden)

    def forward(self, edge_attr):
        # edge_attr: [E, num_edge_features] ints, order = E_KEYS
        h = 0
        for i, k in enumerate(E_KEYS):
            ei = edge_attr[:, i].clamp(min=0, max=len(e_map[k]) - 1)
            h = h + self.embs[k](ei)
        return h

class GraphEncoder(nn.Module):
    def __init__(self, hidden=256, layers=4):
        super().__init__()
        self.node_enc = CategoricalNodeEncoder(hidden)
        self.edge_enc = CategoricalEdgeEncoder(hidden)

        self.convs = nn.ModuleList()
        for _ in range(layers):
            mlp = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, hidden))
            self.convs.append(GINEConv(mlp, edge_dim=hidden))

    def forward(self, batch):
        x = self.node_enc(batch.x.long())
        e = self.edge_enc(batch.edge_attr.long())

        for conv in self.convs:
            x = conv(x, batch.edge_index, e)
            x = F.relu(x)

        # node embeddings returned + batch vector
        return x, batch.batch
